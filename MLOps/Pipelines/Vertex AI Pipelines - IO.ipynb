{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5428f244",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "![tracker](https://us-central1-vertex-ai-mlops-369716.cloudfunctions.net/pixel-tracking?path=statmike%2Fvertex-ai-mlops%2FMLOps%2FPipelines&file=Vertex+AI+Pipelines+-+IO.ipynb)\n",
    "<!--- header table --->\n",
    "<table align=\"left\">\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://colab.research.google.com/github/statmike/vertex-ai-mlops/blob/main/MLOps/Pipelines/Vertex%20AI%20Pipelines%20-%20IO.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Google Colaboratory logo\">\n",
    "      <br>Run in<br>Colab\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/colab/import/https%3A%2F%2Fraw.githubusercontent.com%2Fstatmike%2Fvertex-ai-mlops%2Fmain%2FMLOps%2FPipelines%2FVertex%2520AI%2520Pipelines%2520-%2520IO.ipynb\">\n",
    "      <img width=\"32px\" src=\"https://lh3.googleusercontent.com/JmcxdQi-qOpctIvWKgPtrzZdJJK-J3sWE1RsfjZNwshCFgE_9fULcNpuXYTilIR2hjwN\" alt=\"Google Cloud Colab Enterprise logo\">\n",
    "      <br>Run in<br>Colab Enterprise\n",
    "    </a>\n",
    "  </td>      \n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://github.com/statmike/vertex-ai-mlops/blob/main/MLOps/Pipelines/Vertex%20AI%20Pipelines%20-%20IO.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\">\n",
    "      <br>View on<br>GitHub\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/statmike/vertex-ai-mlops/main/MLOps/Pipelines/Vertex%20AI%20Pipelines%20-%20IO.ipynb\">\n",
    "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\">\n",
    "      <br>Open in<br>Vertex AI Workbench\n",
    "    </a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de82b91d-bbec-4495-abf1-37a0d7f04342",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "This is part of a [series of notebook based workflows](./readme.md) that teach all the ways to use pipelines within Vertex AI. The suggested order and description/reason is:\n",
    "\n",
    "|Link To Section|Notebook Workflow|Description|\n",
    "|---|---|---|\n",
    "||[Vertex AI Pipelines - Start Here](./Vertex%20AI%20Pipelines%20-%20Start%20Here.ipynb)|What are pipelines? Start here to go from code to pipeline and see it in action.|\n",
    "||[Vertex AI Pipelines - Introduction](./Vertex%20AI%20Pipelines%20-%20Introduction.ipynb)|Introduction to pipelines with the console and Vertex AI SDK|\n",
    "||[Vertex AI Pipelines - Components](./Vertex%20AI%20Pipelines%20-%20Components.ipynb)|An introduction to all the ways to create pipeline components from your code|\n",
    "|_**This Notebook**_|[Vertex AI Pipelines - IO](./Vertex%20AI%20Pipelines%20-%20IO.ipynb)|An overview of all the type of inputs and outputs for pipeline components|\n",
    "||[Vertex AI Pipelines - Control](./Vertex%20AI%20Pipelines%20-%20Control.ipynb)|An overview of controlling the flow of exectution for pipelines|\n",
    "||[Vertex AI Pipelines - Secret Manager](./Vertex%20AI%20Pipelines%20-%20Secret%20Manager.ipynb)|How to pass sensitive information to pipelines and components|\n",
    "||[Vertex AI Pipelines - GCS Read and Write](./Vertex%20AI%20Pipelines%20-%20GCS%20Read%20and%20Write.ipynb)|How to read/write to GCS from components, including container components.|\n",
    "||[Vertex AI Pipelines - Scheduling](./Vertex%20AI%20Pipelines%20-%20Scheduling.ipynb)|How to schedule pipeline execution|\n",
    "||[Vertex AI Pipelines - Notifications](./Vertex%20AI%20Pipelines%20-%20Notifications.ipynb)|How to send email notification of pipeline status.|\n",
    "||[Vertex AI Pipelines - Management](./Vertex%20AI%20Pipelines%20-%20Management.ipynb)|Managing, Reusing, and Storing pipelines and components|\n",
    "||[Vertex AI Pipelines - Testing](./Vertex%20AI%20Pipelines%20-%20Testing.ipynb)|Strategies for testing components and pipeliens locally and remotely to aide development.|\n",
    "||[Vertex AI Pipelines - Managing Pipeline Jobs](./Vertex%20AI%20Pipelines%20-%20Managing%20Pipeline%20Jobs.ipynb)|Manage runs of pipelines in an environment: list, check status, filtered list, cancel and delete jobs.|\n",
    "\n",
    "\n",
    "To discover these notebooks as part of an introduction to MLOps orchestration [start here](./readme.md).  To read more about MLOps also check out [the parent folder](../readme.md).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b7e678-d1ad-42f6-8eb5-9d3ca73c49c6",
   "metadata": {},
   "source": [
    "# Vertex AI Pipelines - IO\n",
    "\n",
    "[Vertex AI Pipelines](https://cloud.google.com/vertex-ai/docs/pipelines/introduction) is a serverless  runner for Kubeflow Pipelines [(KFP)](https://www.kubeflow.org/docs/components/pipelines/v2/introduction/) and the [TensorFlow Extended (TFX)](https://www.tensorflow.org/tfx/guide/understanding_tfx_pipelines) framework.\n",
    "\n",
    "Components are used to run the steps of a pipelines.  A pipeline task runs the component with inputs and results in the components outputs.  The components execute code on compute with a container image.  And all the inputs and outputs are logged as pipeline metadata - automatically!\n",
    "\n",
    "This notebook will focus on the different data types for inputs and outputs to components.\n",
    "\n",
    "**Parameters** are Python objects like `str`, `int`, `float`, `bool`, `list`, `dict` objects that are defined as inputs to pipelines and components. Components can also return parameters for input into subsequent components. Paramters are excellent for changing the behavior of a pipeline/component through inputs rather than rewriting code.\n",
    "- [KFP Parameters](https://www.kubeflow.org/docs/components/pipelines/v2/data-types/parameters/)\n",
    "\n",
    "**Artifacts** are multi-parameter objects that represent machine learning artifacts and have defined schemas and are stored as metadata with lineage.  The artifact schemas follow the [ML Metadata (MLMD)](https://github.com/google/ml-metadata) client library.  This helps with understanding and analyzing a pipeline.\n",
    "- [KFP Artifacts](https://www.kubeflow.org/docs/components/pipelines/v2/data-types/artifacts/)\n",
    "    - provided [artifact types](https://www.kubeflow.org/docs/components/pipelines/v2/data-types/artifacts/#artifact-types)\n",
    "    - [Google Cloud Artifact Types](https://google-cloud-pipeline-components.readthedocs.io/en/google-cloud-pipeline-components-2.0.0/api/artifact_types.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71cbd642-b4b6-406d-8686-5c02b3af4ed6",
   "metadata": {
    "id": "od_UkDpvRmgD",
    "tags": []
   },
   "source": [
    "---\n",
    "## Colab Setup\n",
    "\n",
    "To run this notebook in Colab run the cells in this section.  Otherwise, skip this section.\n",
    "\n",
    "This cell will authenticate to GCP (follow prompts in the popup)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "602eac30-3606-435d-a079-d1b9db688990",
   "metadata": {
    "executionInfo": {
     "elapsed": 195,
     "status": "ok",
     "timestamp": 1683726184843,
     "user": {
      "displayName": "Mike Henderson",
      "userId": "07691629187611687318"
     },
     "user_tz": 240
    },
    "id": "8UO9FnqyKBlF",
    "tags": []
   },
   "outputs": [],
   "source": [
    "PROJECT_ID = 'statmike-mlops-349915' # replace with project ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70d9bea9-1567-4c5e-99c9-dd6caf1c9abc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 68869,
     "status": "ok",
     "timestamp": 1683726253709,
     "user": {
      "displayName": "Mike Henderson",
      "userId": "07691629187611687318"
     },
     "user_tz": 240
    },
    "id": "N98-KK7LRkjm",
    "outputId": "09ec5008-0def-4e1a-c349-c598ee752f78",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not a Colab Environment\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    from google.colab import auth\n",
    "    auth.authenticate_user()\n",
    "    !gcloud config set project {PROJECT_ID}\n",
    "    print('Colab authorized to GCP')\n",
    "except Exception:\n",
    "    print('Not a Colab Environment')\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b46f84a-a0b7-49fb-a277-fff79394c0ed",
   "metadata": {},
   "source": [
    "---\n",
    "## Installs\n",
    "\n",
    "The list `packages` contains tuples of package import names and install names.  If the import name is not found then the install name is used to install quitely for the current user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fdf619d0-ac63-47d9-8e68-805b9b366b9d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# tuples of (import name, install name, min_version)\n",
    "packages = [\n",
    "    ('google.cloud.aiplatform', 'google-cloud-aiplatform'),\n",
    "    ('kfp', 'kfp'),\n",
    "    ('google_cloud_pipeline_components', 'google-cloud-pipeline-components'),\n",
    "]\n",
    "\n",
    "import importlib\n",
    "install = False\n",
    "for package in packages:\n",
    "    if not importlib.util.find_spec(package[0]):\n",
    "        print(f'installing package {package[1]}')\n",
    "        install = True\n",
    "        !pip install {package[1]} -U -q --user\n",
    "    elif len(package) == 3:\n",
    "        if importlib.metadata.version(package[0]) < package[2]:\n",
    "            print(f'updating package {package[1]}')\n",
    "            install = True\n",
    "            !pip install {package[1]} -U -q --user"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7766d3aa-8efa-42b7-a355-f4108a089a33",
   "metadata": {},
   "source": [
    "### API Enablement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dbac5cbe-87e7-4569-8dac-c74c910a800a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!gcloud services enable aiplatform.googleapis.com"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba9e053e-4386-490a-8200-ec0bf060fefc",
   "metadata": {},
   "source": [
    "### Restart Kernel (If Installs Occured)\n",
    "\n",
    "After a kernel restart the code submission can start with the next cell after this one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a4eb5cf-ad4d-4a5f-8e00-a9369b21f5df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if install:\n",
    "    import IPython\n",
    "    app = IPython.Application.instance()\n",
    "    app.kernel.do_shutdown(True)\n",
    "    IPython.display.display(IPython.display.Markdown(\"\"\"<div class=\\\"alert alert-block alert-warning\\\">\n",
    "        <b>⚠️ The kernel is going to restart. Please wait until it is finished before continuing to the next step. The previous cells do not need to be run again⚠️</b>\n",
    "        </div>\"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1829ae7-121e-445c-bb8f-6dc29f69fdf0",
   "metadata": {
    "id": "appt8-yVRtJ1"
   },
   "source": [
    "---\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a95d9aed-510f-4a52-ba06-02c18766f4f2",
   "metadata": {
    "id": "63mx2EozRxFP"
   },
   "source": [
    "Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "50d77108-5ced-43a5-9348-68face53ee99",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 2124,
     "status": "ok",
     "timestamp": 1683726390544,
     "user": {
      "displayName": "Mike Henderson",
      "userId": "07691629187611687318"
     },
     "user_tz": 240
    },
    "id": "xzcoXjM5Rky5",
    "outputId": "b3bdcbc1-70d5-472e-aea2-42c74a42efde",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'statmike-mlops-349915'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project = !gcloud config get-value project\n",
    "PROJECT_ID = project[0]\n",
    "PROJECT_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd40bff4-7e8c-4520-8246-cccd7783ec86",
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1683726390712,
     "user": {
      "displayName": "Mike Henderson",
      "userId": "07691629187611687318"
     },
     "user_tz": 240
    },
    "id": "IxWrFtqYMfku",
    "tags": []
   },
   "outputs": [],
   "source": [
    "REGION = 'us-central1'\n",
    "SERIES = 'mlops'\n",
    "EXPERIMENT = 'pipeline-io'\n",
    "\n",
    "# gcs bucket\n",
    "GCS_BUCKET = PROJECT_ID"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "632a67ea-fb37-402b-b2d0-43df633a2f7b",
   "metadata": {
    "id": "LuajVwCiO6Yg"
   },
   "source": [
    "Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c9025f7b-56fe-436c-9827-e959c8639f0f",
   "metadata": {
    "executionInfo": {
     "elapsed": 17761,
     "status": "ok",
     "timestamp": 1683726409304,
     "user": {
      "displayName": "Mike Henderson",
      "userId": "07691629187611687318"
     },
     "user_tz": 240
    },
    "id": "LVC7zzSLRk2C",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os, time, importlib\n",
    "from typing import NamedTuple\n",
    "\n",
    "from google.cloud import aiplatform\n",
    "import kfp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "23ee59c4-31a7-4d9b-b62a-1de226650d98",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.10.1'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kfp.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ae3d6b8-202f-4df3-a031-72b084b80919",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.78.0'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aiplatform.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e563f7-a09c-4746-abf5-a906be394b5b",
   "metadata": {
    "id": "EyAVFG9TO9H-"
   },
   "source": [
    "Clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9c07f984-7130-402d-bb3c-fc400b0283bd",
   "metadata": {
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1683726409306,
     "user": {
      "displayName": "Mike Henderson",
      "userId": "07691629187611687318"
     },
     "user_tz": 240
    },
    "id": "L0RPE13LOZce",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# vertex ai clients\n",
    "aiplatform.init(project = PROJECT_ID, location = REGION)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c47247-7db0-4ae8-a537-2ebe2add47d2",
   "metadata": {},
   "source": [
    "parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5e4bc595-17aa-41e9-9f9b-f91632602671",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DIR = f\"temp/{SERIES}-{EXPERIMENT}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "42ee51d9-77c8-4771-990e-0a05db6aa968",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1026793852137-compute@developer.gserviceaccount.com'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SERVICE_ACCOUNT = !gcloud config list --format='value(core.account)' \n",
    "SERVICE_ACCOUNT = SERVICE_ACCOUNT[0]\n",
    "SERVICE_ACCOUNT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c92fa0b-2566-4607-9f3f-fda7a0b01b95",
   "metadata": {},
   "source": [
    "environment:\n",
    "- make a local folder for temporary storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bdc119f6-47d7-48d4-aef2-9681074a4cfa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(DIR):\n",
    "    os.makedirs(DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b9189c5-d8d7-4aef-a7a5-c9af2a8e778c",
   "metadata": {},
   "source": [
    "---\n",
    "## Parameters\n",
    "\n",
    "**Parameters** are Python objects like `str`, `int`, `float`, `bool`, `list`, `dict` objects that are defined as inputs to pipelines and components. Components can also return parameters for input into subsequent components. Paramters are excellent for changing the behavior of a pipeline/component through inputs rather than rewriting code.\n",
    "- [KFP Parameters](https://www.kubeflow.org/docs/components/pipelines/v2/data-types/parameters/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b6b71d8-c1a7-418e-98c4-803c0f47c65f",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "### Inputs and Output\n",
    "\n",
    "An example pipeline that has all the types of input parameters and outputs a single parameter:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e1ce3e-ab80-46af-8d8a-4e6121665058",
   "metadata": {},
   "source": [
    "#### Create Pipeline Components\n",
    "\n",
    "These are simple Python components, specifically lightweight Python components and container components.  For more details on the types of components check out this workflow in the same repository:\n",
    "- [Vertex AI Pipelines - Components](./Vertex%20AI%20Pipelines%20-%20Components.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ba9066-992b-4294-be7b-2017be63f735",
   "metadata": {},
   "source": [
    "A simple lightweight python component with single input and single output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2d254576-c254-41b7-993a-ea0eefc3eea0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@kfp.dsl.component(\n",
    "    base_image = \"python:3.11\",\n",
    "    packages_to_install = [\"pandas\"]\n",
    ")\n",
    "def single_input(string: str) -> str:\n",
    "    text = string\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa82050-8ec6-4228-81b3-1099bd90b11d",
   "metadata": {},
   "source": [
    "A lightweight python component with multiple inputs and a single output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0c2432a9-69ab-4ade-ac04-3b5d4eaf6b3f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@kfp.dsl.component(\n",
    "    base_image = \"python:3.11\",\n",
    "    packages_to_install = [\"pandas\"]\n",
    ")\n",
    "def multi_input(\n",
    "    a_str: str,\n",
    "    a_int: int,\n",
    "    a_float: float,\n",
    "    a_bool: bool,\n",
    "    a_dict: dict,\n",
    "    a_list: list\n",
    ") -> list:\n",
    "    text = [a_str, a_int, a_float, a_bool, a_dict, a_list]\n",
    "    return [str(t) for t in text]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea4ea67-66e6-49e4-862c-da3a210be9f5",
   "metadata": {},
   "source": [
    "A container component with a single input and single output.  Note that this type of component using the [`kfp.dsl.OutputPath`](https://kubeflow-pipelines.readthedocs.io/en/latest/source/dsl.html#kfp.dsl.OutputPath) to return the output to an object that looks like an input:\n",
    "- The shell command for `mkdir` is used to create an output loation  with the `kfp.dsl.OutputPath` variable\n",
    "- The `echo` command along with the `>` write to instruction are used to write values to the `kfp.dsl_OutputPath` using the directory created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f4e9dfa0-e592-4899-91ab-e70e571526ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@kfp.dsl.container_component\n",
    "def io_container(\n",
    "    in_str: str,\n",
    "    out_str: kfp.dsl.OutputPath(str)\n",
    "):\n",
    "    return kfp.dsl.ContainerSpec(\n",
    "        image = 'alpine',\n",
    "        command = [\n",
    "            'sh', '-c',  f'''mkdir -p $(dirname {out_str})\\\n",
    "                            && echo \"echoing {in_str}\" > {out_str}'''\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b8930d-e632-453e-a66f-20ec53fb76c6",
   "metadata": {},
   "source": [
    "#### Create Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e9e4cb25-a255-4c2e-b24f-945db913a63d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pipeline_name = f'{SERIES}-{EXPERIMENT}-parameter-io'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5930c86c-5568-4ac8-b4f5-45892aed5fec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@kfp.dsl.pipeline(\n",
    "    name = pipeline_name,\n",
    "    description = 'A simple pipeline for testing',\n",
    "    pipeline_root = f'gs://{GCS_BUCKET}/{SERIES}/{EXPERIMENT}/pipeline_root'\n",
    ")\n",
    "def example_pipeline(\n",
    "    a_str: str,\n",
    "    a_int: int,\n",
    "    a_float: float,\n",
    "    a_bool: bool,\n",
    "    a_dict: dict,\n",
    "    a_list: list\n",
    ") -> list:\n",
    "    \n",
    "    single_io = single_input(string = a_str)\n",
    "    multi_i = multi_input(\n",
    "        a_str = single_io.output,\n",
    "        a_int= a_int,\n",
    "        a_float= a_float,\n",
    "        a_bool = a_bool,\n",
    "        a_dict = a_dict,\n",
    "        a_list = a_list   \n",
    "    )\n",
    "    container_io = io_container(in_str = single_io.output)\n",
    "    \n",
    "    return multi_i.output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce2f58e-8485-47ad-9afa-16555926e4c6",
   "metadata": {},
   "source": [
    "#### Compile Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d0f94cc2-61aa-4d36-b333-15af73f3dd9a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "kfp.compiler.Compiler().compile(\n",
    "    pipeline_func = example_pipeline,\n",
    "    package_path = f'{DIR}/{pipeline_name}.yaml'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3843fed-315d-4835-a67e-ffa60c401842",
   "metadata": {},
   "source": [
    "#### Create Pipeline Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "99506b8a-6fe7-48d3-af4a-64af87540368",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "parameters = dict(\n",
    "    a_str = 'test string',\n",
    "    a_int = 1,\n",
    "    a_float = 1.2,\n",
    "    a_bool = True,\n",
    "    a_dict = dict(key = 45),\n",
    "    a_list = [1, 2, 3]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "75d77f8d-1a15-4791-b95a-b5ac85986a69",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pipeline_job = aiplatform.PipelineJob(\n",
    "    display_name = pipeline_name,\n",
    "    template_path = f\"{DIR}/{pipeline_name}.yaml\",\n",
    "    parameter_values = parameters,\n",
    "    pipeline_root = f'gs://{GCS_BUCKET}/{SERIES}/{EXPERIMENT}/pipeline_root',\n",
    "    enable_caching = None # True (enabled), False (disable), None (defer to component level caching) \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef190bf-35e9-46af-8eff-7283c974a9b0",
   "metadata": {},
   "source": [
    "#### Submit Pipeline Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d85d67f0-4d11-4d03-ae2d-92e3a6a142da",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating PipelineJob\n",
      "PipelineJob created. Resource name: projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-io-parameter-io-20250310155145\n",
      "To use this PipelineJob in another session:\n",
      "pipeline_job = aiplatform.PipelineJob.get('projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-io-parameter-io-20250310155145')\n",
      "View Pipeline Job:\n",
      "https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/mlops-pipeline-io-parameter-io-20250310155145?project=1026793852137\n"
     ]
    }
   ],
   "source": [
    "response = pipeline_job.submit(\n",
    "    service_account = SERVICE_ACCOUNT\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4f54890d-ce67-4012-b8a8-b41fda947d45",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Dashboard can be viewed here:\n",
      "https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/mlops-pipeline-io-parameter-io-20250310155145?project=1026793852137\n"
     ]
    }
   ],
   "source": [
    "print(f'The Dashboard can be viewed here:\\n{pipeline_job._dashboard_uri()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "32bd4fe7-beb7-4373-b499-c1b90b1a97bb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PipelineJob projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-io-parameter-io-20250310155145 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-io-parameter-io-20250310155145 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-io-parameter-io-20250310155145 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-io-parameter-io-20250310155145 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-io-parameter-io-20250310155145 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob run completed. Resource name: projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-io-parameter-io-20250310155145\n"
     ]
    }
   ],
   "source": [
    "pipeline_job.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7916b9a2-d950-4bd7-b0a1-a56c482d76a7",
   "metadata": {},
   "source": [
    "**Pipeline Dashboard View In The Console: Task Level Details**\n",
    "<p><center>\n",
    "    <img src=\"../resources/images/screenshots/pipelines/io/input-output.png\" width=\"75%\">\n",
    "</center><p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f0e810-ca9a-43b1-bcf7-63e2e5edfbd3",
   "metadata": {},
   "source": [
    "#### Retrieve Pipeline Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "127f461e-6d87-4b68-9562-928b7a1e53c6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pipeline_name</th>\n",
       "      <th>run_name</th>\n",
       "      <th>param.input:a_bool</th>\n",
       "      <th>param.input:a_str</th>\n",
       "      <th>param.input:a_int</th>\n",
       "      <th>param.output:Output</th>\n",
       "      <th>param.input:a_dict</th>\n",
       "      <th>param.vmlmd_lineage_integration</th>\n",
       "      <th>param.input:a_list</th>\n",
       "      <th>param.input:a_float</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mlops-pipeline-io-parameter-io</td>\n",
       "      <td>mlops-pipeline-io-parameter-io-20250310155145</td>\n",
       "      <td>True</td>\n",
       "      <td>test string</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[test string, 1, 1.2, True, {'key': 45}, [1, 2...</td>\n",
       "      <td>{'key': 45.0}</td>\n",
       "      <td>{'pipeline_run_component': {'parent_task_names...</td>\n",
       "      <td>[1.0, 2.0, 3.0]</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mlops-pipeline-io-parameter-io</td>\n",
       "      <td>mlops-pipeline-io-parameter-io-20240507115117</td>\n",
       "      <td>True</td>\n",
       "      <td>test string</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[test string, 1, 1.2, True, {'key': 45}, [1, 2...</td>\n",
       "      <td>{'key': 45.0}</td>\n",
       "      <td>{'pipeline_run_component': {'parent_task_names...</td>\n",
       "      <td>[1.0, 2.0, 3.0]</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    pipeline_name  \\\n",
       "0  mlops-pipeline-io-parameter-io   \n",
       "1  mlops-pipeline-io-parameter-io   \n",
       "\n",
       "                                        run_name  param.input:a_bool  \\\n",
       "0  mlops-pipeline-io-parameter-io-20250310155145                True   \n",
       "1  mlops-pipeline-io-parameter-io-20240507115117                True   \n",
       "\n",
       "  param.input:a_str  param.input:a_int  \\\n",
       "0       test string                1.0   \n",
       "1       test string                1.0   \n",
       "\n",
       "                                 param.output:Output param.input:a_dict  \\\n",
       "0  [test string, 1, 1.2, True, {'key': 45}, [1, 2...      {'key': 45.0}   \n",
       "1  [test string, 1, 1.2, True, {'key': 45}, [1, 2...      {'key': 45.0}   \n",
       "\n",
       "                     param.vmlmd_lineage_integration param.input:a_list  \\\n",
       "0  {'pipeline_run_component': {'parent_task_names...    [1.0, 2.0, 3.0]   \n",
       "1  {'pipeline_run_component': {'parent_task_names...    [1.0, 2.0, 3.0]   \n",
       "\n",
       "   param.input:a_float  \n",
       "0                  1.2  \n",
       "1                  1.2  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aiplatform.get_pipeline_df(pipeline = f'{pipeline_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "003fd409-0a89-4937-a970-7f6f49f9b0c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tasks = {task.task_name: task for task in pipeline_job.task_details}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9e6e6303-4b9d-4d05-8413-9001ba0cdbf7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "single-input State.SUCCEEDED\n",
      "io-container State.SKIPPED\n",
      "multi-input State.SUCCEEDED\n",
      "mlops-pipeline-io-parameter-io-20250310155145 State.SUCCEEDED\n"
     ]
    }
   ],
   "source": [
    "for task in tasks:\n",
    "  print(task, tasks[task].state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d6c6e5b0-194f-4b54-9181-fe1c33c0eef7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#tasks['io-container']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf9f9629-05c1-4b33-8038-bd86f2682fbd",
   "metadata": {},
   "source": [
    "---\n",
    "### Multiple Outputs\n",
    "\n",
    "How to handle multiple output parameters when there is a single output object?  This is possible in pipelines components by using the [`typing` modules](https://docs.python.org/3/library/typing.html#module-typing) [`NamedTuple`](https://docs.python.org/3/library/typing.html#typing.NamedTuple) implementation.  These are tuples with named fields, meaning, that fields can be accessed by name instead of position indexes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2628fd64-0e01-4b98-839a-298f54859b1e",
   "metadata": {},
   "source": [
    "#### Understanding `NamedTuple`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a7254ef-bcd0-4415-b614-943ab85578bd",
   "metadata": {},
   "source": [
    "First, are regular tuple.  The following creates a tuple and then recalls the 3rd element with an index.  At first this might seem like a list in Python but tuples are immutable objects - elements cannot be modified, added, or removed.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "81923be9-e0d2-4596-bf3c-9b55ea44b3e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "example_tuple = (1, 'string', 4.5, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d1e54728-7ef5-46e9-8246-62d81cb8b32a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.5"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_tuple[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fef5f78-bb04-47d8-873c-980883379229",
   "metadata": {},
   "source": [
    "Now, a named tuple.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0e0ca37c-e159-49b9-845d-5aec91df9769",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "example_named_tuple = NamedTuple('example', x=int, y=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c072f0f9-17ad-4968-9765-591c0acd9dd7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_tuple = example_named_tuple(4, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ec151e48-c393-4112-85a3-d968427a505f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "example(x=4, y=8)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e73c9c8a-eba0-48f3-a220-750e736c4554",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_tuple.x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a189bf-3dff-4101-9c7f-25df87ab63e7",
   "metadata": {},
   "source": [
    "Also, define and populate all at once like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "62e6d6e1-224b-46e4-aa0c-200ea033e168",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "example(x=2, y=9)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NamedTuple('example', x=int, y=int)(2, 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f5eb202-081f-4edd-b067-1f841f3d95ca",
   "metadata": {},
   "source": [
    "#### Create Pipeline Components\n",
    "\n",
    "These are simple Python components, specifically lightweight Python components and container components.  For more details on the types of components check out this workflow in the same repository:\n",
    "- [Vertex AI Pipelines - Components](./Vertex%20AI%20Pipelines%20-%20Components.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddeda78c-777e-4cdb-b342-5332005ceaa8",
   "metadata": {},
   "source": [
    "A lightweight python component with multiple inputs and multiple outputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "650b6d9f-8c7e-455c-bf5f-fe7ca2100e49",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@kfp.dsl.component(\n",
    "    base_image = \"python:3.11\",\n",
    "    packages_to_install = [\"pandas\"]\n",
    ")\n",
    "def multi_input_output(\n",
    "    a_str: str,\n",
    "    a_int: int,\n",
    "    a_float: float,\n",
    "    a_bool: bool,\n",
    "    a_dict: dict,\n",
    "    a_list: list\n",
    ") -> NamedTuple('multi_output', b_str=str, b_int=int, b_float=float, b_bool=bool, b_dict=dict, b_list=list):\n",
    "    from typing import NamedTuple\n",
    "    output = NamedTuple('multi_output', b_str=str, b_int=int, b_float=float, b_bool=bool, b_dict=dict, b_list=list)\n",
    "    return output(a_str, a_int, a_float, a_bool, a_dict, a_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11737e06-b7cd-4ddd-9bfa-b1ca2043b37e",
   "metadata": {},
   "source": [
    "#### Create Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fc3b39d1-f7da-4b79-a6a6-d0ce78b4486a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pipeline_name = f'{SERIES}-{EXPERIMENT}-parameter-multi-io'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e4da685b-225e-4600-a3ea-7fe451f4894e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@kfp.dsl.pipeline(\n",
    "    name = pipeline_name,\n",
    "    description = 'A simple pipeline for testing',\n",
    "    pipeline_root = f'gs://{GCS_BUCKET}/{SERIES}/{EXPERIMENT}/pipeline_root'\n",
    ")\n",
    "def example_pipeline(\n",
    "    a_str: str,\n",
    "    a_int: int,\n",
    "    a_float: float,\n",
    "    a_bool: bool,\n",
    "    a_dict: dict,\n",
    "    a_list: list\n",
    ") -> list:\n",
    "    \n",
    "    multi_io = multi_input_output(\n",
    "        a_str = a_str,\n",
    "        a_int= a_int,\n",
    "        a_float= a_float,\n",
    "        a_bool = a_bool,\n",
    "        a_dict = a_dict,\n",
    "        a_list = a_list \n",
    "    )\n",
    "    multi_i = multi_input(\n",
    "        a_str = multi_io.outputs['b_str'],\n",
    "        a_int= multi_io.outputs['b_int'],\n",
    "        a_float= multi_io.outputs['b_float'],\n",
    "        a_bool = multi_io.outputs['b_bool'],\n",
    "        a_dict = multi_io.outputs['b_dict'],\n",
    "        a_list = multi_io.outputs['b_list']   \n",
    "    )\n",
    "    \n",
    "    return multi_i.output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f68190-6495-42a6-b821-f3a9a2a20993",
   "metadata": {},
   "source": [
    "#### Compile Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e7264d29-7548-4a6e-ad29-7e8a005a55a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "kfp.compiler.Compiler().compile(\n",
    "    pipeline_func = example_pipeline,\n",
    "    package_path = f'{DIR}/{pipeline_name}.yaml'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c940e2de-9a83-4165-8079-c16c6fbc226b",
   "metadata": {},
   "source": [
    "#### Create Pipeline Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4f82973d-0f9c-406f-bdf6-07f14b1fa013",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "parameters = dict(\n",
    "    a_str = 'test string',\n",
    "    a_int = 1,\n",
    "    a_float = 1.2,\n",
    "    a_bool = True,\n",
    "    a_dict = dict(key = 45),\n",
    "    a_list = [1, 2, 3]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a9cb62ed-9e66-40ca-9c74-d4703953f020",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pipeline_job = aiplatform.PipelineJob(\n",
    "    display_name = pipeline_name,\n",
    "    template_path = f\"{DIR}/{pipeline_name}.yaml\",\n",
    "    parameter_values = parameters,\n",
    "    pipeline_root = f'gs://{GCS_BUCKET}/{SERIES}/{EXPERIMENT}/pipeline_root',\n",
    "    enable_caching = None # True (enabled), False (disable), None (defer to component level caching) \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c35ad519-f9ae-4ced-aab9-cb42964d4bd2",
   "metadata": {},
   "source": [
    "#### Submit Pipeline Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1d9d06fe-ce77-40b0-8eea-8b555982d526",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating PipelineJob\n",
      "PipelineJob created. Resource name: projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-io-parameter-multi-io-20250310160048\n",
      "To use this PipelineJob in another session:\n",
      "pipeline_job = aiplatform.PipelineJob.get('projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-io-parameter-multi-io-20250310160048')\n",
      "View Pipeline Job:\n",
      "https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/mlops-pipeline-io-parameter-multi-io-20250310160048?project=1026793852137\n"
     ]
    }
   ],
   "source": [
    "response = pipeline_job.submit(\n",
    "    service_account = SERVICE_ACCOUNT\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f25fdc8d-d61b-4b0c-a587-aa7493aab440",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Dashboard can be viewed here:\n",
      "https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/mlops-pipeline-io-parameter-multi-io-20250310160048?project=1026793852137\n"
     ]
    }
   ],
   "source": [
    "print(f'The Dashboard can be viewed here:\\n{pipeline_job._dashboard_uri()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2250c5e4-40a7-4a5c-9128-988b79394b3c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PipelineJob projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-io-parameter-multi-io-20250310160048 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-io-parameter-multi-io-20250310160048 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-io-parameter-multi-io-20250310160048 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-io-parameter-multi-io-20250310160048 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob run completed. Resource name: projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-io-parameter-multi-io-20250310160048\n"
     ]
    }
   ],
   "source": [
    "pipeline_job.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c010b6-fef2-4d86-9db0-808bdb37787d",
   "metadata": {},
   "source": [
    "**Pipeline Dashboard View In The Console: Task Level Details**\n",
    "<p><center>\n",
    "    <img src=\"../resources/images/screenshots/pipelines/io/multi-output.png\" width=\"75%\">\n",
    "</center><p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b4242c-6113-4409-91b2-2aad6646b0c2",
   "metadata": {},
   "source": [
    "#### Retrieve Pipeline Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "744c662c-7a82-424f-8d04-3b05fde07d80",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pipeline_name</th>\n",
       "      <th>run_name</th>\n",
       "      <th>param.input:a_bool</th>\n",
       "      <th>param.input:a_str</th>\n",
       "      <th>param.input:a_int</th>\n",
       "      <th>param.output:Output</th>\n",
       "      <th>param.input:a_dict</th>\n",
       "      <th>param.vmlmd_lineage_integration</th>\n",
       "      <th>param.input:a_list</th>\n",
       "      <th>param.input:a_float</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mlops-pipeline-io-parameter-multi-io</td>\n",
       "      <td>mlops-pipeline-io-parameter-multi-io-202503101...</td>\n",
       "      <td>True</td>\n",
       "      <td>test string</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[test string, 1, 1.2, True, {'key': 45}, [1, 2...</td>\n",
       "      <td>{'key': 45.0}</td>\n",
       "      <td>{'pipeline_run_component': {'location_id': 'us...</td>\n",
       "      <td>[1.0, 2.0, 3.0]</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mlops-pipeline-io-parameter-multi-io</td>\n",
       "      <td>mlops-pipeline-io-parameter-multi-io-202405071...</td>\n",
       "      <td>True</td>\n",
       "      <td>test string</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[test string, 1, 1.2, True, {'key': 45}, [1, 2...</td>\n",
       "      <td>{'key': 45.0}</td>\n",
       "      <td>{'pipeline_run_component': {'location_id': 'us...</td>\n",
       "      <td>[1.0, 2.0, 3.0]</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mlops-pipeline-io-parameter-multi-io</td>\n",
       "      <td>mlops-pipeline-io-parameter-multi-io-202405071...</td>\n",
       "      <td>True</td>\n",
       "      <td>test string</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'key': 45.0}</td>\n",
       "      <td>{'pipeline_run_component': {'parent_task_names...</td>\n",
       "      <td>[1.0, 2.0, 3.0]</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mlops-pipeline-io-parameter-multi-io</td>\n",
       "      <td>mlops-pipeline-io-parameter-multi-io-202405071...</td>\n",
       "      <td>True</td>\n",
       "      <td>test string</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'key': 45.0}</td>\n",
       "      <td>{'pipeline_run_component': {'location_id': 'us...</td>\n",
       "      <td>[1.0, 2.0, 3.0]</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          pipeline_name  \\\n",
       "0  mlops-pipeline-io-parameter-multi-io   \n",
       "1  mlops-pipeline-io-parameter-multi-io   \n",
       "2  mlops-pipeline-io-parameter-multi-io   \n",
       "3  mlops-pipeline-io-parameter-multi-io   \n",
       "\n",
       "                                            run_name  param.input:a_bool  \\\n",
       "0  mlops-pipeline-io-parameter-multi-io-202503101...                True   \n",
       "1  mlops-pipeline-io-parameter-multi-io-202405071...                True   \n",
       "2  mlops-pipeline-io-parameter-multi-io-202405071...                True   \n",
       "3  mlops-pipeline-io-parameter-multi-io-202405071...                True   \n",
       "\n",
       "  param.input:a_str  param.input:a_int  \\\n",
       "0       test string                1.0   \n",
       "1       test string                1.0   \n",
       "2       test string                1.0   \n",
       "3       test string                1.0   \n",
       "\n",
       "                                 param.output:Output param.input:a_dict  \\\n",
       "0  [test string, 1, 1.2, True, {'key': 45}, [1, 2...      {'key': 45.0}   \n",
       "1  [test string, 1, 1.2, True, {'key': 45}, [1, 2...      {'key': 45.0}   \n",
       "2                                                NaN      {'key': 45.0}   \n",
       "3                                                NaN      {'key': 45.0}   \n",
       "\n",
       "                     param.vmlmd_lineage_integration param.input:a_list  \\\n",
       "0  {'pipeline_run_component': {'location_id': 'us...    [1.0, 2.0, 3.0]   \n",
       "1  {'pipeline_run_component': {'location_id': 'us...    [1.0, 2.0, 3.0]   \n",
       "2  {'pipeline_run_component': {'parent_task_names...    [1.0, 2.0, 3.0]   \n",
       "3  {'pipeline_run_component': {'location_id': 'us...    [1.0, 2.0, 3.0]   \n",
       "\n",
       "   param.input:a_float  \n",
       "0                  1.2  \n",
       "1                  1.2  \n",
       "2                  1.2  \n",
       "3                  1.2  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aiplatform.get_pipeline_df(pipeline = f'{pipeline_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "12c50b08-4a6e-44b9-b5dc-e4d1f3685768",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tasks = {task.task_name: task for task in pipeline_job.task_details}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d824941f-62ce-41ac-abb0-9ba058daabd6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multi-input State.SUCCEEDED\n",
      "mlops-pipeline-io-parameter-multi-io-20250310160048 State.SUCCEEDED\n",
      "multi-input-output State.SUCCEEDED\n"
     ]
    }
   ],
   "source": [
    "for task in tasks:\n",
    "  print(task, tasks[task].state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "da07aff4-720f-402c-add5-bf8d0486a439",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#tasks['multi-input-output']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ee04af-71d9-43cf-8cc7-a7d1cb9f9162",
   "metadata": {},
   "source": [
    "---\n",
    "## Artifacts\n",
    "\n",
    "**Artifacts** are multi-parameter objects that represent machine learning artifacts and have defined schemas and are stored as metadata with lineage.  The artifact schemas follow the [ML Metadata (MLMD)](https://github.com/google/ml-metadata) client library.  This helps with understanding and analyzing a pipeline.\n",
    "- [KFP Artifacts](https://www.kubeflow.org/docs/components/pipelines/v2/data-types/artifacts/)\n",
    "    - provided [artifact types](https://www.kubeflow.org/docs/components/pipelines/v2/data-types/artifacts/#artifact-types)\n",
    "    - [Google Cloud Artifact Types](https://google-cloud-pipeline-components.readthedocs.io/en/google-cloud-pipeline-components-2.0.0/api/artifact_types.html)\n",
    "    \n",
    "Artifacts are like other input parameters and output parameters and can be passed directly with the artifact class as a parameter.  For returning multiple artifacts use the same `NamedTuple` approach covered under parameters above.\n",
    "\n",
    "For Example:\n",
    "```Python\n",
    "import kfp\n",
    "\n",
    "@kfp.dsl.component()\n",
    "def new_component(input_artifact: kfp.dsl.Artifact) > kfp.dsl.Artifact:\n",
    "    ...\n",
    "    return kfp.dsl.Artifact\n",
    "```\n",
    "\n",
    "---\n",
    "**NOTE:** This is different than you may have seen in earlier `kfp` pipeline implementations.  Previously, artifacts were passed to and from components with input parameters that were defined with wrapper classes:\n",
    "- `kfp.dsl.Input`\n",
    "- `kfp.dsl.Output`\n",
    "\n",
    "See more information at [traditional artifact syntax](https://www.kubeflow.org/docs/components/pipelines/v2/data-types/artifacts/#traditional-artifact-syntax)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f32c7277-fd5f-46e8-b8b6-25c665337c99",
   "metadata": {},
   "source": [
    "### Artifacts: `kfp` Artifact Types\n",
    "\n",
    "There are generic artifacts available directly through `kfp` so you don't need to define custom ones (more later on importing additional artifiacts):\n",
    "|Artifact Object|Schema Name|Description|\n",
    "|---|---|---|\n",
    "|[`kfp.dsl.Artifact`](https://kubeflow-pipelines.readthedocs.io/en/latest/source/dsl.html#kfp.dsl.Artifact)|`system.Artifact`|Generic Artifact|\n",
    "|[`kfp.dsl.Dataset`](https://kubeflow-pipelines.readthedocs.io/en/latest/source/dsl.html#kfp.dsl.Dataset)|`system.Dataset`|Dataset Object|\n",
    "|[`kfp.dsl.Model`](https://kubeflow-pipelines.readthedocs.io/en/latest/source/dsl.html#kfp.dsl.Model)|`system.Model`|Model Object|\n",
    "|[`kfp.dsl.Metrics`](https://kubeflow-pipelines.readthedocs.io/en/latest/source/dsl.html#kfp.dsl.Metrics)|`system.Metrics`|Key:value scalar metrics (accuracy, precision, recall, ...)|\n",
    "|[`kfp.dsl.ClassificationMetrics`](https://kubeflow-pipelines.readthedocs.io/en/latest/source/dsl.html#kfp.dsl.ClassificationMetrics)|`system.ClassificationMetrics`|Classificaiton Metrics (ROC, consion matrix)|\n",
    "|[`kfp.dsl.SlicedClassificationMetrics`](https://kubeflow-pipelines.readthedocs.io/en/latest/source/dsl.html#kfp.dsl.SlicedClassificationMetrics)|`system.SlicedClassificationMetrics`|Classification Metrics (ROC, confusion matrix) for slices of data|\n",
    "|[`kfp.dsl.HTML`](https://kubeflow-pipelines.readthedocs.io/en/latest/source/dsl.html#kfp.dsl.HTML)|`system.HTML`|An HTML file|\n",
    "|[`kfp.dsl.Markdown`](https://kubeflow-pipelines.readthedocs.io/en/latest/source/dsl.html#kfp.dsl.Markdown)|`system.Markdown`|A Markdown file|\n",
    "\n",
    "These objects each have parameters:\n",
    "- `name` is the name of the artifact.  Vertex AI Pipelines automatically assigns this name to the metadata resource location and **cannot be overwritten**.\n",
    "- `uri` is the uri to artifacts location.  Vertex AI Pipelines automatically assigns a location based on the `aiplatform.PipelineJob(pipeline_root = 'gs://...')` value but **can be overwritten** to another location.\n",
    "- `metadata` is a `dict` of key:value pairs describing the object"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78bcaa21-72b1-4fe0-92be-ceed841c989d",
   "metadata": {},
   "source": [
    "### Artifacts: Google Cloud Artifact Types\n",
    "\n",
    "In addition to the `kfp` provided artifact types, there are also libraries of artifacts for native Google Cloud Artifacts.  Everything from BigQuery Tables, BigQuery ML Models, to Vertex AI Models and Vertex AI Endpoints.  These are included with the [Google Cloud Pipeline Components SDK](https://cloud.google.com/vertex-ai/docs/pipelines/components-introduction) which also includes GCP specific pre-built components as covered in the components workflow at see [Vertex AI Pipelines - Components](./Vertex%20AI%20Pipelines%20-%20Components.ipynb).\n",
    "- [GCP Specific Artifact Types](https://cloud.google.com/vertex-ai/docs/pipelines/artifact-types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "39252cad-fa1a-490b-893f-4be20b8604fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from google_cloud_pipeline_components.types import artifact_types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde5c5ad-8514-4d6b-8554-be22b882fc0d",
   "metadata": {},
   "source": [
    "---\n",
    "## Pipeline With Artifacts\n",
    "\n",
    "An example pipeline that makes use of:\n",
    "- all 8 `kfp` artifact types and multiple Google Cloud Artifact Types\n",
    "- passing artifacts as outputs and inputs between components\n",
    "- returning multiple artifacts from components\n",
    "- saving content for multiple artifacts with the same component"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f54e07a5-8ae6-4dcd-a8d1-6fd0ec1bf962",
   "metadata": {},
   "source": [
    "### Create Pipeline Components\n",
    "\n",
    "These are simple Python components, specifically lightweight Python components.  For more details on the types of components check out this workflow in the same repository:\n",
    "- [Vertex AI Pipelines - Components](./Vertex%20AI%20Pipelines%20-%20Components.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9291e57-7262-468a-a015-a74a010e4fb9",
   "metadata": {},
   "source": [
    "#### Component: `data_source`\n",
    "\n",
    "This component defines an artifact that points to the data source in place, in BigQuery.  It uses the Google Cloud Artifact Type for BigQuery Tables: [`google_cloud_pipeline_components.types.artifact_types.BQTable()`](https://google-cloud-pipeline-components.readthedocs.io/en/google-cloud-pipeline-components-2.14.0/api/artifact_types.html#google_cloud_pipeline_components.types.artifact_types.BQTable).\n",
    "\n",
    ">**NOTE:** This could be done with an importer component `kfp.dsl.importer` - see [Vertex AI Pipelines - Components](./Vertex%20AI%20Pipelines%20-%20Components.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "765cc393-ffbf-425c-af45-0edea9db45a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@kfp.dsl.component(\n",
    "    base_image = \"python:3.11\",\n",
    "    packages_to_install = [\"google-cloud-pipeline-components\"]\n",
    ")\n",
    "def data_source(\n",
    "    bq_project: str,\n",
    "    bq_dataset: str,\n",
    "    bq_table: str,\n",
    "    bq_table_artifact: kfp.dsl.Output[artifact_types.BQTable]\n",
    "):\n",
    "    \n",
    "    bq_table_artifact.uri = f'https://www.googleapis.com/bigquery/v2/projects/{bq_project}/datasets/{bq_dataset}/tables/{bq_table}'\n",
    "    bq_table_artifact.metadata['projectId'] = bq_project\n",
    "    bq_table_artifact.metadata['datasetId'] = bq_dataset\n",
    "    bq_table_artifact.metadata['tableId'] = bq_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93420d86-3805-4ddb-8840-d9e8108c159e",
   "metadata": {},
   "source": [
    "#### Component: `data_prep`\n",
    "\n",
    "A lightweight Python component that:\n",
    "- read data from BigQuery Table using Input Artifact for BigQuery Table\n",
    "- split data in the train, eval, text\n",
    "- create output artifacts (`kfp.dsl.Dataset`) for each split of the data\n",
    "- create output artifact (`kfp.dsl.Artifact`) with feature information from the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "78442045-b769-4ac4-b871-eaf1d0d9891c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@kfp.dsl.component(\n",
    "    base_image = \"python:3.11\",\n",
    "    packages_to_install = [\"google-cloud-pipeline-components\", \"bigframes\", \"scikit-learn\"]\n",
    ")\n",
    "def data_prep(\n",
    "    project_id: str,\n",
    "    bq_source: kfp.dsl.Input[artifact_types.BQTable],\n",
    ") -> NamedTuple(\n",
    "        'output',\n",
    "        train=kfp.dsl.Dataset,\n",
    "        test=kfp.dsl.Dataset,\n",
    "        features=kfp.dsl.Artifact\n",
    "):\n",
    "    from typing import NamedTuple\n",
    "    outputs = NamedTuple(\n",
    "            'output',\n",
    "            train=kfp.dsl.Dataset,\n",
    "            test=kfp.dsl.Dataset,\n",
    "            features=kfp.dsl.Artifact\n",
    "    )\n",
    "    \n",
    "    # connect to BigQuery table, ELT, read to local\n",
    "    import bigframes.pandas as bpd\n",
    "    bpd.options.bigquery.project = project_id\n",
    "    bpd.options.bigquery.location = 'us'\n",
    "    ds = bpd.read_gbq(f\"{bq_source.metadata['projectId']}.{bq_source.metadata['datasetId']}.{bq_source.metadata['tableId']}\")\n",
    "    # fix data quality issue\n",
    "    ds['sex'] = ds['sex'].replace('.', None)\n",
    "    full_ds = ds.to_pandas()\n",
    "    \n",
    "    # split data into train/test\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    train_ds, test_ds = train_test_split(full_ds, test_size = 0.25)\n",
    "    \n",
    "    # write test and train to Dataset artifacts - with specific subfolders\n",
    "    import os\n",
    "    #train\n",
    "    train = kfp.dsl.Dataset(\n",
    "        uri = kfp.dsl.get_uri(suffix = 'train'),\n",
    "        metadata = dict(\n",
    "            samples = train_ds.shape[0],\n",
    "            filename = 'data.txt'\n",
    "        )\n",
    "    )\n",
    "    path = train.path + '/data.txt'\n",
    "    os.makedirs(os.path.dirname(path), exist_ok = True)\n",
    "    with open(path, 'w') as f:\n",
    "        f.write(train_ds.to_json(orient='records'))\n",
    "    # test    \n",
    "    test = kfp.dsl.Dataset(\n",
    "        uri = kfp.dsl.get_uri(suffix = 'test'),\n",
    "        metadata = dict(\n",
    "            samples = test_ds.shape[0],\n",
    "            filename = 'data.txt'\n",
    "        )\n",
    "    )\n",
    "    path = test.path + '/data.txt'\n",
    "    os.makedirs(os.path.dirname(path), exist_ok = True)\n",
    "    with open(path, 'w') as f:\n",
    "        f.write(test_ds.to_json(orient='records'))\n",
    "    \n",
    "    # add feature info the feature Artifact\n",
    "    features = kfp.dsl.Artifact(\n",
    "        metadata = dict(\n",
    "            label_col = 'species',\n",
    "            label_values = ds['species'].unique().to_list(),\n",
    "            train_n = train_ds.shape[0],\n",
    "            test_n = test_ds.shape[0],\n",
    "            features = [x for x in ds.columns.to_list() if x != 'species']\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    return outputs(train, test, features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c18facd9-fa73-485e-8a4b-99e2496fed6f",
   "metadata": {},
   "source": [
    "#### Component: `model_gb`\n",
    "\n",
    "A lightweight Python component that:\n",
    "- inputs artifacts for training data as well as feature information created by the `data_prep` component\n",
    "- creates a model with `sklearn.ensemble.GradientBoostingClassifier`\n",
    "- output artifact for the model (`kfp.dsl.Model`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "730923c9-86b4-4a66-9b9d-5e9716fbaf64",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@kfp.dsl.component(\n",
    "    base_image = \"python:3.11\",\n",
    "    packages_to_install = [\"pandas\", \"scikit-learn\"]\n",
    ")\n",
    "def model_gb(\n",
    "    train: kfp.dsl.Dataset,\n",
    "    features: kfp.dsl.Artifact\n",
    ") -> kfp.dsl.Model:\n",
    "    \n",
    "    # import data\n",
    "    import pandas as pd\n",
    "    from io import StringIO\n",
    "    with open(train.path + f\"/{train.metadata['filename']}\", 'r') as f:\n",
    "        train_ds = f.read()\n",
    "    train_ds = pd.read_json(StringIO(train_ds), orient='records')\n",
    "    \n",
    "    # prepare data for training: split the features (x) and label (y)\n",
    "    train_x = train_ds[features.metadata['features']]\n",
    "    train_y = train_ds[features.metadata['label_col']] \n",
    "    \n",
    "    # create pipeline with preprocessing and training\n",
    "    import sklearn.ensemble\n",
    "    import sklearn.impute\n",
    "    import sklearn.pipeline\n",
    "    import sklearn.preprocessing\n",
    "    import sklearn.compose\n",
    "    import numpy as np\n",
    "    numerical_transformer = sklearn.pipeline.Pipeline([\n",
    "        ('imputer', sklearn.impute.SimpleImputer(strategy = 'mean')),\n",
    "        ('scaler', sklearn.preprocessing.MinMaxScaler()),\n",
    "    ])\n",
    "    categorical_transformer = sklearn.pipeline.Pipeline([\n",
    "        ('imputer', sklearn.impute.SimpleImputer(strategy = 'most_frequent', add_indicator = True)),\n",
    "        ('encoder', sklearn.preprocessing.OrdinalEncoder()),\n",
    "    ])\n",
    "    preprocessor = sklearn.compose.ColumnTransformer(\n",
    "        transformers = [\n",
    "            ('numerical', numerical_transformer, [c for c in train_x.columns if train_x[c].isna().any() and train_x[c].dtypes == 'float64']),\n",
    "            ('categorical', categorical_transformer, [c for c in train_x.columns if train_x[c].isna().any() and train_x[c].dtypes == 'object'])\n",
    "        ]\n",
    "    )\n",
    "    pipeline = sklearn.pipeline.Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('classifier', sklearn.ensemble.GradientBoostingClassifier(n_estimators = 100, learning_rate = 0.125, max_depth = 3)),\n",
    "    ])\n",
    "    \n",
    "    # fit/train model\n",
    "    pipeline.fit(train_x, train_y)\n",
    "    \n",
    "    # save model and create artifact\n",
    "    import pickle, os\n",
    "    model = kfp.dsl.Model(\n",
    "        uri = kfp.dsl.get_uri(),\n",
    "        metadata = dict(\n",
    "            accuracy = pipeline.score(train_x, train_y)\n",
    "        )\n",
    "    )\n",
    "    path = model.path + '/model.pkl'\n",
    "    os.makedirs(os.path.dirname(path), exist_ok = True)\n",
    "    with open(path, 'wb') as f:\n",
    "        pickle.dump(pipeline, f)\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45702654-8195-4ed4-a4f4-b08b51acaff6",
   "metadata": {},
   "source": [
    "#### Component: `model_rf`\n",
    "\n",
    "A lightweight Python component that:\n",
    "- inputs artifacts for training data as well as feature information created by the `data_prep` component\n",
    "- creates a model with `sklearn.ensemble.RandomForestClassifier`\n",
    "- output artifacts for the model (`kfp.dsl.Model`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3d2d6381-d60f-4bb0-8825-94fcf1b4807e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@kfp.dsl.component(\n",
    "    base_image = \"python:3.11\",\n",
    "    packages_to_install = [\"pandas\", \"scikit-learn\"]\n",
    ")\n",
    "def model_rf(\n",
    "    train: kfp.dsl.Dataset,\n",
    "    features: kfp.dsl.Artifact\n",
    ") -> kfp.dsl.Model:\n",
    "    \n",
    "    # import data\n",
    "    import pandas as pd\n",
    "    from io import StringIO\n",
    "    with open(train.path + f\"/{train.metadata['filename']}\", 'r') as f:\n",
    "        train_ds = f.read()\n",
    "    train_ds = pd.read_json(StringIO(train_ds), orient='records')\n",
    "    \n",
    "    # prepare data for training: split the features (x) and label (y)\n",
    "    train_x = train_ds[features.metadata['features']]\n",
    "    train_y = train_ds[features.metadata['label_col']] \n",
    "    \n",
    "    # create pipeline with preprocessing and training\n",
    "    import sklearn.ensemble\n",
    "    import sklearn.impute\n",
    "    import sklearn.pipeline\n",
    "    import sklearn.preprocessing\n",
    "    import sklearn.compose\n",
    "    import numpy as np\n",
    "    numerical_transformer = sklearn.pipeline.Pipeline([\n",
    "        ('imputer', sklearn.impute.SimpleImputer(strategy = 'mean')),\n",
    "        ('scaler', sklearn.preprocessing.MinMaxScaler()),\n",
    "    ])\n",
    "    categorical_transformer = sklearn.pipeline.Pipeline([\n",
    "        ('imputer', sklearn.impute.SimpleImputer(strategy = 'most_frequent', add_indicator = True)),\n",
    "        ('encoder', sklearn.preprocessing.OrdinalEncoder()),\n",
    "    ])\n",
    "    preprocessor = sklearn.compose.ColumnTransformer(\n",
    "        transformers = [\n",
    "            ('numerical', numerical_transformer, [c for c in train_x.columns if train_x[c].isna().any() and train_x[c].dtypes == 'float64']),\n",
    "            ('categorical', categorical_transformer, [c for c in train_x.columns if train_x[c].isna().any() and train_x[c].dtypes == 'object'])\n",
    "        ]\n",
    "    )\n",
    "    pipeline = sklearn.pipeline.Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('classifier', sklearn.ensemble.RandomForestClassifier(n_estimators = 200, max_depth = 3)),\n",
    "    ])\n",
    "    \n",
    "    # fit/train model\n",
    "    pipeline.fit(train_x, train_y)\n",
    "    \n",
    "    # save model and create artifact\n",
    "    import pickle, os\n",
    "    model = kfp.dsl.Model(\n",
    "        uri = kfp.dsl.get_uri(),\n",
    "        metadata = dict(\n",
    "            accuracy = pipeline.score(train_x, train_y)\n",
    "        )\n",
    "    )\n",
    "    path = model.path + '/model.pkl'\n",
    "    os.makedirs(os.path.dirname(path), exist_ok = True)\n",
    "    with open(path, 'wb') as f:\n",
    "        pickle.dump(pipeline, f)\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c207652-8096-4895-88af-d8228d172c77",
   "metadata": {},
   "source": [
    "#### Component: `metrics`\n",
    "\n",
    "A lightweight Python component that:\n",
    "- inputs artifacts for a dataset and a model\n",
    "- create artifacts for:\n",
    "    - Metrics with `kfp.dsl.Metrics`\n",
    "    - Classification metrics with `kfp.dsl.ClassificationMetrics`\n",
    "    - Sliced Classification metrics wtih `kfp.dsl.SlicedClassificationMetrics`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b55ee56c-7969-4c38-9a7d-eeb6480651de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@kfp.dsl.component(\n",
    "    base_image = \"python:3.11\",\n",
    "    packages_to_install = [\"pandas\", \"numpy\", \"scikit-learn\"]\n",
    ")\n",
    "def metrics(\n",
    "    data: kfp.dsl.Dataset,\n",
    "    features: kfp.dsl.Artifact,\n",
    "    model: kfp.dsl.Model\n",
    ") -> NamedTuple(\n",
    "        'output',\n",
    "        metrics=kfp.dsl.Metrics,\n",
    "        class_metrics=kfp.dsl.ClassificationMetrics,\n",
    "        #slice_class_metrics=kfp.dsl.SlicedClassificationMetrics\n",
    "):\n",
    "    from typing import NamedTuple\n",
    "    outputs = NamedTuple(\n",
    "            'output',\n",
    "            metrics=kfp.dsl.Metrics,\n",
    "            class_metrics=kfp.dsl.ClassificationMetrics,\n",
    "            #slice_class_metrics=kfp.dsl.SlicedClassificationMetrics\n",
    "    )\n",
    "    \n",
    "    # import data\n",
    "    import pandas as pd\n",
    "    from io import StringIO\n",
    "    with open(data.path + f\"/{data.metadata['filename']}\", 'r') as f:\n",
    "        ds = f.read()\n",
    "    ds = pd.read_json(StringIO(ds), orient='records')\n",
    "    \n",
    "    # get the ground truth\n",
    "    x = ds[features.metadata['features']]\n",
    "    y = ds[features.metadata['label_col']]\n",
    "    \n",
    "    # import model\n",
    "    import pickle\n",
    "    with open(model.path+'/model.pkl', 'rb') as f:\n",
    "        classifier = pickle.load(f)\n",
    "    pred = classifier.predict(x)\n",
    "    proba = classifier.predict_proba(x)\n",
    "    \n",
    "    # metrics artifact\n",
    "    import sklearn.metrics\n",
    "    metrics = kfp.dsl.Metrics()\n",
    "    metrics.log_metric('accuracy', classifier.score(x, y))\n",
    "    if len(features.metadata['label_values'])>2:\n",
    "        metrics.log_metric('precision', sklearn.metrics.precision_score(y, pred, average='macro'))\n",
    "        metrics.log_metric('recall', sklearn.metrics.recall_score(y, pred, average='macro'))\n",
    "        metrics.log_metric('f1', sklearn.metrics.f1_score(y, pred, average='macro'))\n",
    "        metrics.log_metric('average_precision', sklearn.metrics.average_precision_score(y, proba, average='macro'))\n",
    "    else:\n",
    "        metrics.log_metric('precision', sklearn.metrics.precision_score(y, pred, average='binary'))\n",
    "        metrics.log_metric('recall', sklearn.metrics.recall_score(y, pred, average='binary'))\n",
    "        metrics.log_metric('f1', sklearn.metrics.f1_score(y, pred, average='binary'))\n",
    "        metrics.log_metric('average_precision', sklearn.metrics.average_precision_score(y, proba, average='binary'))\n",
    "    \n",
    "    # classification metrics artifact\n",
    "    class_metrics = kfp.dsl.ClassificationMetrics()\n",
    "    class_metrics.log_confusion_matrix(\n",
    "        categories = classifier.classes_,\n",
    "        matrix = sklearn.metrics.confusion_matrix(y, pred).tolist()\n",
    "    )\n",
    "    \n",
    "    # sliced classification metrics artifact\n",
    "    #import numpy as np\n",
    "    #import sklearn.preprocessing\n",
    "    #slice_class_metrics = kfp.dsl.SlicedClassificationMetrics()\n",
    "    #labeler = sklearn.preprocessing.LabelBinarizer().fit(y)\n",
    "    #for c in classifier.classes_:\n",
    "    #    i = np.where(labeler.transform([c]) == 1)[0][0]\n",
    "    #    fpr, tpr, thresholds = sklearn.metrics.roc_curve(\n",
    "    #        y_true = labeler.transform(y)[:, i],\n",
    "    #        y_score = classifier.predict_proba(x)[:, i]\n",
    "    #    )\n",
    "    #    infs = [t==np.inf for t in thresholds.tolist()]\n",
    "    #    \n",
    "    #    slice_class_metrics.load_roc_readings(\n",
    "    #        c,\n",
    "    #        [\n",
    "    #            [t for i,t in enumerate(thresholds.tolist()) if infs[i]==True],\n",
    "    #            [t for i,t in enumerate(tpr.tolist()) if infs[i]==True],\n",
    "    #            [t for i,t in enumerate(fpr.tolist()) if infs[i]==True]\n",
    "    #        ]\n",
    "    #    )\n",
    "        \n",
    "                       \n",
    "    return outputs(metrics, class_metrics) #, slice_class_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c8d227-3fc6-446d-8cfd-799f6f2b13e3",
   "metadata": {},
   "source": [
    "#### Component: `overview`\n",
    "\n",
    "A lightweight Python component that:\n",
    "- inputs a list of metric artifacts\n",
    "- create a `kfp.dsl.HTML` artifact\n",
    "- creates a `kfp.dsl.Markdown` artifact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f9d32d46-e46b-4587-a14a-d0fb9c3fd1f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@kfp.dsl.component(\n",
    "    base_image = \"python:3.11\",\n",
    "    packages_to_install = [\"pandas\", \"tabulate\"]\n",
    ")\n",
    "def overview(\n",
    "    metrics_0: kfp.dsl.Metrics,\n",
    "    metrics_1: kfp.dsl.Metrics,\n",
    "    metrics_2: kfp.dsl.Metrics,\n",
    "    metrics_3: kfp.dsl.Metrics,\n",
    "    models: list,\n",
    "    data: list\n",
    ") -> NamedTuple(\n",
    "        'output',\n",
    "        html=kfp.dsl.HTML,\n",
    "        md=kfp.dsl.Markdown\n",
    "):\n",
    "    from typing import NamedTuple\n",
    "    outputs = NamedTuple(\n",
    "            'output',\n",
    "            html=kfp.dsl.HTML,\n",
    "            md=kfp.dsl.Markdown\n",
    "    )\n",
    "    \n",
    "    # construct dataframe\n",
    "    import pandas as pd\n",
    "    metrics = [metrics_0.metadata, metrics_1.metadata, metrics_2.metadata, metrics_3.metadata]\n",
    "    records = []\n",
    "    for m, metric in enumerate(metrics):\n",
    "        records.append(\n",
    "            dict(\n",
    "                model = models[m],\n",
    "                data = data[m]\n",
    "            )|metrics[m]\n",
    "        )\n",
    "    df = pd.DataFrame(records)\n",
    " \n",
    "    import os\n",
    "    # html artifact\n",
    "    html = kfp.dsl.HTML(uri = kfp.dsl.get_uri('html.html'))\n",
    "    os.makedirs(os.path.dirname(html.path), exist_ok = True)\n",
    "    with open(html.path, 'w') as f:\n",
    "        f.write(df.to_html(index = False))\n",
    "    \n",
    "    \n",
    "    # markdown artifact\n",
    "    md = kfp.dsl.Markdown(uri = kfp.dsl.get_uri('md.md'))\n",
    "    os.makedirs(os.path.dirname(md.path), exist_ok = True)\n",
    "    with open(md.path, 'w') as f:\n",
    "        f.write(df.to_markdown(index = False))\n",
    "    \n",
    "    return outputs(html, md)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0852c793-0e93-42fa-84d1-69f3f70649c3",
   "metadata": {},
   "source": [
    "### Create Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c1eac05c-c30c-4c03-b920-deedd7370b8a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pipeline_name = f'{SERIES}-{EXPERIMENT}-artifacts'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "345982f0-6b4f-46e1-b4ed-186da73249c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@kfp.dsl.pipeline(\n",
    "    name = pipeline_name,\n",
    "    description = 'A simple pipeline for testing',\n",
    "    pipeline_root = f'gs://{GCS_BUCKET}/{SERIES}/{EXPERIMENT}/pipeline_root'\n",
    ")\n",
    "def pipeline(\n",
    "    project_id: str,\n",
    "    bq_project: str,\n",
    "    bq_dataset: str,\n",
    "    bq_table: str\n",
    "):\n",
    "    \n",
    "    bq_source = data_source(\n",
    "        bq_project = bq_project,\n",
    "        bq_dataset = bq_dataset,\n",
    "        bq_table = bq_table\n",
    "    )\n",
    "    train_data = data_prep(\n",
    "        project_id = project_id,\n",
    "        bq_source = bq_source.output\n",
    "    )\n",
    "    model_1 = model_gb(\n",
    "        train = train_data.outputs['train'],\n",
    "        features = train_data.outputs['features']\n",
    "    )\n",
    "    model_2 = model_rf(\n",
    "        train = train_data.outputs['train'],\n",
    "        features = train_data.outputs['features']\n",
    "    )\n",
    "    metrics_1_train = metrics(\n",
    "        data = train_data.outputs['train'],\n",
    "        features = train_data.outputs['features'],\n",
    "        model = model_1.output,\n",
    "    ).set_display_name('Metrics: Training Data')\n",
    "    metrics_1_test = metrics(\n",
    "        data = train_data.outputs['test'],\n",
    "        features = train_data.outputs['features'],\n",
    "        model = model_1.output,\n",
    "    ).set_display_name('Metrics: Test Data')\n",
    "    metrics_2_train = metrics(\n",
    "        data = train_data.outputs['train'],\n",
    "        features = train_data.outputs['features'],\n",
    "        model = model_2.output,\n",
    "    ).set_display_name('Metrics: Training Data')\n",
    "    metrics_2_test = metrics(\n",
    "        data = train_data.outputs['test'],\n",
    "        features = train_data.outputs['features'],\n",
    "        model = model_2.output,\n",
    "    ).set_display_name('Metrics: Test Data')\n",
    "    \n",
    "    review = overview(\n",
    "        metrics_0 = metrics_1_train.outputs['metrics'],\n",
    "        metrics_1 = metrics_1_test.outputs['metrics'],\n",
    "        metrics_2 = metrics_2_train.outputs['metrics'],\n",
    "        metrics_3 = metrics_2_test.outputs['metrics'],\n",
    "        models = ['GB', 'GB', 'RF', 'RF'],\n",
    "        data = ['Train', 'Test', 'Train', 'Test']\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f958f76a-52af-4c20-9870-e7bb77ce009a",
   "metadata": {},
   "source": [
    "### Compile Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "912ca1b6-daaf-4193-a9be-35d3a6d7187f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "kfp.compiler.Compiler().compile(\n",
    "    pipeline_func = pipeline,\n",
    "    package_path = f'{DIR}/{pipeline_name}.yaml'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2347d333-927e-4e55-b1fb-c4922e69e6f7",
   "metadata": {},
   "source": [
    "### Create Pipeline Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8bc66761-42ba-447b-b591-5f2df62de6f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "parameters = dict(\n",
    "    project_id = PROJECT_ID,\n",
    "    bq_project = 'bigquery-public-data',\n",
    "    bq_dataset = 'ml_datasets',\n",
    "    bq_table = 'penguins'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2226ceab-9a6e-4b42-9fd8-3cdb8ae1ddc7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pipeline_job = aiplatform.PipelineJob(\n",
    "    display_name = pipeline_name,\n",
    "    template_path = f\"{DIR}/{pipeline_name}.yaml\",\n",
    "    parameter_values = parameters,\n",
    "    pipeline_root = f'gs://{GCS_BUCKET}/{SERIES}/{EXPERIMENT}/pipeline_root',\n",
    "    enable_caching = None # True (enabled), False (disable), None (defer to component level caching) \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c28dcc-873f-47b1-a319-0524af4f59ce",
   "metadata": {},
   "source": [
    "### Submit Pipeline Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5d5eb4bf-7448-4d9c-a445-53418d2c029f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating PipelineJob\n",
      "PipelineJob created. Resource name: projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-io-artifacts-20250310160910\n",
      "To use this PipelineJob in another session:\n",
      "pipeline_job = aiplatform.PipelineJob.get('projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-io-artifacts-20250310160910')\n",
      "View Pipeline Job:\n",
      "https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/mlops-pipeline-io-artifacts-20250310160910?project=1026793852137\n"
     ]
    }
   ],
   "source": [
    "response = pipeline_job.submit(\n",
    "    service_account = SERVICE_ACCOUNT\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4dce19bb-c8bf-468a-b115-21410f5a800b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Dashboard can be viewed here:\n",
      "https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/mlops-pipeline-io-artifacts-20250310160910?project=1026793852137\n"
     ]
    }
   ],
   "source": [
    "print(f'The Dashboard can be viewed here:\\n{pipeline_job._dashboard_uri()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3234ae0b-d659-45fa-a436-638d234dcee6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PipelineJob projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-io-artifacts-20250310160910 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-io-artifacts-20250310160910 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-io-artifacts-20250310160910 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-io-artifacts-20250310160910 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-io-artifacts-20250310160910 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-io-artifacts-20250310160910 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob run completed. Resource name: projects/1026793852137/locations/us-central1/pipelineJobs/mlops-pipeline-io-artifacts-20250310160910\n"
     ]
    }
   ],
   "source": [
    "pipeline_job.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de9e00f-c93d-4c60-922d-1ecdf6d8ed3a",
   "metadata": {},
   "source": [
    "### Retrieve Pipeline Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "aa8ed08d-9bc7-4af3-877a-2e36bfc42094",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pipeline_name</th>\n",
       "      <th>run_name</th>\n",
       "      <th>param.vmlmd_lineage_integration</th>\n",
       "      <th>param.input:bq_project</th>\n",
       "      <th>param.vertex-ai-pipelines-artifact-argument-binding</th>\n",
       "      <th>param.input:bq_table</th>\n",
       "      <th>param.input:project_id</th>\n",
       "      <th>param.input:bq_dataset</th>\n",
       "      <th>metric.confusionMatrix</th>\n",
       "      <th>metric.accuracy</th>\n",
       "      <th>metric.recall</th>\n",
       "      <th>metric.f1</th>\n",
       "      <th>metric.precision</th>\n",
       "      <th>metric.average_precision</th>\n",
       "      <th>param.input:name</th>\n",
       "      <th>param.input:a_dict</th>\n",
       "      <th>param.input:uri</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mlops-pipeline-io-artifacts</td>\n",
       "      <td>mlops-pipeline-io-artifacts-20240609182055</td>\n",
       "      <td>{'pipeline_run_component': {'task_name': 'mlop...</td>\n",
       "      <td>bigquery-public-data</td>\n",
       "      <td>{'output:metrics-4-class_metrics': ['projects/...</td>\n",
       "      <td>penguins</td>\n",
       "      <td>statmike-mlops-349915</td>\n",
       "      <td>ml_datasets</td>\n",
       "      <td>{'rows': [{'row': [121.0, 1.0, 0.0]}, {'row': ...</td>\n",
       "      <td>0.953488</td>\n",
       "      <td>0.951111</td>\n",
       "      <td>0.952079</td>\n",
       "      <td>0.953472</td>\n",
       "      <td>0.980936</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mlops-pipeline-io-artifacts</td>\n",
       "      <td>mlops-pipeline-io-artifacts-20240609181626</td>\n",
       "      <td>{'pipeline_run_component': {'project_id': 'sta...</td>\n",
       "      <td>bigquery-public-data</td>\n",
       "      <td>{'output:metrics-metrics': ['projects/10267938...</td>\n",
       "      <td>penguins</td>\n",
       "      <td>statmike-mlops-349915</td>\n",
       "      <td>ml_datasets</td>\n",
       "      <td>{'annotationSpecs': [{'displayName': 'Adelie P...</td>\n",
       "      <td>0.996124</td>\n",
       "      <td>0.996416</td>\n",
       "      <td>0.996838</td>\n",
       "      <td>0.997290</td>\n",
       "      <td>0.999940</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mlops-pipeline-io-artifacts</td>\n",
       "      <td>mlops-pipeline-io-artifacts-20240609181110</td>\n",
       "      <td>{'pipeline_run_component': {'task_name': 'mlop...</td>\n",
       "      <td>bigquery-public-data</td>\n",
       "      <td>{'output:metrics-2-metrics': ['projects/102679...</td>\n",
       "      <td>penguins</td>\n",
       "      <td>statmike-mlops-349915</td>\n",
       "      <td>ml_datasets</td>\n",
       "      <td>{'annotationSpecs': [{'displayName': 'Adelie P...</td>\n",
       "      <td>0.996124</td>\n",
       "      <td>0.996416</td>\n",
       "      <td>0.996838</td>\n",
       "      <td>0.997290</td>\n",
       "      <td>0.999940</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mlops-pipeline-io-artifacts</td>\n",
       "      <td>mlops-pipeline-io-artifacts-20240609180134</td>\n",
       "      <td>{'pipeline_run_component': {'location_id': 'us...</td>\n",
       "      <td>bigquery-public-data</td>\n",
       "      <td>{'output:metrics-3-class_metrics': ['projects/...</td>\n",
       "      <td>penguins</td>\n",
       "      <td>statmike-mlops-349915</td>\n",
       "      <td>ml_datasets</td>\n",
       "      <td>{'annotationSpecs': [{'displayName': 'Adelie P...</td>\n",
       "      <td>0.953488</td>\n",
       "      <td>0.951111</td>\n",
       "      <td>0.952079</td>\n",
       "      <td>0.953472</td>\n",
       "      <td>0.980936</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mlops-pipeline-io-artifacts</td>\n",
       "      <td>mlops-pipeline-io-artifacts-20240609175742</td>\n",
       "      <td>{'pipeline_run_component': {'project_id': 'sta...</td>\n",
       "      <td>bigquery-public-data</td>\n",
       "      <td>{'output:metrics-2-metrics': ['projects/102679...</td>\n",
       "      <td>penguins</td>\n",
       "      <td>statmike-mlops-349915</td>\n",
       "      <td>ml_datasets</td>\n",
       "      <td>{'rows': [{'row': [121.0, 1.0, 0.0]}, {'row': ...</td>\n",
       "      <td>0.996124</td>\n",
       "      <td>0.996416</td>\n",
       "      <td>0.996838</td>\n",
       "      <td>0.997290</td>\n",
       "      <td>0.999940</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>mlops-pipeline-io-artifacts</td>\n",
       "      <td>mlops-pipeline-io-artifacts-20240609142244</td>\n",
       "      <td>{'pipeline_run_component': {'project_id': 'sta...</td>\n",
       "      <td>bigquery-public-data</td>\n",
       "      <td>{'output:metrics-class_metrics': ['projects/10...</td>\n",
       "      <td>penguins</td>\n",
       "      <td>statmike-mlops-349915</td>\n",
       "      <td>ml_datasets</td>\n",
       "      <td>{'rows': [{'row': [28.0, 1.0, 1.0]}, {'row': [...</td>\n",
       "      <td>0.953488</td>\n",
       "      <td>0.953692</td>\n",
       "      <td>0.952690</td>\n",
       "      <td>0.952112</td>\n",
       "      <td>0.992971</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>mlops-pipeline-io-artifacts</td>\n",
       "      <td>mlops-pipeline-io-artifacts-20240609141949</td>\n",
       "      <td>{'pipeline_run_component': {'pipeline_run_id':...</td>\n",
       "      <td>bigquery-public-data</td>\n",
       "      <td>{'output:metrics-2-metrics': ['projects/102679...</td>\n",
       "      <td>penguins</td>\n",
       "      <td>statmike-mlops-349915</td>\n",
       "      <td>ml_datasets</td>\n",
       "      <td>{'annotationSpecs': [{'displayName': 'Adelie P...</td>\n",
       "      <td>0.980620</td>\n",
       "      <td>0.970428</td>\n",
       "      <td>0.975578</td>\n",
       "      <td>0.981203</td>\n",
       "      <td>0.995643</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>mlops-pipeline-io-artifacts</td>\n",
       "      <td>mlops-pipeline-io-artifacts-20240609141654</td>\n",
       "      <td>{'pipeline_run_component': {'pipeline_run_id':...</td>\n",
       "      <td>bigquery-public-data</td>\n",
       "      <td>{'output:metrics-class_metrics': ['projects/10...</td>\n",
       "      <td>penguins</td>\n",
       "      <td>statmike-mlops-349915</td>\n",
       "      <td>ml_datasets</td>\n",
       "      <td>{'rows': [{'row': [28.0, 1.0, 1.0]}, {'row': [...</td>\n",
       "      <td>0.953488</td>\n",
       "      <td>0.951111</td>\n",
       "      <td>0.952079</td>\n",
       "      <td>0.953472</td>\n",
       "      <td>0.980936</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>mlops-pipeline-io-artifacts</td>\n",
       "      <td>mlops-pipeline-io-artifacts-20240609141307</td>\n",
       "      <td>{'pipeline_run_component': {'parent_task_names...</td>\n",
       "      <td>bigquery-public-data</td>\n",
       "      <td>{'output:metrics-3-class_metrics': ['projects/...</td>\n",
       "      <td>penguins</td>\n",
       "      <td>statmike-mlops-349915</td>\n",
       "      <td>ml_datasets</td>\n",
       "      <td>{'annotationSpecs': [{'displayName': 'Adelie P...</td>\n",
       "      <td>0.980620</td>\n",
       "      <td>0.970428</td>\n",
       "      <td>0.975578</td>\n",
       "      <td>0.981203</td>\n",
       "      <td>0.995643</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>mlops-pipeline-io-artifacts</td>\n",
       "      <td>mlops-pipeline-io-artifacts-20240609140521</td>\n",
       "      <td>{'pipeline_run_component': {'project_id': 'sta...</td>\n",
       "      <td>bigquery-public-data</td>\n",
       "      <td>{'output:metrics-4-class_metrics': ['projects/...</td>\n",
       "      <td>penguins</td>\n",
       "      <td>statmike-mlops-349915</td>\n",
       "      <td>ml_datasets</td>\n",
       "      <td>{'rows': [{'row': [121.0, 1.0, 0.0]}, {'row': ...</td>\n",
       "      <td>0.953488</td>\n",
       "      <td>0.951111</td>\n",
       "      <td>0.952079</td>\n",
       "      <td>0.953472</td>\n",
       "      <td>0.980936</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 pipeline_name                                    run_name  \\\n",
       "0  mlops-pipeline-io-artifacts  mlops-pipeline-io-artifacts-20240609182055   \n",
       "1  mlops-pipeline-io-artifacts  mlops-pipeline-io-artifacts-20240609181626   \n",
       "2  mlops-pipeline-io-artifacts  mlops-pipeline-io-artifacts-20240609181110   \n",
       "3  mlops-pipeline-io-artifacts  mlops-pipeline-io-artifacts-20240609180134   \n",
       "4  mlops-pipeline-io-artifacts  mlops-pipeline-io-artifacts-20240609175742   \n",
       "5  mlops-pipeline-io-artifacts  mlops-pipeline-io-artifacts-20240609142244   \n",
       "6  mlops-pipeline-io-artifacts  mlops-pipeline-io-artifacts-20240609141949   \n",
       "7  mlops-pipeline-io-artifacts  mlops-pipeline-io-artifacts-20240609141654   \n",
       "8  mlops-pipeline-io-artifacts  mlops-pipeline-io-artifacts-20240609141307   \n",
       "9  mlops-pipeline-io-artifacts  mlops-pipeline-io-artifacts-20240609140521   \n",
       "\n",
       "                     param.vmlmd_lineage_integration param.input:bq_project  \\\n",
       "0  {'pipeline_run_component': {'task_name': 'mlop...   bigquery-public-data   \n",
       "1  {'pipeline_run_component': {'project_id': 'sta...   bigquery-public-data   \n",
       "2  {'pipeline_run_component': {'task_name': 'mlop...   bigquery-public-data   \n",
       "3  {'pipeline_run_component': {'location_id': 'us...   bigquery-public-data   \n",
       "4  {'pipeline_run_component': {'project_id': 'sta...   bigquery-public-data   \n",
       "5  {'pipeline_run_component': {'project_id': 'sta...   bigquery-public-data   \n",
       "6  {'pipeline_run_component': {'pipeline_run_id':...   bigquery-public-data   \n",
       "7  {'pipeline_run_component': {'pipeline_run_id':...   bigquery-public-data   \n",
       "8  {'pipeline_run_component': {'parent_task_names...   bigquery-public-data   \n",
       "9  {'pipeline_run_component': {'project_id': 'sta...   bigquery-public-data   \n",
       "\n",
       "  param.vertex-ai-pipelines-artifact-argument-binding param.input:bq_table  \\\n",
       "0  {'output:metrics-4-class_metrics': ['projects/...              penguins   \n",
       "1  {'output:metrics-metrics': ['projects/10267938...              penguins   \n",
       "2  {'output:metrics-2-metrics': ['projects/102679...              penguins   \n",
       "3  {'output:metrics-3-class_metrics': ['projects/...              penguins   \n",
       "4  {'output:metrics-2-metrics': ['projects/102679...              penguins   \n",
       "5  {'output:metrics-class_metrics': ['projects/10...              penguins   \n",
       "6  {'output:metrics-2-metrics': ['projects/102679...              penguins   \n",
       "7  {'output:metrics-class_metrics': ['projects/10...              penguins   \n",
       "8  {'output:metrics-3-class_metrics': ['projects/...              penguins   \n",
       "9  {'output:metrics-4-class_metrics': ['projects/...              penguins   \n",
       "\n",
       "  param.input:project_id param.input:bq_dataset  \\\n",
       "0  statmike-mlops-349915            ml_datasets   \n",
       "1  statmike-mlops-349915            ml_datasets   \n",
       "2  statmike-mlops-349915            ml_datasets   \n",
       "3  statmike-mlops-349915            ml_datasets   \n",
       "4  statmike-mlops-349915            ml_datasets   \n",
       "5  statmike-mlops-349915            ml_datasets   \n",
       "6  statmike-mlops-349915            ml_datasets   \n",
       "7  statmike-mlops-349915            ml_datasets   \n",
       "8  statmike-mlops-349915            ml_datasets   \n",
       "9  statmike-mlops-349915            ml_datasets   \n",
       "\n",
       "                              metric.confusionMatrix  metric.accuracy  \\\n",
       "0  {'rows': [{'row': [121.0, 1.0, 0.0]}, {'row': ...         0.953488   \n",
       "1  {'annotationSpecs': [{'displayName': 'Adelie P...         0.996124   \n",
       "2  {'annotationSpecs': [{'displayName': 'Adelie P...         0.996124   \n",
       "3  {'annotationSpecs': [{'displayName': 'Adelie P...         0.953488   \n",
       "4  {'rows': [{'row': [121.0, 1.0, 0.0]}, {'row': ...         0.996124   \n",
       "5  {'rows': [{'row': [28.0, 1.0, 1.0]}, {'row': [...         0.953488   \n",
       "6  {'annotationSpecs': [{'displayName': 'Adelie P...         0.980620   \n",
       "7  {'rows': [{'row': [28.0, 1.0, 1.0]}, {'row': [...         0.953488   \n",
       "8  {'annotationSpecs': [{'displayName': 'Adelie P...         0.980620   \n",
       "9  {'rows': [{'row': [121.0, 1.0, 0.0]}, {'row': ...         0.953488   \n",
       "\n",
       "   metric.recall  metric.f1  metric.precision  metric.average_precision  \\\n",
       "0       0.951111   0.952079          0.953472                  0.980936   \n",
       "1       0.996416   0.996838          0.997290                  0.999940   \n",
       "2       0.996416   0.996838          0.997290                  0.999940   \n",
       "3       0.951111   0.952079          0.953472                  0.980936   \n",
       "4       0.996416   0.996838          0.997290                  0.999940   \n",
       "5       0.953692   0.952690          0.952112                  0.992971   \n",
       "6       0.970428   0.975578          0.981203                  0.995643   \n",
       "7       0.951111   0.952079          0.953472                  0.980936   \n",
       "8       0.970428   0.975578          0.981203                  0.995643   \n",
       "9       0.951111   0.952079          0.953472                  0.980936   \n",
       "\n",
       "  param.input:name param.input:a_dict param.input:uri  \n",
       "0              NaN                NaN             NaN  \n",
       "1              NaN                NaN             NaN  \n",
       "2              NaN                NaN             NaN  \n",
       "3              NaN                NaN             NaN  \n",
       "4              NaN                NaN             NaN  \n",
       "5              NaN                NaN             NaN  \n",
       "6              NaN                NaN             NaN  \n",
       "7              NaN                NaN             NaN  \n",
       "8              NaN                NaN             NaN  \n",
       "9              NaN                NaN             NaN  "
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aiplatform.get_pipeline_df(pipeline = f'{pipeline_name}')[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f39428d5-edb9-4adb-ac95-a4b94e39afba",
   "metadata": {},
   "source": [
    "### Visual Review of Pipeline Information\n",
    "\n",
    "**Pipeline Overview With Artifacts:**\n",
    "<p><center>\n",
    "    <img src=\"../resources/images/screenshots/pipelines/io/artifact-overview.png\" width=\"75%\">\n",
    "</center><p>\n",
    "    \n",
    "**BigQuery Table Artifact (`google.BQTable`):**\n",
    "<p><center>\n",
    "    <img src=\"../resources/images/screenshots/pipelines/io/artifact-bqtable.png\" width=\"75%\">\n",
    "</center><p>\n",
    "    \n",
    "**KFP Artifact from `kfp.dsl.Artifact` (`system.Artifact`):**\n",
    "<p><center>\n",
    "    <img src=\"../resources/images/screenshots/pipelines/io/artifact-generic.png\" width=\"75%\">\n",
    "</center><p>\n",
    "    \n",
    "**KFP Artifact from `kfp.dsl.Dataset` (`system.Dataset`):**\n",
    "<p><center>\n",
    "    <img src=\"../resources/images/screenshots/pipelines/io/artifact-dataset.png\" width=\"75%\">\n",
    "</center><p>\n",
    "    \n",
    "**KFP Artifact from `kfp.dsl.Model` (`system.Model`):**\n",
    "<p><center>\n",
    "    <img src=\"../resources/images/screenshots/pipelines/io/artifact-model.png\" width=\"75%\">\n",
    "</center><p>\n",
    "    \n",
    "**KFP Artifact from `kfp.dsl.Metrics` (`system.Metrics`):**\n",
    "<p><center>\n",
    "    <img src=\"../resources/images/screenshots/pipelines/io/artifact-metrics.png\" width=\"75%\">\n",
    "</center><p>\n",
    "    \n",
    "**KFP Artifact from `kfp.dsl.ClassificationMetrics` (`system.ClassificationMetrics`):**\n",
    "<p><center>\n",
    "    <img src=\"../resources/images/screenshots/pipelines/io/artifact-classmetrics.png\" width=\"75%\">\n",
    "</center><p>\n",
    "    \n",
    "**KFP Artifact from `kfp.dsl.HTML` (`system.HTML`):**\n",
    "<p><center>\n",
    "    <img src=\"../resources/images/screenshots/pipelines/io/artifact-html.png\" width=\"75%\">\n",
    "</center><p>\n",
    "    \n",
    "**KFP Artifact from `kfp.dsl.Markdown` (`system.Markdown`):**\n",
    "<p><center>\n",
    "    <img src=\"../resources/images/screenshots/pipelines/io/artifact-markdown.png\" width=\"75%\">\n",
    "</center><p>    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b47d768a-af53-4f62-b221-8109c810f0bb",
   "metadata": {},
   "source": [
    "---\n",
    "## Artifacts: Vertex AI ML Metadata\n",
    "\n",
    "\n",
    "Pipeline jobs are runs of a pipeline.  These jobs are made of tasks, the running of a commponent.  And some tasks consume and/or produce artifacts.  These artifacts are automatically stored in [Vertex AI ML Metadata](https://cloud.google.com/vertex-ai/docs/ml-metadata/introduction).  This system tracks lineage of the ML artifacts to understand changes over time and the downstream usage of these artifacts.\n",
    "\n",
    "This section will cover the retrieval of Artifact metadata."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d26fb7-fdfc-459e-8f8d-526d3c08855f",
   "metadata": {},
   "source": [
    "#### Retrieve Artifact Info From `PipelineJob`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e8aa90c4-4114-4292-b1f3-3129613dd528",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'vmlmd_lineage_integration': {'pipeline_run_component': {'location_id': 'us-central1',\n",
       "   'parent_task_names': ['mlops-pipeline-io-artifacts-20250310160910'],\n",
       "   'pipeline_run_id': 'mlops-pipeline-io-artifacts-20250310160910',\n",
       "   'task_name': 'metrics-4',\n",
       "   'project_id': 'statmike-mlops-349915'}},\n",
       " 'vertex-ai-pipelines-artifact-argument-binding': {'output:class_metrics': ['projects/1026793852137/locations/us-central1/metadataStores/default/artifacts/7705072623014439488'],\n",
       "  'input:model': ['projects/1026793852137/locations/us-central1/metadataStores/default/artifacts/16501065068696233238'],\n",
       "  'input:features': ['projects/1026793852137/locations/us-central1/metadataStores/default/artifacts/1263228497508632990'],\n",
       "  'output:metrics': ['projects/1026793852137/locations/us-central1/metadataStores/default/artifacts/17701935695847583126'],\n",
       "  'input:data': ['projects/1026793852137/locations/us-central1/metadataStores/default/artifacts/6803969787790414499']}}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for a specific component\n",
    "pipeline_job.to_dict()['jobDetail']['taskDetails'][3]['execution']['metadata']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "bf7b3839-8690-4b41-ae5d-8ab46c015b28",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'output:class_metrics': ['projects/1026793852137/locations/us-central1/metadataStores/default/artifacts/7705072623014439488'],\n",
       " 'input:model': ['projects/1026793852137/locations/us-central1/metadataStores/default/artifacts/16501065068696233238'],\n",
       " 'input:features': ['projects/1026793852137/locations/us-central1/metadataStores/default/artifacts/1263228497508632990'],\n",
       " 'output:metrics': ['projects/1026793852137/locations/us-central1/metadataStores/default/artifacts/17701935695847583126'],\n",
       " 'input:data': ['projects/1026793852137/locations/us-central1/metadataStores/default/artifacts/6803969787790414499']}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# artifacts from the component\n",
    "artifact_id = pipeline_job.to_dict()['jobDetail']['taskDetails'][3]['execution']['metadata']['vertex-ai-pipelines-artifact-argument-binding']#['output:Output'][0]\n",
    "artifact_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "0c78cf53-c5f2-4281-b4fc-7eae58b30d37",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "artifact = aiplatform.Artifact.get(resource_id = artifact_id['input:model'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f7c6e554-b3cf-42be-b0c9-973e54790b88",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<google.cloud.aiplatform.metadata.artifact.Artifact object at 0x7f126b1783d0> \n",
       "resource name: projects/1026793852137/locations/us-central1/metadataStores/default/artifacts/16501065068696233238\n",
       "uri: gs://statmike-mlops-349915/mlops/pipeline-io/pipeline_root/1026793852137/mlops-pipeline-io-artifacts-20250310160910/model-rf_-7502397985880276992/Output\n",
       "schema_title:system.Model"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artifact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "cd4e71c4-d245-4988-9ed0-17cbc33778d7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gs://statmike-mlops-349915/mlops/pipeline-io/pipeline_root/1026793852137/mlops-pipeline-io-artifacts-20250310160910/model-rf_-7502397985880276992/Output'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artifact.uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f7cfebf1-76fc-41bc-9b88-adf46c8d265d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.9767441860465116}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artifact.metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "db4bbaa8-310e-477f-a950-f4f9104fcc3b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Output'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artifact.display_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "5b70c004-13f9-472d-a575-f5d3ae6b0911",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://console.cloud.google.com/vertex-ai/locations/us-central1/metadata-stores/default/artifacts/16501065068696233238?project=statmike-mlops-349915'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artifact.lineage_console_uri"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dac6e89-159a-4c05-8f92-002183e5ef89",
   "metadata": {},
   "source": [
    "**Vertex AI Console ML Metadata Review:**\n",
    "<p><center>\n",
    "    <img src=\"../resources/images/screenshots/pipelines/io/artifact-metadata.png\" width=\"75%\">\n",
    "</center><p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc257bfc-630d-4358-bba2-9ed5bd7ef1e5",
   "metadata": {},
   "source": [
    "#### Retrieve Pipeline Artifacts Vertex AI SDK\n",
    "\n",
    "- [`aiplatform.Artifact()`](https://cloud.google.com/python/docs/reference/aiplatform/latest/google.cloud.aiplatform.Artifact)\n",
    "- An [Overview of the filter syntax](https://cloud.google.com/vertex-ai/docs/ml-metadata/analyzing#filters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "f53c8ba1-e934-4c3a-9b6b-b7ea59afa5aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "artifacts = aiplatform.Artifact.list(\n",
    "    filter = \"display_name=\\\"Output\\\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "6dd0b2a5-89f7-4511-8f5e-1df0ff3d6787",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "269"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(artifacts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "f40f1d68-5499-40a2-afbe-8bec07d3180d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "artifacts = aiplatform.Artifact.list(\n",
    "    filter = \"display_name=\\\"Output\\\" AND create_time>\\\"2024-05-19\\\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "7ff00f9e-1832-40ad-947c-05990175c442",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "248"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(artifacts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "d8a79e5b-dbdd-42d4-a592-f6a5ba4bfc71",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<google.cloud.aiplatform.metadata.artifact.Artifact object at 0x7f126b0b4460> \n",
       "resource name: projects/1026793852137/locations/us-central1/metadataStores/default/artifacts/16501065068696233238\n",
       "uri: gs://statmike-mlops-349915/mlops/pipeline-io/pipeline_root/1026793852137/mlops-pipeline-io-artifacts-20250310160910/model-rf_-7502397985880276992/Output\n",
       "schema_title:system.Model"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artifacts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "624377de-8ee4-414b-bf37-9de013ed72f1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "google.cloud.aiplatform.metadata.artifact.Artifact"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(artifacts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "f3b20195-e01e-4fda-a77a-d3df7539ed9f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.9767441860465116}"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artifacts[0].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "690a1711-a9dd-4a62-ab62-20fd8376b8ce",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://console.cloud.google.com/vertex-ai/locations/us-central1/metadata-stores/default/artifacts/16501065068696233238?project=1026793852137'"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artifacts[0].lineage_console_uri"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b46db90-865a-4391-8ff8-810f12875e14",
   "metadata": {},
   "source": [
    "#### Query Artifacts: Model with Accuracy > 0.987"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "f28df188-ddd6-45e3-955d-5346e8562682",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "artifacts = aiplatform.Artifact.list(\n",
    "    filter = \"schema_title=\\\"system.Model\\\" AND metadata.accuracy.number_value>0.987\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "ce77bb31-ae6e-4911-915a-0dac82e7585b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<google.cloud.aiplatform.metadata.artifact.Artifact object at 0x7f129133ab90> \n",
       " resource name: projects/1026793852137/locations/us-central1/metadataStores/default/artifacts/12955947915489551239\n",
       " uri: gs://statmike-mlops-349915/mlops/pipeline-io/pipeline_root/1026793852137/mlops-pipeline-io-artifacts-20250310160910/model-gb_1720974050974498816/Output\n",
       " schema_title:system.Model,\n",
       " <google.cloud.aiplatform.metadata.artifact.Artifact object at 0x7f129133a950> \n",
       " resource name: projects/1026793852137/locations/us-central1/metadataStores/default/artifacts/6009253201450768239\n",
       " uri: gs://statmike-mlops-349915/mlops/pipeline-pattern-modular/pipeline_root/1026793852137/mlops-pipeline-pattern-modular-example-2-20240801170641/model-gb_5056559624300265472/Output\n",
       " schema_title:system.Model,\n",
       " <google.cloud.aiplatform.metadata.artifact.Artifact object at 0x7f129133aef0> \n",
       " resource name: projects/1026793852137/locations/us-central1/metadataStores/default/artifacts/4851358657665890425\n",
       " uri: gs://statmike-mlops-349915/mlops/pipeline-pattern-modular/pipeline_root/1026793852137/mlops-pipeline-pattern-modular-preview-20240801142330/model-gb_135666746886455296/Output\n",
       " schema_title:system.Model,\n",
       " <google.cloud.aiplatform.metadata.artifact.Artifact object at 0x7f129133b310> \n",
       " resource name: projects/1026793852137/locations/us-central1/metadataStores/default/artifacts/5441132600420380970\n",
       " uri: gs://statmike-mlops-349915/mlops/pipeline-pattern-modular/pipeline_root/1026793852137/mlops-pipeline-pattern-modular-preview-20240801123852/model-gb_4674591483834138624/Output\n",
       " schema_title:system.Model,\n",
       " <google.cloud.aiplatform.metadata.artifact.Artifact object at 0x7f129133b430> \n",
       " resource name: projects/1026793852137/locations/us-central1/metadataStores/default/artifacts/6882445020641204841\n",
       " uri: gs://statmike-mlops-349915/mlops/pipeline-io/pipeline_root/1026793852137/mlops-pipeline-io-artifacts-20240517210244/model-gb_1158353435645444096/Output\n",
       " schema_title:system.Model,\n",
       " <google.cloud.aiplatform.metadata.artifact.Artifact object at 0x7f129133b640> \n",
       " resource name: projects/1026793852137/locations/us-central1/metadataStores/default/artifacts/8280931390702315684\n",
       " uri: gs://statmike-mlops-349915/mlops/pipeline-io/pipeline_root/1026793852137/mlops-pipeline-io-artifacts-20240517152923/model-gb_-8736969739361845248/Output\n",
       " schema_title:system.Model]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "790ccf64-776a-47c2-96c2-fd1f2fd320c7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'projects/1026793852137/locations/us-central1/metadataStores/default/artifacts/12955947915489551239',\n",
       " 'displayName': 'Output',\n",
       " 'uri': 'gs://statmike-mlops-349915/mlops/pipeline-io/pipeline_root/1026793852137/mlops-pipeline-io-artifacts-20250310160910/model-gb_1720974050974498816/Output',\n",
       " 'etag': '1741623241969',\n",
       " 'createTime': '2025-03-10T16:13:00.236Z',\n",
       " 'updateTime': '2025-03-10T16:14:01.969Z',\n",
       " 'state': 'LIVE',\n",
       " 'schemaTitle': 'system.Model',\n",
       " 'schemaVersion': '0.0.1',\n",
       " 'metadata': {'accuracy': 0.9961240310077519}}"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artifacts[0].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fcce696-2158-48a8-9c25-11b70e1426b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58effcc-bcdf-4a1b-8181-61769a21d85d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m128",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m128"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
