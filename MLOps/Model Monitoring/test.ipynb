{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![tracker](https://us-central1-vertex-ai-mlops-369716.cloudfunctions.net/pixel-tracking?path=statmike%2Fvertex-ai-mlops%2FMLOps%2FModel+Monitoring&file=bqml-model-monitoring-tutorial.ipynb)\n",
    "<!--- header table --->\n",
    "<table align=\"left\">\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://colab.research.google.com/github/statmike/vertex-ai-mlops/blob/main/MLOps/Model%20Monitoring/bqml-model-monitoring-tutorial.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Google Colaboratory logo\">\n",
    "      <br>Run in<br>Colab\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/colab/import/https%3A%2F%2Fraw.githubusercontent.com%2Fstatmike%2Fvertex-ai-mlops%2Fmain%2FMLOps%2FModel%2520Monitoring%2Fbqml-model-monitoring-tutorial.ipynb\">\n",
    "      <img width=\"32px\" src=\"https://lh3.googleusercontent.com/JmcxdQi-qOpctIvWKgPtrzZdJJK-J3sWE1RsfjZNwshCFgE_9fULcNpuXYTilIR2hjwN\" alt=\"Google Cloud Colab Enterprise logo\">\n",
    "      <br>Run in<br>Colab Enterprise\n",
    "    </a>\n",
    "  </td>      \n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://github.com/statmike/vertex-ai-mlops/blob/main/MLOps/Model%20Monitoring/bqml-model-monitoring-tutorial.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\">\n",
    "      <br>View on<br>GitHub\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/statmike/vertex-ai-mlops/main/MLOps/Model%20Monitoring/bqml-model-monitoring-tutorial.ipynb\">\n",
    "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\">\n",
    "      <br>Open in<br>Vertex AI Workbench\n",
    "    </a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jwgBsT4ZeFWn"
   },
   "source": [
    "# BigQuery ML (BQML) - Model Monitoring Tutorial \n",
    "---\n",
    "**UPDATES:**\n",
    "- **Now With Vertex AI Model Monitoring Integration For [Monitoring visualization](https://cloud.google.com/bigquery/docs/model-monitoring-overview#monitoring_visualization)** - March 2025\n",
    "---\n",
    "\n",
    "This notebook provides an in-depth look at model monitoring with BigQuery ML that accompanies the [blog announcing these features](https://cloud.google.com/blog/products/data-analytics/monitor-ml-model-skew-and-drift-in-bigquery). It complements the introductory notebook, ['BigQuery ML (BQML) - Model Monitoring Introduction'](./bqml-model-monitoring-introduction.ipynb), and delves deeper into various monitoring techniques and tools.\n",
    "\n",
    "**Key Areas Covered:**\n",
    "\n",
    "* **Data Preparation and Understanding:**\n",
    "    * Employing `ML.DESCRIBE_DATA` to analyze feature distributions and identify potential data quality issues.\n",
    "    * Splitting data into training, evaluation, and test sets while preserving data balance.\n",
    "* **Model Training and Evaluation:**\n",
    "    * Training a random forest model using `CREATE MODEL` with the `TRANSFORM` clause for incorporating feature engineering.\n",
    "    * Evaluating model performance using `ML.EVALUATE` and `ML.CONFUSION_MATRIX` on different data splits.\n",
    "* **Model Serving and Data Drift Simulation:**\n",
    "    * Generating predictions with `ML.PREDICT` and simulating data drift over time to represent real-world scenarios.\n",
    "* **Model Monitoring Techniques:**\n",
    "    * Implementing `ML.VALIDATE_DATA_SKEW` to detect changes between training and serving data distributions.\n",
    "    * Using `ML.VALIDATE_DATA_DRIFT` to identify gradual shifts in the serving data distribution over time.\n",
    "    * Understanding the metrics used for monitoring: L-infinity distance and Jensen-Shannon divergence.\n",
    "* **TensorFlow Data Validation (TFDV) Integration:**\n",
    "    * Leveraging `ML.TFDV_DESCRIBE` and `ML.TFDV_VALIDATE` to generate descriptive statistics and detect anomalies.\n",
    "    * Visualizing feature distributions using `tfdv.visualize_statistics` for comparative analysis.\n",
    "* **Monitoring Feature Attributions and Drift:**\n",
    "    * Employing `ML.EXPLAIN_PREDICT` to obtain feature attributions and understand feature importance for predictions.\n",
    "    * Monitoring drift in feature attributions over time to gain insights into model behavior changes. \n",
    "* **Continuous Monitoring and Automation:**\n",
    "    * Building a BigQuery SQL job using procedural language to automate skew and drift detection.\n",
    "    * Incorporating alerting mechanisms and model retraining when anomalies are detected.\n",
    "    * Discussing options for automating monitoring jobs:\n",
    "        * BigQuery Scheduled Queries\n",
    "        * Dataform\n",
    "        * Workflows\n",
    "        * Cloud Composer\n",
    "        * Vertex AI Pipelines\n",
    "* **Model Monitoring for Online Inference with Vertex AI:**\n",
    "    * Deploying the trained BigQuery ML model to Vertex AI for online predictions. \n",
    "    * Enabling request-response logging to BigQuery for continuous monitoring of online predictions.\n",
    "\n",
    "**Target Audience:**\n",
    "\n",
    "This tutorial is designed for data scientists, machine learning engineers, and individuals with a basic understanding of BigQuery, SQL, and machine learning concepts who want to delve deeper into model monitoring with BigQuery ML. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J_-1oCZ7oQe_"
   },
   "source": [
    "---\n",
    "## Colab Setup\n",
    "\n",
    "When running this notebook in [Colab](https://colab.google/) or [Colab Enterprise](https://cloud.google.com/colab/docs/introduction), this section will authenticate to GCP (follow prompts in the popup) and set the current project for the session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 178,
     "status": "ok",
     "timestamp": 1710716382256,
     "user": {
      "displayName": "Mike Henderson",
      "userId": "07691629187611687318"
     },
     "user_tz": 240
    },
    "id": "bUeb3Vz9c-cz",
    "tags": []
   },
   "outputs": [],
   "source": [
    "PROJECT_ID = 'statmike-mlops-349915' # replace with project ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1769,
     "status": "ok",
     "timestamp": 1710716384851,
     "user": {
      "displayName": "Mike Henderson",
      "userId": "07691629187611687318"
     },
     "user_tz": 240
    },
    "id": "ztC0h14fc-fr",
    "outputId": "16d1144f-1671-4919-edba-31bc197ffc7b",
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    from google.colab import auth\n",
    "    auth.authenticate_user(project_id = PROJECT_ID)\n",
    "    print('Colab authorized to GCP')\n",
    "except Exception:\n",
    "    print('Not a Colab Environment')\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Installs\n",
    "\n",
    "The list `packages` contains tuples of package import names and install names.  If the import name is not found then the install name is used to install quitely for the current user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# tuples of (import name, install name, min_version)\n",
    "packages = [\n",
    "    ('tensorflow_data_validation', 'tensorflow-data-validation'),\n",
    "    ('tensorflow_metadata', 'tensorflow-metadata'),\n",
    "    ('google.cloud.aiplatform', 'google-cloud-aiplatform'),\n",
    "    ('google.cloud.bigquery', 'google-cloud-bigquery'),\n",
    "    ('google.cloud.bigquery_datatransfer', 'google-cloud-bigquery-datatransfer'),\n",
    "    ('numpy', 'numpy'),\n",
    "    ('pandas', 'pandas')\n",
    "]\n",
    "\n",
    "import importlib\n",
    "install = False\n",
    "for package in packages:\n",
    "    if not importlib.util.find_spec(package[0]):\n",
    "        print(f'installing package {package[1]}')\n",
    "        install = True\n",
    "        !pip install {package[1]} -U -q --user\n",
    "    elif len(package) == 3:\n",
    "        if importlib.metadata.version(package[0]) < package[2]:\n",
    "            print(f'updating package {package[1]}')\n",
    "            install = True\n",
    "            !pip install {package[1]} -U -q --user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### API Enablement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!gcloud services enable aiplatform.googleapis.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Restart Kernel (If Installs Occured)\n",
    "After a kernel restart the code submission can start with the next cell after this one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if install:\n",
    "    import IPython\n",
    "    app = IPython.Application.instance()\n",
    "    app.kernel.do_shutdown(True)\n",
    "    IPython.display.display(IPython.display.Markdown(\"\"\"<div class=\\\"alert alert-block alert-warning\\\">\n",
    "        <b>⚠️ The kernel is going to restart. Please wait until it is finished before continuing to the next step. The previous cells do not need to be run again⚠️</b>\n",
    "        </div>\"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yt5uZFvRoWLp"
   },
   "source": [
    "---\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "from IPython.display import Image, display, HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clients:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 159,
     "status": "ok",
     "timestamp": 1710716582376,
     "user": {
      "displayName": "Mike Henderson",
      "userId": "07691629187611687318"
     },
     "user_tz": 240
    },
    "id": "14nUE43Oc-ip",
    "outputId": "55b2c2b1-b6ad-42cc-b3cc-d6e3afcaa071",
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext google.cloud.bigquery"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare the code below for your environment.\n",
    "\n",
    "This notebook takes advantage of the [BigQuery IPython magic](https://cloud.google.com/python/docs/reference/bigquery/latest/magics) for legibility and ease of copy/pasting to BigQuery SQL editor.  If this notebook is being used from an environment that can run notebooks it needs further preparation: Colab, Colab Enterprise, Vertex AI Workbench Instances, or BigQuery Studio with a Python Notebook.  The SQL code in these cells uses the fully qualified [BigQuery table](https://cloud.google.com/bigquery/docs/tables-intro) names in the form `projectname.datasetname.tablename`.  Prepare for your environment by:\n",
    "- Edit > Find\n",
    "    - Find: `statmike-mlops-349915`\n",
    "    - Replace: `<your project id>`\n",
    "    - Replace All"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## BigQuery Source Data\n",
    "\n",
    "This project will uses the following data source as a tutorial.  It is good for examples like this because it is small, has few columns, but contains categorial and numerical data types.\n",
    "\n",
    "The source table is a BigQuery Public Dataset table.  The following cell uses the [BigQuery IPython magic](https://cloud.google.com/python/docs/reference/bigquery/latest/magics) to retrieve 5 rows of the table for review.  This data is known as [Palmer Penguins](https://allisonhorst.github.io/palmerpenguins/) data: \n",
    "\n",
    "```\n",
    "@Manual{,\n",
    "  title = {palmerpenguins: Palmer Archipelago (Antarctica) penguin data},\n",
    "  author = {Allison Marie Horst and Alison Presmanes Hill and Kristen B Gorman},\n",
    "  year = {2020},\n",
    "  note = {R package version 0.1.0},\n",
    "  doi = {10.5281/zenodo.3960218},\n",
    "  url = {https://allisonhorst.github.io/palmerpenguins/},\n",
    "}\n",
    "```\n",
    "\n",
    "\n",
    "There are 334 observations of 4 numerical features (culman length, culmen depth, flipper length, body mass) and 2  categorical features (island, sex) that represent 3 species of penguins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bigquery\n",
    "SELECT *\n",
    "FROM `bigquery-public-data.ml_datasets.penguins`\n",
    "LIMIT 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## **Goal: Train, Serve, And Monitor A Model**\n",
    "\n",
    "**Train A Model**\n",
    "\n",
    "In this workflow our goal is to train and operationalize a machine leanring model that can classify unidentified penguins into the correct `species` using only measurements (`culmen_length_mm`, `culmen_depth_mm`, `flipper_length_mm`, `body_mass_g`), location (`island`) and gender (`sex`).  That means serving predictions, monitoring features, and potentially retraining the model.\n",
    "\n",
    "**Operationalize The Model**\n",
    "\n",
    "Taking a trained model to production introduces challenges. The model needs to be regularly evaluated to understand it's performance once put into production. This can be challenging as actual values used to assess the accuracy of predictions may arrive later than the predictions. Continuous monitoring bridges this gap with early signals in two key ways. First, monitoring the distributions of each of the models features for shift (called **skew**) from the training data to the current data. Then, also monitoring for any gradual **drift** in the distribution over time. Setting thresholds and getting alerts for features on each of this distribution changes gives early signals that the model needs to be carefully considered for evaluation and re-training to ensure effectiveness. If the evaluation can be automated then this can even extend to **continuous training**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Understand The Data Source With `ML.DESCRIBE_DATA`\n",
    "\n",
    "Reviewing a few records, like above, gives a good sense of how the data is arranged. Before proceeding with machine learning techniques it is important to understand more about these raw columns.  Are they ready to use a features in a model or is some form of feature engineering needed first?  For this, the distribution of values is an important starting point.  \n",
    "\n",
    "While SQL could be used to look at the distribution, it would be a time consuming process and requires different techniques for different data types like numerical, string, boolean, dates, times, array and struct version of these, and arrays of structs.\n",
    "\n",
    "To make this process fast and simple, the new [`ML.DESCRIBE_DATA`](https://cloud.google.com/bigquery/docs/reference/standard-sql/bigqueryml-syntax-describe-data)\n",
    "\n",
    "function is used to get a single row for each column the describes the data distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bigquery\n",
    "SELECT *\n",
    "FROM ML.DESCRIBE_DATA(\n",
    "  TABLE `bigquery-public-data.ml_datasets.penguins`\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some observations:\n",
    "- All columns have `num_rows` and `num_nulls`\n",
    "- Numerical columns have `min`, `max`, `stddev`, `median`, and `quantiles` showing the distribution of the data in the column\n",
    "- Categorical (string) columns have `min`, `max` values representing the class levels and a `unique` column show how many class levels\n",
    "\n",
    "Data quality observation:\n",
    "- The column `sex` has both missing values (10 indicated in `num_nulls`) as well as a `min` values of `.`.  This appears to be a data quality issue that needs fixing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Create A BigQuery Dataset\n",
    "\n",
    "Create a new [BigQuery Dataset](https://cloud.google.com/bigquery/docs/datasets) as a working location for this workflow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bigquery\n",
    "CREATE SCHEMA IF NOT EXISTS `statmike-mlops-349915.bqml_model_monitoring`\n",
    "    OPTIONS(\n",
    "        location = 'US'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare The Source Data\n",
    "\n",
    "Make a copy of the table source in the new BigQuery dataset with fixes applied to the data quality issue identified for the `sex` column with values of `.`.\n",
    "\n",
    "> Note: A copy is being made in this case because the source project is `bigquery-public` which is not editable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bigquery\n",
    "CREATE OR REPLACE TABLE `statmike-mlops-349915.bqml_model_monitoring.training` AS\n",
    "    SELECT * EXCEPT(sex),\n",
    "        CASE WHEN sex = '.' THEN NULL ELSE sex END AS sex\n",
    "    FROM `bigquery-public-data.ml_datasets.penguins`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split The Data\n",
    "\n",
    "Depending on the ML technique, it may be desired to split the data into partitions for training, evaluation, and testing (in this case monitoring examples). \n",
    "\n",
    "The following cell creates a version with a new column column named `splits` with values [`TRAIN`, `EVAL`, `TEST`].  The data is first grouped (stratified) by the values of `species` and `island` to preserve any imbalance across the groups. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bigquery\n",
    "CREATE OR REPLACE TABLE `statmike-mlops-349915.bqml_model_monitoring.training_split` AS\n",
    "    WITH\n",
    "        # randomized numbering within groups (species, island)\n",
    "        RANDOM AS (\n",
    "            SELECT *,\n",
    "                ROW_NUMBER() OVER (PARTITION BY species, island ORDER BY RAND()) AS sequence\n",
    "            FROM `statmike-mlops-349915.bqml_model_monitoring.training`\n",
    "        ),\n",
    "        # get group sizes\n",
    "        GROUP_SIZES AS (\n",
    "            SELECT species, island, COUNT(*) AS count\n",
    "            FROM `statmike-mlops-349915.bqml_model_monitoring.training`\n",
    "            GROUP BY species, island\n",
    "        )\n",
    "    SELECT\n",
    "        * EXCEPT(sequence, count),\n",
    "        CASE\n",
    "            WHEN sequence <= CEIL(.2 * count) AND species is not Null THEN 'TEST'\n",
    "            WHEN sequence <= CEIL(.3 * count) THEN 'EVAL'\n",
    "            ELSE 'TRAIN'\n",
    "        END AS splits\n",
    "    FROM RANDOM\n",
    "    LEFT OUTER JOIN GROUP_SIZES USING(species, island)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Review the data by `splits`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bigquery\n",
    "SELECT species, island,\n",
    "    COUNT(*) as count,\n",
    "    100 * COUNTIF(splits = 'TRAIN')/COUNT(*) AS TRAIN_PCT,\n",
    "    100 * COUNTIF(splits = 'EVAL')/COUNT(*) AS EVAL_PCT,\n",
    "    100 * COUNTIF(splits = 'TEST')/COUNT(*) AS TEST_PCT\n",
    "FROM `statmike-mlops-349915.bqml_model_monitoring.training_split`\n",
    "GROUP BY species, island"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review the Training Split With: `ML.DESCRIBE_DATA`\n",
    "\n",
    "Use [`ML.DESCRIBE_DATA`](https://cloud.google.com/bigquery/docs/reference/standard-sql/bigqueryml-syntax-describe-data) to first review the training split of the source data.  This time, some of the additional parameters of the function are useful:\n",
    "- `top_k`: get the top 3 most frequent categories for string columns (default = 1)\n",
    "- `num_quantiles`: get 4 quantiles for numerical columns (default = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bigquery\n",
    "SELECT *\n",
    "FROM ML.DESCRIBE_DATA(\n",
    "    (\n",
    "        SELECT * EXCEPT(splits)\n",
    "        FROM `statmike-mlops-349915.bqml_model_monitoring.training_split`\n",
    "        WHERE splits = 'TRAIN'\n",
    "    ),\n",
    "    STRUCT(3 AS top_k, 4 AS num_quantiles)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "## Model Training\n",
    "\n",
    "Create a model trained to classify `species` for the traning records.  Here, directly in BigQuery, the [`CREATE MODEL` statement for random forest](https://cloud.google.com/bigquery/docs/reference/standard-sql/bigqueryml-syntax-create-random-forest) is used.  This uses the `TRANSFORM` clause within the model to embed user specified transfomations within the model for use during serving and model monitoring which will both be show later in this introduction.\n",
    "\n",
    "From reviewing the training data above, the following transformations will be tried:\n",
    "- Apply [`ML.ROBUST_SCALER`](https://cloud.google.com/bigquery/docs/reference/standard-sql/bigqueryml-syntax-robust-scaler) to `body_mass_g`\n",
    "- Apply [`ML.STANDARD_SCALER`](https://cloud.google.com/bigquery/docs/reference/standard-sql/bigqueryml-syntax-standard-scaler) to `culmen_depth_mm` and `culmen_length_mm`\n",
    "- Apply [`ML.QUANTILE_BUCKATIZE`](https://cloud.google.com/bigquery/docs/reference/standard-sql/bigqueryml-syntax-quantile-bucketize) to `flipper_length_mm`\n",
    "- Apply [`ML.IMPUTER`](https://cloud.google.com/bigquery/docs/reference/standard-sql/bigqueryml-syntax-imputer) to `island`, and `sex`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bigquery\n",
    "CREATE OR REPLACE MODEL `statmike-mlops-349915.bqml_model_monitoring.classify_species_rf`\n",
    "    TRANSFORM(\n",
    "        ML.ROBUST_SCALER(body_mass_g) OVER() AS body_mass_g,\n",
    "        ML.STANDARD_SCALER(culmen_length_mm) OVER() AS culmen_length_mm,\n",
    "        ML.STANDARD_SCALER(culmen_depth_mm) OVER() AS culmen_depth_mm,\n",
    "        ML.QUANTILE_BUCKETIZE(flipper_length_mm, 3) OVER() AS flipper_length_mm,\n",
    "        ML.IMPUTER(sex, 'most_frequent') OVER() AS sex,\n",
    "        ML.IMPUTER(island, 'most_frequent') OVER() AS island,\n",
    "        species, split\n",
    "    )\n",
    "    OPTIONS(\n",
    "        MODEL_TYPE = 'RANDOM_FOREST_CLASSIFIER',\n",
    "        INPUT_LABEL_COLS = ['species'],\n",
    "        \n",
    "        # data specifics\n",
    "        DATA_SPLIT_METHOD = 'CUSTOM',\n",
    "        DATA_SPLIT_COL = 'split',\n",
    "        \n",
    "        # model specifics\n",
    "        AUTO_CLASS_WEIGHTS = FALSE,\n",
    "        NUM_PARALLEL_TREE= 150,\n",
    "        TREE_METHOD = 'HIST',\n",
    "        SUBSAMPLE = 0.85,\n",
    "        COLSAMPLE_BYTREE = 0.9,\n",
    "        ENABLE_GLOBAL_EXPLAIN = TRUE,\n",
    "        \n",
    "        # register model in Vertex AI For Online Serving\n",
    "        MODEL_REGISTRY = 'VERTEX_AI',\n",
    "        VERTEX_AI_MODEL_ID = 'classify_species_rf'\n",
    "    )\n",
    "AS\n",
    "    SELECT * EXCEPT(splits),\n",
    "        CASE WHEN splits = 'TRAIN' THEN FALSE\n",
    "        ELSE TRUE END AS split\n",
    "    FROM `statmike-mlops-349915.bqml_model_monitoring.training_split`\n",
    "    WHERE splits != 'TEST'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bigquery\n",
    "SELECT *\n",
    "FROM ML.TRAINING_INFO(MODEL `statmike-mlops-349915.bqml_model_monitoring.classify_species_rf`)\n",
    "ORDER BY iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation With `ML.EVALUATE`\n",
    "\n",
    "BigQuery ML models can be directly evaluated with the [`ML.EVALUATE` function](https://cloud.google.com/bigquery/docs/reference/standard-sql/bigqueryml-syntax-evaluate).  The evaluation of the model on evaluation data specified during training can be done by just specifying the model.  To evaluate the model on new data, like a `TEST` split or even the `TRAIN` split, the records can be specified with a query statement as seen in the following evaluations.\n",
    "\n",
    "> An evaluation split with 10% of records was created above.  This set would normally be used for tuning model hyperparameters, like `BATCH_SIZE`, `DROPOUT`, `HIDDEN_UNITS`, `LEARN_RATE`, and/or `OPTIMIZER` in the case of the DNN used here.  This could also be done directly in the BigQuery `CREATE MODEL` statement with [hyperparameter tuning](https://cloud.google.com/bigquery/docs/hp-tuning-overview)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bigquery\n",
    "SELECT *\n",
    "FROM ML.EVALUATE (\n",
    "    MODEL `statmike-mlops-349915.bqml_model_monitoring.classify_species_rf`\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate The Model: Training Data Split (`TRAIN`)\n",
    "\n",
    "Evaluating the model on the training data is good for setting a baseline for the likely best possible performance of the model.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bigquery\n",
    "SELECT *\n",
    "FROM ML.EVALUATE (\n",
    "    MODEL `statmike-mlops-349915.bqml_model_monitoring.classify_species_rf`,\n",
    "    (\n",
    "        SELECT *\n",
    "        FROM `statmike-mlops-349915.bqml_model_monitoring.training_split`\n",
    "        WHERE splits = 'TRAIN'\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate The Model: `TEST` Data Split\n",
    "\n",
    "Evaluating the model on the `TEST` split is a good gauge of performance in general as it represents data the model was not exposed to during training: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bigquery\n",
    "SELECT *\n",
    "FROM ML.EVALUATE (\n",
    "    MODEL `statmike-mlops-349915.bqml_model_monitoring.classify_species_rf`,\n",
    "    (\n",
    "        SELECT *\n",
    "        FROM `statmike-mlops-349915.bqml_model_monitoring.training_split`\n",
    "        WHERE splits = 'TEST'\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate The Classification Performance with `ML.CONFUSION_MATRIX`\n",
    "\n",
    "This model is a classification model and reviewing the true versus predicted classification categories can be done with the [`ML.CONFUSION_MATRIX` function](https://cloud.google.com/bigquery/docs/reference/standard-sql/bigqueryml-syntax-confusion)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bigquery\n",
    "SELECT *\n",
    "FROM ML.CONFUSION_MATRIX (\n",
    "    MODEL `statmike-mlops-349915.bqml_model_monitoring.classify_species_rf`\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bigquery\n",
    "SELECT *\n",
    "FROM ML.CONFUSION_MATRIX (\n",
    "    MODEL `statmike-mlops-349915.bqml_model_monitoring.classify_species_rf`,\n",
    "    (\n",
    "        SELECT *\n",
    "        FROM `statmike-mlops-349915.bqml_model_monitoring.training_split`\n",
    "        WHERE splits = 'TRAIN'\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bigquery\n",
    "SELECT *\n",
    "FROM ML.CONFUSION_MATRIX (\n",
    "    MODEL `statmike-mlops-349915.bqml_model_monitoring.classify_species_rf`,\n",
    "    (\n",
    "        SELECT *\n",
    "        FROM `statmike-mlops-349915.bqml_model_monitoring.training_split`\n",
    "        WHERE splits = 'TEST'\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "## Model Serving\n",
    "\n",
    "Once a version of the model is trusted to serve predictions we can put it into use.  At first, this means creating and using predictions from the model.  This is quickly followed by important considerations:\n",
    "\n",
    ">Has the system that is being measured, that creates the data, or that records the data changed in a way that could impact the models ability to correctly predict/classify?\n",
    "\n",
    "It seems like a good idea to continously run evaluations to make sure the model accuracy does not degrade - and it is.  There can be a lag between new data and knowing the actual outcome which makes using using evaluations to monitor models a potentially reactive, or late signal.  To overcome this we can also monitor the model.  More on this later on below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions With `ML.PREDICT`\n",
    "\n",
    "Use [`ML.PREDICT`](https://cloud.google.com/bigquery/docs/reference/standard-sql/bigqueryml-syntax-predict) to serve predictions with the model directly in BigQuery."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bigquery\n",
    "SELECT *\n",
    "FROM ML.PREDICT(\n",
    "    MODEL `statmike-mlops-349915.bqml_model_monitoring.classify_species_rf`,\n",
    "    (\n",
    "        SELECT *\n",
    "        FROM `statmike-mlops-349915.bqml_model_monitoring.training_split`\n",
    "        LIMIT 5\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "## Serving Data\n",
    "\n",
    "The data source for training and evaluation represents what is known about a system at a point-in-time.  In real world systems measurements can change for many reasons, for example:\n",
    "- training/serving skew due to measurement and data systems:\n",
    "    - the tool used for measurement may change resulting is slight shifts and variations\n",
    "    - the system reporting results might be updated and introduce errors like rearranging the order or parameters and format of the results\n",
    "    - the data processing systems might have changes that alter the calculations of measurements\n",
    "- the system, environment, or subjects being measured may:\n",
    "    - change behaviors\n",
    "    - short-term even forces change\n",
    "    - have environmental changes that impact them\n",
    "    - have seasonal changes that were not represented in the training data\n",
    "    - change in general due to upstream causes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduce Changes Over Time\n",
    "\n",
    "To illustrate the impact of change over time, the following code creates a new set of data from the test split.  It creates a series of changes to measurements for each of the past 30 days.  In each case, the values of the parameters `flipper_length_mm` and `body_mass_g` are allowed to slightly increase which can accumulate over the timespan. This might mimic a potential growth season for the penguins that might not have been represented in the training data.\n",
    "\n",
    "This table of serving data could be sourced form where your features are coming from.  In the case of an online model, like [Vertex AI Prediction Endpoints](https://cloud.google.com/vertex-ai/docs/predictions/overview), then [prediction request could be logged to BigQuery](https://cloud.google.com/vertex-ai/docs/predictions/online-prediction-logging#enabling-and-disabling) for use in the model monitoring tasks below.  This online serving pattern is covered later in this tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bigquery\n",
    "DECLARE counter INT64 DEFAULT 30;\n",
    "\n",
    "# actual data as starting point - add entity_id, and feature_timestamp:\n",
    "CREATE OR REPLACE TABLE `statmike-mlops-349915.bqml_model_monitoring.serving` AS\n",
    "    SELECT * EXCEPT(flipper_length_mm, body_mass_g),\n",
    "    TIMESTAMP_SUB(TIMESTAMP(CURRENT_DATE()), INTERVAL counter DAY) AS instance_timestamp,\n",
    "    flipper_length_mm as flipper_length_mm,\n",
    "    body_mass_g as body_mass_g\n",
    "    FROM `statmike-mlops-349915.bqml_model_monitoring.training`\n",
    "    WHERE RAND() <= 0.20;\n",
    "\n",
    "LOOP\n",
    "    SET counter = counter - 1;\n",
    "    IF counter < 0 THEN LEAVE;\n",
    "    END IF;\n",
    "    INSERT `statmike-mlops-349915.bqml_model_monitoring.serving`\n",
    "        SELECT * EXCEPT(instance_timestamp, flipper_length_mm, body_mass_g),\n",
    "            TIMESTAMP_ADD(instance_timestamp, INTERVAL 1 DAY) AS instance_timestamp,\n",
    "            CASE\n",
    "                WHEN RAND() >= 0.75 THEN flipper_length_mm\n",
    "                ELSE flipper_length_mm + 6*(RAND()-0.1)\n",
    "            END AS flipper_length_mm,\n",
    "            CASE\n",
    "                WHEN RAND() >= 0.75 THEN body_mass_g\n",
    "                ELSE body_mass_g + 120*(RAND()-0.1)\n",
    "            END AS body_mass_g,\n",
    "        FROM `statmike-mlops-349915.bqml_model_monitoring.serving`\n",
    "        WHERE instance_timestamp >= (SELECT MAX(instance_timestamp) FROM `statmike-mlops-349915.bqml_model_monitoring.serving`);\n",
    "END LOOP;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bigquery serve\n",
    "SELECT\n",
    "    DATE(instance_timestamp) AS DATE,\n",
    "    AVG(flipper_length_mm) AS flipper_length_mm,\n",
    "    AVG(body_mass_g) AS body_mass_g\n",
    "FROM `statmike-mlops-349915.bqml_model_monitoring.serving`\n",
    "GROUP BY DATE\n",
    "ORDER BY DATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "serve.set_index('DATE', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#serve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "serve['flipper_length_mm'].plot(legend = True, figsize = (8, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "serve['body_mass_g'].plot(legend = True, figsize = (8, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "## Monitoring With Evaluations\n",
    "\n",
    "It might seem like ongoing model evaluations are a great solution to model monitoring.  If the actual known values are available immediately then this could be possible to use for monitoring.  However, detecting a change in evaluation metrics means the model has realized a degradation.  It is a lagging signal.  To be more proactive we should monitor the inputs to the model, the features.  More on that in the next section.\n",
    "\n",
    "First, look at the evaluation metrics for the most recent days data which has the cumulative change of the past 30 days introduced above.  In this case, the actual known values is known. This may not be possible in many real-world examples where the actual known values are:\n",
    "- delayed by minutes, hours, days, or even longer\n",
    "- not always known for all instances\n",
    "- potentially in a different status that can change over a period of time before being confirmed as final\n",
    "\n",
    "In reviewing the evaluation for the most recent instances here, the `precision` has dropped and the `log_loss` has increased drastically.  The confusion matrix shows Chinstrap penguins's are now being misclassified much more often than when the model was trained.  \n",
    "\n",
    "The question becomes \"How soon could this have been noticed?\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bigquery\n",
    "SELECT *\n",
    "FROM ML.EVALUATE (\n",
    "    MODEL `statmike-mlops-349915.bqml_model_monitoring.classify_species_rf`,\n",
    "    (\n",
    "        SELECT *\n",
    "        FROM `statmike-mlops-349915.bqml_model_monitoring.serving`\n",
    "        WHERE DATE(instance_timestamp) >= CURRENT_DATE()\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bigquery\n",
    "SELECT *\n",
    "FROM ML.CONFUSION_MATRIX (\n",
    "    MODEL `statmike-mlops-349915.bqml_model_monitoring.classify_species_rf`,\n",
    "    (\n",
    "        SELECT *\n",
    "        FROM `statmike-mlops-349915.bqml_model_monitoring.serving`\n",
    "        WHERE DATE(instance_timestamp) >= CURRENT_DATE()\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluations: Over Time\n",
    "\n",
    "In this case, we know the actual identification of the `species` and are measuring the same penguins daily.  Reviewing the evaluations daily could give a good sense of how the model is performing on a daily basis.\n",
    "\n",
    "The result of the daily evaluations below shows that the log_loss starts to increase immediately and it takes more than a week for a noticable impact on precision/recall/accuracy/f1_score. \n",
    "\n",
    "What if the actual values where only known after a lag of days or weeks?  How quickly would evaluations be able to indicate the model's accuracy is possibly questionable?  The answer is a different approach - Model Monitoring.  This is covered in the section that follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bigquery evaluations\n",
    "DECLARE counter INT64 DEFAULT 30;\n",
    "DECLARE result STRUCT<precision FLOAT64, recall FLOAT64, accuracy FLOAT64, f1_score FLOAT64, log_loss FLOAT64, roc_auc FLOAT64, eval_date DATE>;\n",
    "DECLARE results ARRAY<STRUCT<precision FLOAT64, recall FLOAT64, accuracy FLOAT64, f1_score FLOAT64, log_loss FLOAT64, roc_auc FLOAT64, eval_date DATE>> DEFAULT [];\n",
    "LOOP\n",
    "    IF counter < 0 THEN LEAVE;\n",
    "    END IF;\n",
    "    SET result = (\n",
    "            SELECT AS STRUCT precision, recall, accuracy, f1_score, log_loss, roc_auc, DATE_SUB(CURRENT_DATE(), INTERVAL counter DAY) AS eval_date\n",
    "            FROM ML.EVALUATE (\n",
    "                MODEL `statmike-mlops-349915.bqml_model_monitoring.classify_species_rf`,\n",
    "                (\n",
    "                    SELECT *\n",
    "                    FROM `statmike-mlops-349915.bqml_model_monitoring.serving`\n",
    "                    WHERE DATE(instance_timestamp) = DATE_SUB(CURRENT_DATE(), INTERVAL counter DAY)\n",
    "                )\n",
    "            )\n",
    "    );\n",
    "    SET results = ARRAY_CONCAT(results,[result]);\n",
    "    SET counter = counter - 1;\n",
    "END LOOP;\n",
    "SELECT * FROM UNNEST(results);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "evaluations.set_index('eval_date', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "evaluations.plot(y = ['log_loss', 'f1_score', 'precision'], legend = True, title = 'Evaluation Metrics Over Last 30 days', figsize = (8, 3), grid = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "## **Model Monitoring**\n",
    "\n",
    "Reviewing model evaluations over time does show a pattern of deterioration in the example above.  But at what point is it actionable?  And what if each days evaluations are relying on actual values that took hours, days, weeks, or even months to be available?  \n",
    "\n",
    "Model monitoring takes a different approach.  It goes back to the source of the model, each input feature.  These features form a distribution at the input to the model (the training data) and this can be used to compare to over time.  By setting thresholds on these comparisons to the original training data, alerts can be used to notify that a models accuracy *could be* in question.  This comparison to the training data is called **skew** detection.\n",
    "\n",
    "Similarly, each days values could be compared to the previous days, or weeks values.  These comparisons are referred to as **drift** detection.  \n",
    "\n",
    "Both of these types of comparisons can be done directly in BigQuery with two functions built for these tasks:\n",
    "- [`ML.VALIDATE_DATA_SKEW`](https://cloud.google.com/bigquery/docs/reference/standard-sql/bigqueryml-syntax-validate-data-skew)\n",
    "- [`ML.VALIDATE_DATA_DRIFT`](https://cloud.google.com/bigquery/docs/reference/standard-sql/bigqueryml-syntax-validate-data-drift)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monitoring Skew (Change from training) With `ML.VALIDATE_DATA_SKEW`\n",
    "\n",
    "Compare today, or any data, to the training data by directly comparing to the the model created in BigQuery.\n",
    "\n",
    ">**NOTE:** By adding the `enable_visualization_link` argument to the `ML.VALIDATE_DATA_SKEW` function it adds the Vertex AI Model Monitoring console link in the `visualization_link` column of the output.  Read more about [Monitoring visualization](https://cloud.google.com/bigquery/docs/model-monitoring-overview#monitoring_visualization) in the BigQuery ML [Model monitoring overview](https://cloud.google.com/bigquery/docs/model-monitoring-overview)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bigquery skew\n",
    "SELECT *\n",
    "FROM ML.VALIDATE_DATA_SKEW(\n",
    "    # base\n",
    "    MODEL `statmike-mlops-349915.bqml_model_monitoring.classify_species_rf`,\n",
    "    (# compare\n",
    "        SELECT *\n",
    "        FROM `statmike-mlops-349915.bqml_model_monitoring.serving`\n",
    "        WHERE DATE(instance_timestamp) >= CURRENT_DATE()\n",
    "    )\n",
    "    ,STRUCT(TRUE AS enable_visualization_link)\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "skew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "display(HTML(f'<a href=\"{skew.visualization_link[0]}\" target=\"_blank\" style=\"font-size: 18px;\">Open Google Cloud Console in a new tab</a>'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "display(HTML('<div style=\"text-align: center;\"><img src=\"./resources/tutorial_skew.gif\" style=\"border: 2px solid black; width: auto; height: 600px;\"></div>'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monitoring Drift (Change Over Time) With `ML.VALIDATE_DATA_DRIFT`\n",
    "\n",
    "Compare today to 5 days ago and set the a lower, more sensitive, threshold of `0.03` (default is `0.3`) for all features.\n",
    "\n",
    "\n",
    ">**NOTE:** By adding the `MODEL` to the `ML.VALIDATE_DATA_DRIFT` function it adds the Vertex AI Model Monitoring console link in the `visualization_link` column of the output.  Read more about [Monitoring visualization](https://cloud.google.com/bigquery/docs/model-monitoring-overview#monitoring_visualization) in the BigQuery ML [Model monitoring overview](https://cloud.google.com/bigquery/docs/model-monitoring-overview)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bigquery drift\n",
    "SELECT *\n",
    "FROM ML.VALIDATE_DATA_DRIFT(\n",
    "    (# base\n",
    "        SELECT * EXCEPT(instance_timestamp, species)\n",
    "        FROM `statmike-mlops-349915.bqml_model_monitoring.serving`\n",
    "        WHERE DATE(instance_timestamp) = DATE_SUB(CURRENT_DATE(), INTERVAL 5 DAY)\n",
    "    ),\n",
    "    (# compare\n",
    "        SELECT * EXCEPT(instance_timestamp, species)\n",
    "        FROM `statmike-mlops-349915.bqml_model_monitoring.serving`\n",
    "        WHERE DATE(instance_timestamp) = CURRENT_DATE() \n",
    "    ),\n",
    "    STRUCT(\n",
    "        0.03 AS categorical_default_threshold,\n",
    "        0.03 AS numerical_default_threshold\n",
    "    )\n",
    "    , MODEL `statmike-mlops-349915.bqml_model_monitoring.classify_species_rf`\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "drift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "display(HTML(f'<a href=\"{drift.visualization_link[0]}\" target=\"_blank\" style=\"font-size: 18px;\">Open Google Cloud Console in a new tab</a>'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "display(HTML('<div style=\"text-align: center;\"><img src=\"./resources/tutorial_drift.gif\" style=\"border: 2px solid black; width: auto; height: 600px;\"></div>'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monitoring Skew (Manually) - As Drift from Training Data\n",
    "\n",
    "Since the `ML.VALIDATE_DATA_DRIFT` is comparing two tables, it could also be used for **skew** by comparing the training data to new data, like todays data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bigquery skew_manual\n",
    "SELECT *\n",
    "FROM ML.VALIDATE_DATA_DRIFT(\n",
    "    (# base\n",
    "        SELECT *\n",
    "        FROM `statmike-mlops-349915.bqml_model_monitoring.training_split`\n",
    "        WHERE splits = 'TRAIN'\n",
    "    ),\n",
    "    (# compare\n",
    "        SELECT * EXCEPT(instance_timestamp, species)\n",
    "        FROM `statmike-mlops-349915.bqml_model_monitoring.serving`\n",
    "        WHERE DATE(instance_timestamp) = CURRENT_DATE() \n",
    "    ),\n",
    "    STRUCT()\n",
    "    , MODEL `statmike-mlops-349915.bqml_model_monitoring.classify_species_rf`\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "skew_manual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "display(HTML(f'<a href=\"{skew_manual.visualization_link[0]}\" target=\"_blank\" style=\"font-size: 18px;\">Open Google Cloud Console in a new tab</a>'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "display(HTML('<div style=\"text-align: center;\"><img src=\"./resources/tutorial_skew_manual.gif\" style=\"border: 2px solid black; width: auto; height: 600px;\"></div>'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### TensorFlow Data Validation (TFDV) In BigQuery\n",
    "\n",
    "BigQuery offers two functions that bring the power of the TensorFlow's [TFX platform](https://www.tensorflow.org/tfx) with built-in [TensorFlow Data Validation (TFDV)](https://www.tensorflow.org/tfx/data_validation/get_started) module directly inside of BigQuery.\n",
    "- [`ML.TFDV_DESCRIBE`](https://cloud.google.com/bigquery/docs/reference/standard-sql/bigqueryml-syntax-tfdv-describe) to generate descriptive statistics of any table\n",
    "- [`ML.TFDV_VALIDATE`](https://cloud.google.com/bigquery/docs/reference/standard-sql/bigqueryml-syntax-tfdv-validate) to compare statistics of two tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate Statistics with `ML.TFDV_DESCRIBE`\n",
    "\n",
    "Generate statistics for any table, in this case the training data features or a timespan of serving data features.  This is like using the TensorFlow's [TFX platform](https://www.tensorflow.org/tfx) with built-in [TensorFlow Data Validation (TFDV)](https://www.tensorflow.org/tfx/data_validation/get_started) module's [`tfdv.generate_statistics_from_csv()`](https://www.tensorflow.org/tfx/data_validation/api_docs/python/tfdv/generate_statistics_from_csv) method.\n",
    "\n",
    "The descriptions can be used in comparisons for skew or drift detection with the `ML.TFDV_VALIDATE` function, covered next, as well as in the visualization tool `tfdv.visualize_statistics` also covered below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bigquery train_describe\n",
    "SELECT *\n",
    "FROM ML.TFDV_DESCRIBE(\n",
    "    (\n",
    "        SELECT * EXCEPT(splits, species)\n",
    "        FROM `statmike-mlops-349915.bqml_model_monitoring.training_split`\n",
    "        WHERE splits = 'TRAIN'\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_describe = json.loads(train_describe['dataset_feature_statistics_list'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_describe['datasets'][0]['features'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bigquery today_describe\n",
    "SELECT *\n",
    "FROM ML.TFDV_DESCRIBE(\n",
    "    (\n",
    "        SELECT * EXCEPT(instance_timestamp, species)\n",
    "        FROM `statmike-mlops-349915.bqml_model_monitoring.serving`\n",
    "        WHERE DATE(instance_timestamp) = CURRENT_DATE()\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "today_describe = json.loads(today_describe['dataset_feature_statistics_list'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#today_describe['datasets'][0]['features'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize Statistics with `tfdv.visualize_statistics`\n",
    "\n",
    "Use the [`tfdv.visualize_statistics`](https://www.tensorflow.org/tfx/data_validation/api_docs/python/tfdv/visualize_statistics) tool to visualize the generated descriptions and directly compare them.  This presents visuals using [Facets Overview](https://pair-code.github.io/facets/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "import tensorflow_data_validation as tfdv\n",
    "import tensorflow_metadata as tfmd\n",
    "from google.protobuf import json_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tfdv.visualize_statistics(\n",
    "    lhs_statistics = json_format.ParseDict(train_describe, tfmd.proto.statistics_pb2.DatasetFeatureStatisticsList()),\n",
    "    rhs_statistics = json_format.ParseDict(today_describe, tfmd.proto.statistics_pb2.DatasetFeatureStatisticsList()),\n",
    "    lhs_name = 'Training Data Stats',\n",
    "    rhs_name = 'Serving Data Stats - For Today'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "display(HTML('<div style=\"text-align: center;\"><img src=\"./resources/tutorial_tfdv_visualize.gif\" style=\"border: 2px solid black; width: auto; height: 400px;\"></div>'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare And Detect Anomalies with `ML.TFDV_VALIDATE`\n",
    "\n",
    "Compare the distribution of any table to a base table and compute distance statistics to detect anomalies.  This is like using the TensorFlow's [TFX platform](https://www.tensorflow.org/tfx) with built-in [TensorFlow Data Validation (TFDV)](https://www.tensorflow.org/tfx/data_validation/get_started) module's [validate_statistics api](https://www.tensorflow.org/tfx/data_validation/api_docs/python/tfdv/validate_statistics).\n",
    "\n",
    "These comparison can be made to training data for **skew** detection or previous serving data for **drift** detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bigquery validate\n",
    "WITH\n",
    "    TRAIN AS (\n",
    "        SELECT * EXCEPT(splits, species)\n",
    "        FROM `statmike-mlops-349915.bqml_model_monitoring.training_split`\n",
    "        WHERE splits = 'TRAIN'\n",
    "    ),\n",
    "    SERVE AS (\n",
    "        SELECT * EXCEPT(instance_timestamp, species)\n",
    "        FROM `statmike-mlops-349915.bqml_model_monitoring.serving`\n",
    "        WHERE DATE(instance_timestamp) = CURRENT_DATE()\n",
    "    )\n",
    "SELECT ML.TFDV_VALIDATE(\n",
    "    (SELECT * FROM ML.TFDV_DESCRIBE(TABLE TRAIN)),\n",
    "    (SELECT * FROM ML.TFDV_DESCRIBE(TABLE SERVE)),\n",
    "    'SKEW'\n",
    ") as validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "validate = json.loads(validate['validate'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#validate['anomaly_info']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display Anomalies with `tfdv.display_anomalies`\n",
    "\n",
    "Use the [`tfdv.display_anomalies`](https://www.tensorflow.org/tfx/data_validation/api_docs/python/tfdv/display_anomalies) tool to display a table of anomaly detections with descriptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if 'generate_legacy_feature_spec' in validate['baseline'].keys():\n",
    "    del validate['baseline']['generate_legacy_feature_spec']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tfdv.display_anomalies(\n",
    "    anomalies = json_format.ParseDict(validate, tfmd.proto.anomalies_pb2.Anomalies())\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Understanding Monitoring Thresholds\n",
    "\n",
    "The `ML.VALIDATE_DATA_DRIFT`, `ML.VALIDATE_DATA_SKEW`, and `ML.TFDV_VALIDATE` functions use distance scores to quantify the change in the statistical distribution of features.  The methods of calculating the distance scores are:\n",
    "- [L-infinity distance](https://en.wikipedia.org/wiki/Chebyshev_distance) for categorical features\n",
    "- [Jensen-Shannon divergence](https://en.wikipedia.org/wiki/Jensen%E2%80%93Shannon_divergence) for numeric features.  Can also be use for categorical features.\n",
    "\n",
    "These methods are the same ones used by [TensorFlow Data Validation](https://www.tensorflow.org/tfx/guide/tfdv#training-serving_skew_detection) which is also used in [Vertex AI Model Monitoring](https://cloud.google.com/vertex-ai/docs/model-monitoring/overview#calculating-skew-and-drift).\n",
    "\n",
    "This section aims to provide intuition on how these two metrics work.  In the data used for this workflow the feature `island` has three possible values: `Biscoe`, `Dream`, and `Torgersen`.  The proportion of data in each of these categories forms a distribution.  This will be used to visually show how both methods of calculating distance scores work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve Distributions: Training & Serving\n",
    "\n",
    "Use the `ML.TFDV_DESCRIBE` function to get the statistics for the distribution of the `island` feature at both training and for serving."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bigquery island_train\n",
    "SELECT *\n",
    "FROM ML.TFDV_DESCRIBE(\n",
    "    (\n",
    "        SELECT island\n",
    "        FROM `statmike-mlops-349915.bqml_model_monitoring.training_split`\n",
    "        WHERE splits = 'TRAIN'\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bigquery island_serve\n",
    "SELECT *\n",
    "FROM ML.TFDV_DESCRIBE(\n",
    "    (\n",
    "        SELECT island\n",
    "        FROM `statmike-mlops-349915.bqml_model_monitoring.serving`\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "island_train = json.loads(island_train['dataset_feature_statistics_list'].iloc[0])\n",
    "island_serve = json.loads(island_serve['dataset_feature_statistics_list'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "island_train['datasets'][0]['features'][0]['string_stats']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "island_train_stats = island_train['datasets'][0]['features'][0]['string_stats']['rank_histogram']['buckets']\n",
    "island_train_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "island_serve_stats = island_serve['datasets'][0]['features'][0]['string_stats']['rank_histogram']['buckets']\n",
    "island_serve_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine Distributions In DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "index = [i['label'] for i in island_train_stats]\n",
    "train = [i['sample_count'] for i in island_train_stats]\n",
    "serve = [island_serve_stats[index.index(k)]['sample_count'] for k in [i['label'] for i in island_serve_stats]]\n",
    "stats = pd.DataFrame(\n",
    "    {\n",
    "        'train_n': train,\n",
    "        'serve_n': serve,\n",
    "        'train_pct': [x/sum(train) for x in train],\n",
    "        'serve_pct': [x/sum(serve) for x in serve]\n",
    "    },\n",
    "    index = index\n",
    ")\n",
    "stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ax = stats[['train_pct', 'serve_pct']].plot.bar(rot=0)\n",
    "for container in ax.containers:\n",
    "    ax.bar_label(container)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### L-Infinity Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "stats['abs_change_pct'] = abs(stats['train_pct'] - stats['serve_pct'])\n",
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ax = stats['abs_change_pct'].plot.bar()\n",
    "ax.bar_label(ax.containers[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f\"The max change in percentage(L-Infinity Distance) is {max(stats['abs_change_pct'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jensen-Shannon Divergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "stats['mix'] = (stats['train_pct'] + stats['serve_pct']) / 2\n",
    "stats['train_kl'] = stats['train_pct'] * np.log2(stats['train_pct'] / stats['mix'])\n",
    "stats['serve_kl'] = stats['serve_pct'] * np.log2(stats['serve_pct'] / stats['mix'])\n",
    "stats['JSD'] = (stats['train_kl'] + stats['serve_kl']) / 2\n",
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f\"The total for the Jansen-Shannon Divergence is {sum(stats['JSD'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify Calculations with `ML.VALIDATE_DATA_DRIFT`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bigquery\n",
    "SELECT *\n",
    "FROM ML.VALIDATE_DATA_DRIFT(\n",
    "    (\n",
    "        SELECT island\n",
    "        FROM `statmike-mlops-349915.bqml_model_monitoring.training_split`\n",
    "        WHERE splits = 'TRAIN'\n",
    "    ),\n",
    "    (\n",
    "        SELECT island\n",
    "        FROM `statmike-mlops-349915.bqml_model_monitoring.serving`\n",
    "    ),\n",
    "    STRUCT('L_INFTY' AS categorical_metric_type)\n",
    "    #, MODEL `statmike-mlops-349915.bqml_model_monitoring.classify_species_rf`\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f\"The max change in percentage(L-Infinity Distance) is {max(stats['abs_change_pct'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bigquery\n",
    "SELECT *\n",
    "FROM ML.VALIDATE_DATA_DRIFT(\n",
    "    (\n",
    "        SELECT island\n",
    "        FROM `statmike-mlops-349915.bqml_model_monitoring.training_split`\n",
    "        WHERE splits = 'TRAIN'\n",
    "    ),\n",
    "    (\n",
    "        SELECT island\n",
    "        FROM `statmike-mlops-349915.bqml_model_monitoring.serving`\n",
    "    ),\n",
    "    STRUCT('JENSEN_SHANNON_DIVERGENCE' AS categorical_metric_type)\n",
    "    #, MODEL `statmike-mlops-349915.bqml_model_monitoring.classify_species_rf`\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f\"The total for the Jansen-Shannon Divergence is {sum(stats['JSD'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## More Applications For Model Monitoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Monitoring Transformed Features\n",
    "\n",
    "The [`CREATE MODEL`](https://cloud.google.com/bigquery/docs/reference/standard-sql/bigqueryml-syntax-create) statement included a [`TRANSFORM`](https://cloud.google.com/bigquery/docs/reference/standard-sql/bigqueryml-syntax-create#transform).  This is available to be called directly for input data with the [`ML.TRANSFORM`](https://cloud.google.com/bigquery/docs/reference/standard-sql/bigqueryml-syntax-transform) function.  This can be useful for considering monitoring the transformed features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transformations With `ML.TRANSFORM`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bigquery\n",
    "SELECT *\n",
    "FROM ML.TRANSFORM(\n",
    "    MODEL `statmike-mlops-349915.bqml_model_monitoring.classify_species_rf`,\n",
    "    (\n",
    "        SELECT *\n",
    "        FROM `statmike-mlops-349915.bqml_model_monitoring.serving`\n",
    "        LIMIT 5\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Monitoring Skew (Manually) - As Drift from Training Data With `ML.VALIDATE_DATA_DRIFT`\n",
    "\n",
    "Compare today, or any data, to the training data by directly comparing to the the model created in BigQuery."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bigquery\n",
    "SELECT *\n",
    "FROM ML.VALIDATE_DATA_DRIFT(\n",
    "    (\n",
    "        SELECT *\n",
    "        FROM ML.TRANSFORM(\n",
    "            MODEL `statmike-mlops-349915.bqml_model_monitoring.classify_species_rf`,\n",
    "            (\n",
    "                SELECT *\n",
    "                FROM `statmike-mlops-349915.bqml_model_monitoring.training_split`\n",
    "                WHERE splits = 'TRAIN'\n",
    "            )\n",
    "        )\n",
    "    ),\n",
    "    (\n",
    "        SELECT *\n",
    "        FROM ML.TRANSFORM(\n",
    "            MODEL `statmike-mlops-349915.bqml_model_monitoring.classify_species_rf`,\n",
    "            (\n",
    "                SELECT *\n",
    "                FROM `statmike-mlops-349915.bqml_model_monitoring.serving`\n",
    "                WHERE DATE(instance_timestamp) >= CURRENT_DATE()\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    #, MODEL `statmike-mlops-349915.bqml_model_monitoring.classify_species_rf`\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Monitoring Drift (Change Over Time) With `ML.VALIDATE_DATA_DRIFT`\n",
    "\n",
    "Compare today to 5 days ago and set the a lower, more sensitive, threshold of `0.03` (default is `0.3`) for all features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bigquery\n",
    "SELECT *\n",
    "FROM ML.VALIDATE_DATA_DRIFT(\n",
    "    (\n",
    "        SELECT *\n",
    "        FROM ML.TRANSFORM(\n",
    "            MODEL `statmike-mlops-349915.bqml_model_monitoring.classify_species_rf`,\n",
    "            (\n",
    "                SELECT *\n",
    "                FROM `statmike-mlops-349915.bqml_model_monitoring.serving`\n",
    "                WHERE DATE(instance_timestamp) = DATE_SUB(CURRENT_DATE(), INTERVAL 5 DAY)\n",
    "            )\n",
    "        )\n",
    "    ),\n",
    "    (\n",
    "        SELECT *\n",
    "        FROM ML.TRANSFORM(\n",
    "            MODEL `statmike-mlops-349915.bqml_model_monitoring.classify_species_rf`,\n",
    "            (\n",
    "                SELECT *\n",
    "                FROM `statmike-mlops-349915.bqml_model_monitoring.serving`\n",
    "                WHERE DATE(instance_timestamp) >= CURRENT_DATE()\n",
    "            )\n",
    "        )\n",
    "    ),\n",
    "    STRUCT(\n",
    "        0.03 AS categorical_default_threshold,\n",
    "        0.03 AS numerical_default_threshold\n",
    "    )\n",
    "    #, MODEL `statmike-mlops-349915.bqml_model_monitoring.classify_species_rf`\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "### Monitoring Feature Attributions\n",
    "\n",
    "BigQuery ML models, like the deep neural network classifier (`model_type = 'DNN_CLASSIFIER'`) used above, can also serve explanations using the BigQuery function [`ML.EXPLAIN_PREDICT`](https://cloud.google.com/bigquery/docs/reference/standard-sql/bigqueryml-syntax-explain-predict).  This function returns feature attributions for each feature used in the model to explain how much contribution was made to the final prediction for a given instance.\n",
    "\n",
    "**Feature Attributions**\n",
    "\n",
    "The feature attributions from `ML.EXPLAIN_PREDICT` are [local explanations](https://cloud.google.com/bigquery/docs/xai-overview#local_versus_global_explainability), specific to the instance being predicted.  The attribution values are given for each feature and they add up to the `prediction_value`. In this case the model is a classifier and the `prediction_value` is the logit value (log-odds) of the predicted class.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Serving Feature Attributions\n",
    "\n",
    "As an example, the following cell gets the feature attributions for a single penguin with for the latest values of the features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bigquery\n",
    "WITH\n",
    "    EXPLAIN AS (\n",
    "        SELECT * EXCEPT(body_mass_g, sex, island, flipper_length_mm, culmen_depth_mm, culmen_length_mm)\n",
    "        FROM ML.EXPLAIN_PREDICT(\n",
    "            MODEL `statmike-mlops-349915.bqml_model_monitoring.classify_species_rf`,\n",
    "            (\n",
    "                SELECT * EXCEPT(instance_timestamp, species)\n",
    "                FROM `statmike-mlops-349915.bqml_model_monitoring.serving`\n",
    "                WHERE DATE(instance_timestamp) = CURRENT_DATE()\n",
    "                LIMIT 1\n",
    "            ), \n",
    "            STRUCT(10 AS top_k_features)\n",
    "        )\n",
    "    ),\n",
    "    ATTRIBUTIONS AS (\n",
    "        SELECT * EXCEPT(top_feature_attributions),\n",
    "        FROM EXPLAIN\n",
    "        JOIN UNNEST(top_feature_attributions)\n",
    "    )\n",
    "SELECT * \n",
    "FROM ATTRIBUTIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reviewing Feature Attributions\n",
    "\n",
    "Get attributions for all penguins:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bigquery explain\n",
    "WITH\n",
    "    EXPLAIN AS (\n",
    "        SELECT * EXCEPT(body_mass_g, sex, island, flipper_length_mm, culmen_depth_mm, culmen_length_mm)\n",
    "        FROM ML.EXPLAIN_PREDICT(\n",
    "            MODEL `statmike-mlops-349915.bqml_model_monitoring.classify_species_rf`,\n",
    "            (\n",
    "                SELECT * EXCEPT(instance_timestamp, species)\n",
    "                FROM `statmike-mlops-349915.bqml_model_monitoring.serving`\n",
    "                WHERE DATE(instance_timestamp) = CURRENT_DATE()\n",
    "            ), \n",
    "            STRUCT(10 AS top_k_features)\n",
    "        )\n",
    "    ),\n",
    "    ATTRIBUTIONS AS (\n",
    "        SELECT * EXCEPT(top_feature_attributions),\n",
    "        FROM EXPLAIN\n",
    "        JOIN UNNEST(top_feature_attributions)\n",
    "    ),\n",
    "    PIVOT_ATTRIBUTION AS (\n",
    "        SELECT body_mass_g, sex, island, flipper_length_mm, culmen_depth_mm, culmen_length_mm\n",
    "        FROM ATTRIBUTIONS PIVOT(MAX(attribution) FOR feature IN ('body_mass_g', 'sex', 'island', 'flipper_length_mm', 'culmen_depth_mm', 'culmen_length_mm'))\n",
    "    )\n",
    "SELECT *\n",
    "FROM PIVOT_ATTRIBUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "explain.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Monitor Feature Attributions For Drift with `ML.VALIDATE_DATA_DRIFT`\n",
    "\n",
    "Compare yesterday to 25 days ago:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bigquery\n",
    "WITH\n",
    "    EXPLAIN_BASE AS (\n",
    "        SELECT * EXCEPT(body_mass_g, sex, island, flipper_length_mm, culmen_depth_mm, culmen_length_mm)\n",
    "        FROM ML.EXPLAIN_PREDICT(\n",
    "            MODEL `statmike-mlops-349915.bqml_model_monitoring.classify_species_rf`,\n",
    "            (\n",
    "                SELECT * EXCEPT(instance_timestamp, species)\n",
    "                FROM `statmike-mlops-349915.bqml_model_monitoring.serving`\n",
    "                WHERE DATE(instance_timestamp) = DATE_SUB(CURRENT_DATE(), INTERVAL 25 DAY)\n",
    "            ), \n",
    "            STRUCT(10 AS top_k_features)\n",
    "        )\n",
    "    ),\n",
    "    ATTRIBUTIONS_BASE AS (\n",
    "        SELECT * EXCEPT(top_feature_attributions),\n",
    "        FROM EXPLAIN_BASE\n",
    "        JOIN UNNEST(top_feature_attributions)\n",
    "    ),\n",
    "    PIVOT_ATTRIBUTION_BASE AS (\n",
    "        SELECT body_mass_g, sex, island, flipper_length_mm, culmen_depth_mm, culmen_length_mm\n",
    "        FROM ATTRIBUTIONS_BASE PIVOT(MAX(attribution) FOR feature IN ('body_mass_g', 'sex', 'island', 'flipper_length_mm', 'culmen_depth_mm', 'culmen_length_mm'))\n",
    "    ),\n",
    "    EXPLAIN_COMP AS (\n",
    "        SELECT * EXCEPT(body_mass_g, sex, island, flipper_length_mm, culmen_depth_mm, culmen_length_mm)\n",
    "        FROM ML.EXPLAIN_PREDICT(\n",
    "            MODEL `statmike-mlops-349915.bqml_model_monitoring.classify_species_rf`,\n",
    "            (\n",
    "                SELECT * EXCEPT(instance_timestamp, species)\n",
    "                FROM `statmike-mlops-349915.bqml_model_monitoring.serving`\n",
    "                WHERE DATE(instance_timestamp) = DATE_SUB(CURRENT_DATE(), INTERVAL 1 DAY)\n",
    "            ), \n",
    "            STRUCT(10 AS top_k_features)\n",
    "        )\n",
    "    ),\n",
    "    ATTRIBUTIONS_COMP AS (\n",
    "        SELECT * EXCEPT(top_feature_attributions),\n",
    "        FROM EXPLAIN_COMP\n",
    "        JOIN UNNEST(top_feature_attributions)\n",
    "    ),\n",
    "    PIVOT_ATTRIBUTION_COMP AS (\n",
    "        SELECT body_mass_g, sex, island, flipper_length_mm, culmen_depth_mm, culmen_length_mm\n",
    "        FROM ATTRIBUTIONS_COMP PIVOT(MAX(attribution) FOR feature IN ('body_mass_g', 'sex', 'island', 'flipper_length_mm', 'culmen_depth_mm', 'culmen_length_mm'))\n",
    "    )\n",
    "SELECT *\n",
    "FROM ML.VALIDATE_DATA_DRIFT(\n",
    "    TABLE PIVOT_ATTRIBUTION_BASE,\n",
    "    TABLE PIVOT_ATTRIBUTION_COMP\n",
    "    #, MODEL `statmike-mlops-349915.bqml_model_monitoring.classify_species_rf`\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Model Monitoring For Online Inference With Vertex AI\n",
    "\n",
    "The model trained above was trained using BigQuery ML's [`CREATE MODEL` statement](https://cloud.google.com/bigquery/docs/reference/standard-sql/bigqueryml-syntax-create) along with the training option `MODEL_REGISTRY = \"vertex_ai\"` which automatically registers the model in the [Vertex AI Model Registry](https://cloud.google.com/vertex-ai/docs/model-registry/introduction).  This means the BigQuery ML models can be managed directly in Vertex AI - [more information](https://cloud.google.com/bigquery/docs/managing-models-vertex).\n",
    "\n",
    "Models in the Vertex AI Model Registry can be used to [serve batch or online predictions](https://cloud.google.com/vertex-ai/docs/predictions/get-predictions).  In this section the [Vertex AI Python SDK](https://cloud.google.com/vertex-ai/docs/start/use-vertex-ai-python-sdk) is used to [deploy the model](https://cloud.google.com/vertex-ai/docs/general/deployment) created in this workflow and [get online predictions](https://cloud.google.com/vertex-ai/docs/predictions/get-online-predictions).\n",
    "\n",
    "The deployment of the model will include an extra setting to [setup logging of prediction request and responses to BigQuery](https://cloud.google.com/vertex-ai/docs/predictions/online-prediction-logging#enabling-and-disabling).  By logging the request and responses to BigQuery we can easily use the model monitoring functions covered in this tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from google.cloud import aiplatform\n",
    "aiplatform.init(project = 'statmike-mlops-349915', location = 'us-central1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Model From Vertex AI Model Registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = aiplatform.Model(model_name = 'classify_species_rf')\n",
    "model.versioned_resource_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy Model To Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "endpoint = model.deploy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "endpoint.resource_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Data For Predictions\n",
    "\n",
    "Get a sample of data from the serving table to use as online prediction requests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bigquery online\n",
    "SELECT * EXCEPT(species, instance_timestamp)\n",
    "FROM statmike-mlops-349915.bqml_model_monitoring.serving\n",
    "WHERE RAND() < 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "online = online.dropna()\n",
    "online['sex'].replace(np.nan, '', inplace=True)\n",
    "online = online.to_dict(orient = 'records')\n",
    "online[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Get Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "endpoint.predict(instances = online[0:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enable Prediction request-response logging To BigQuery\n",
    "\n",
    "The endpoint can be enabled for logging both the request and response for predictions.  These logs are directed to a BigQuery table.  This is enable throught the `gcloud ai endpoints update` command - [reference](https://cloud.google.com/sdk/gcloud/reference/ai/endpoints/update)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "endpoint.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!gcloud ai endpoints update $endpoint.name \\\n",
    "--region=us-central1 \\\n",
    "--request-response-logging-table=bq://statmike-mlops-349915.bqml_model_monitoring.serving_online"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Send Prediction Requests To Endpoint\n",
    "\n",
    "These will get logged to the BigQuery table specified above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for instance in online:\n",
    "    prediction = endpoint.predict(instances = [instance])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bigquery\n",
    "SELECT *\n",
    "FROM `statmike-mlops-349915.bqml_model_monitoring.serving_online`\n",
    "LIMIT 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create A View Of All Serving Data\n",
    "\n",
    "Combine the batch serving data with the online serving data in a view."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bigquery\n",
    "SELECT\n",
    "    logging_time as instance_timestamp,\n",
    "    JSON_VALUE(request, \"$.island\") as island,\n",
    "    JSON_VALUE(request, \"$.sex\") as sex,\n",
    "    CAST(JSON_VALUE(request, \"$.flipper_length_mm\") AS FLOAT64) as flipper_length_mm,\n",
    "    CAST(JSON_VALUE(request, \"$.body_mass_g\") AS FLOAT64) as body_mass_g,\n",
    "    CAST(JSON_VALUE(request, \"$.culmen_length_mm\") AS FLOAT64) as culmen_length_mm,\n",
    "    CAST(JSON_VALUE(request, \"$.culmen_depth_mm\") AS FLOAT64) as culmen_depth_mm\n",
    "FROM `statmike-mlops-349915.bqml_model_monitoring.serving_online`,\n",
    "UNNEST(request_payload) as request\n",
    "LIMIT 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bigquery\n",
    "CREATE OR REPLACE VIEW `statmike-mlops-349915.bqml_model_monitoring.serving_all` AS\n",
    "WITH\n",
    "    BATCH AS (\n",
    "        SELECT instance_timestamp, island, sex, flipper_length_mm, body_mass_g, culmen_length_mm, culmen_depth_mm\n",
    "        FROM `statmike-mlops-349915.bqml_model_monitoring.serving`\n",
    "    ),\n",
    "    ONLINE AS (\n",
    "        SELECT\n",
    "            logging_time as instance_timestamp,\n",
    "            JSON_VALUE(request, \"$.island\") as island,\n",
    "            JSON_VALUE(request, \"$.sex\") as sex,\n",
    "            CAST(JSON_VALUE(request, \"$.flipper_length_mm\") AS FLOAT64) as flipper_length_mm,\n",
    "            CAST(JSON_VALUE(request, \"$.body_mass_g\") AS FLOAT64) as body_mass_g,\n",
    "            CAST(JSON_VALUE(request, \"$.culmen_length_mm\") AS FLOAT64) as culmen_length_mm,\n",
    "            CAST(JSON_VALUE(request, \"$.culmen_depth_mm\") AS FLOAT64) as culmen_depth_mm\n",
    "        FROM `statmike-mlops-349915.bqml_model_monitoring.serving_online`,\n",
    "        UNNEST(request_payload) as request\n",
    "    )\n",
    "SELECT * FROM BATCH\n",
    "UNION ALL\n",
    "SELECT * FROM ONLINE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monitoring Skew (Change from training) With `ML.VALIDATE_DATA_SKEW`\n",
    "\n",
    "Compare today, or any data, to the training data by directly comparing to the the model created in BigQuery."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bigquery c_skew\n",
    "SELECT *\n",
    "FROM ML.VALIDATE_DATA_SKEW(\n",
    "    MODEL `statmike-mlops-349915.bqml_model_monitoring.classify_species_rf`,\n",
    "    (\n",
    "        SELECT *\n",
    "        FROM `statmike-mlops-349915.bqml_model_monitoring.serving_all`\n",
    "        WHERE DATE(instance_timestamp) >= CURRENT_DATE()\n",
    "    )\n",
    "    ,STRUCT(TRUE AS enable_visualization_link)\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "c_skew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "display(HTML(f'<a href=\"{c_skew.visualization_link[0]}\" target=\"_blank\" style=\"font-size: 18px;\">Open Google Cloud Console in a new tab</a>'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monitoring Drift (Change Over Time) With `ML.VALIDATE_DATA_DRIFT`\n",
    "\n",
    "Compare today to 5 days ago and set the a lower, more sensitive, threshold of `0.03` (default is `0.3`) for all features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bigquery c_drift\n",
    "SELECT *\n",
    "FROM ML.VALIDATE_DATA_DRIFT(\n",
    "    (\n",
    "        SELECT * EXCEPT(instance_timestamp)\n",
    "        FROM `statmike-mlops-349915.bqml_model_monitoring.serving_all`\n",
    "        WHERE DATE(instance_timestamp) = DATE_SUB(CURRENT_DATE(), INTERVAL 5 DAY)\n",
    "    ),\n",
    "    (\n",
    "        SELECT * EXCEPT(instance_timestamp)\n",
    "        FROM `statmike-mlops-349915.bqml_model_monitoring.serving_all`\n",
    "        WHERE DATE(instance_timestamp) = CURRENT_DATE() \n",
    "    ),\n",
    "    STRUCT(\n",
    "        0.03 AS categorical_default_threshold,\n",
    "        0.03 AS numerical_default_threshold\n",
    "    )\n",
    "    , MODEL `statmike-mlops-349915.bqml_model_monitoring.classify_species_logistic`\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "c_drift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "display(HTML(f'<a href=\"{c_drift.visualization_link[0]}\" target=\"_blank\" style=\"font-size: 18px;\">Open Google Cloud Console in a new tab</a>'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Endpoint \n",
    "To prevent ongoing cost for this demonstration, remove the endpoint.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "endpoint.delete(force = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Continous Monitoring\n",
    "\n",
    "The methods above can be combined into a job that runs both skew and drift detection.  The jobs can be scheduled or triggered to make the process of model monitoring continous - continous monitoring.  If the model quality can be evaluated with confidence then the automation can even be extended to retrain and update the model for continous training.   \n",
    "\n",
    "This section shows one of many ways to create a model monitoring job. For models created in BigQuery with BigQuery ML it also shows a retraining action as part of the job when alerts are detected.\n",
    "\n",
    "These types of jobs could be automated for continous monitoring with one of these methods:\n",
    "- [BigQuery Scheduled Queries](https://cloud.google.com/bigquery/docs/scheduling-queries)\n",
    "    - Featured below\n",
    "- [Dataform](https://cloud.google.com/dataform/docs/quickstart-create-workflow)\n",
    "- [Workflows](https://cloud.google.com/workflows/docs/tutorials/bigquery-parallel-jobs)\n",
    "- [Cloud Composer](https://cloud.google.com/composer/docs/data-analytics-googlecloud)\n",
    "- [Vertex AI Pipelines](https://cloud.google.com/vertex-ai/docs/pipelines/gcpc-list#bqml_components)\n",
    "\n",
    "This section will show how to:\n",
    "- Develop model monitoring jobs:\n",
    "    - with alterting and retraining\n",
    "- Build tables to capture continous monitoring results\n",
    "- Extend monitoring jobs to BigQuery Scheduled Queries\n",
    "- Backfill monitoring jobs for a past time period"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Monitoring Job: With Alerting And Retraining\n",
    "\n",
    "A BigQuery SQL job that uses the [procedural language](https://cloud.google.com/bigquery/docs/reference/standard-sql/procedural-language) to execute multiple statements (steps) as a single query.  In this case, monitoring skew and drift, detecting any feature level anomalies in either and reporting back the anomalies via a log note with a forced error.\n",
    "\n",
    "This job also includes retraining of the BigQuery ML model:\n",
    "In this case the example is simplified to retrain the model and directly implement it as a replacement with `CREATE OR REPLACE MODEL`.  In a production enviornment additional pre/post steps might take place as part of this workflow:\n",
    "- on skew/drift detection:\n",
    "    - Prior to retraining:\n",
    "        - ensure detection is not due to data errors, schema changes, or system changes\n",
    "    - After retrainning:\n",
    "        - evaluate the model and compare to current production version\n",
    "        - conditionally deploy the new version if it is better in any/all key metrics\n",
    "        - consider rollout strategies for the retrained model\n",
    "        - trigger human review before deployment of the replacement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bigquery\n",
    "DECLARE drift_anomalies ARRAY<STRUCT<input STRING, visualization_link STRING>>;\n",
    "DECLARE drift STRING;\n",
    "DECLARE skew_anomalies ARRAY<STRUCT<input STRING, visualization_link STRING>>;\n",
    "DECLARE skew STRING;\n",
    "\n",
    "# Monitor Drift:\n",
    "SET drift_anomalies = (\n",
    "    SELECT ARRAY_AGG(STRUCT(input, visualization_link))\n",
    "    FROM ML.VALIDATE_DATA_DRIFT(\n",
    "        (# base\n",
    "            SELECT * EXCEPT(species, instance_timestamp)\n",
    "            FROM `statmike-mlops-349915.bqml_model_monitoring.serving`\n",
    "            WHERE DATE(instance_timestamp) = DATE_SUB(CURRENT_DATE(), INTERVAL 30 DAY)\n",
    "        ),\n",
    "        (# compare\n",
    "            SELECT * EXCEPT(species, instance_timestamp)\n",
    "            FROM `statmike-mlops-349915.bqml_model_monitoring.serving`\n",
    "            WHERE DATE(instance_timestamp) = DATE_SUB(CURRENT_DATE(), INTERVAL 29 DAY)\n",
    "        ),\n",
    "        STRUCT(\n",
    "            0.4 AS categorical_default_threshold,\n",
    "            0.4 AS numerical_default_threshold\n",
    "        )\n",
    "        , MODEL `statmike-mlops-349915.bqml_model_monitoring.classify_species_logistic`\n",
    "    )\n",
    "    WHERE is_anomaly = True\n",
    ");\n",
    "IF(ARRAY_LENGTH(drift_anomalies) > 0) THEN\n",
    "    SET drift = CONCAT(\n",
    "        \"\\n\\tDrift: detected in the following features\",\n",
    "        (\n",
    "            SELECT STRING_AGG(\n",
    "                CONCAT(\n",
    "                    '\\n\\t\\t',\n",
    "                    da.input,\n",
    "                    ': ',\n",
    "                    da.visualization_link\n",
    "                )\n",
    "            )\n",
    "            FROM UNNEST(drift_anomalies) as da\n",
    "        )\n",
    "    );\n",
    "    ELSE SET drift = '\\n\\tDrift: not detected.';\n",
    "END IF;\n",
    "\n",
    "# Monitor Skew\n",
    "SET skew_anomalies = (\n",
    "    SELECT ARRAY_AGG(STRUCT(input, visualization_link))\n",
    "    FROM ML.VALIDATE_DATA_SKEW(\n",
    "        # base\n",
    "        MODEL `statmike-mlops-349915.bqml_model_monitoring.classify_species_rf`,\n",
    "        (# compare\n",
    "            SELECT * EXCEPT(species, instance_timestamp)\n",
    "            FROM `statmike-mlops-349915.bqml_model_monitoring.serving`\n",
    "            WHERE DATE(instance_timestamp) = DATE_SUB(CURRENT_DATE(), INTERVAL 30 DAY)\n",
    "        )\n",
    "        ,STRUCT(TRUE AS enable_visualization_link)\n",
    "    )\n",
    "    WHERE is_anomaly = True\n",
    ");\n",
    "IF(ARRAY_LENGTH(skew_anomalies) > 0) THEN\n",
    "    SET skew = CONCAT(\n",
    "        \"\\n\\tSkew: detected in the following features\",\n",
    "        (\n",
    "            SELECT STRING_AGG(\n",
    "                CONCAT(\n",
    "                    '\\n\\t\\t',\n",
    "                    sa.input,\n",
    "                    ': ',\n",
    "                    sa.visualization_link\n",
    "                )\n",
    "            )\n",
    "            FROM UNNEST(skew_anomalies) as sa\n",
    "        )\n",
    "    );\n",
    "    ELSE SET skew = '\\n\\tSkew: not detected.';\n",
    "END IF;\n",
    "\n",
    "# Prepare Alert\n",
    "IF(ARRAY_LENGTH(drift_anomalies) > 0 OR ARRAY_LENGTH(skew_anomalies) > 0) THEN\n",
    "    BEGIN\n",
    "        DECLARE train_accuracy FLOAT64;\n",
    "        DECLARE recent_accuracy FLOAT64;\n",
    "        DECLARE retrain_accuracy FLOAT64;\n",
    "\n",
    "        # get current models evaluation metrics: accuracy\n",
    "        SET train_accuracy = (\n",
    "            SELECT accuracy\n",
    "            FROM ML.EVALUATE (\n",
    "                MODEL `statmike-mlops-349915.bqml_model_monitoring.classify_species_rf`\n",
    "            )\n",
    "        );\n",
    "\n",
    "        # get current models recent evaluation metrics: accuracy\n",
    "        SET recent_accuracy = (\n",
    "            SELECT accuracy\n",
    "            FROM ML.EVALUATE (\n",
    "                MODEL `statmike-mlops-349915.bqml_model_monitoring.classify_species_rf`,\n",
    "                (\n",
    "                    SELECT *\n",
    "                    FROM `statmike-mlops-349915.bqml_model_monitoring.serving`\n",
    "                    WHERE DATE(instance_timestamp) = DATE_SUB(CURRENT_DATE(), INTERVAL 30 DAY) \n",
    "                )\n",
    "            )\n",
    "        );\n",
    "\n",
    "        # retrain the model\n",
    "        CREATE OR REPLACE MODEL `statmike-mlops-349915.bqml_model_monitoring.classify_species_rf`\n",
    "            TRANSFORM(\n",
    "                ML.ROBUST_SCALER(body_mass_g) OVER() AS body_mass_g,\n",
    "                ML.STANDARD_SCALER(culmen_length_mm) OVER() AS culmen_length_mm,\n",
    "                ML.STANDARD_SCALER(culmen_depth_mm) OVER() AS culmen_depth_mm,\n",
    "                ML.QUANTILE_BUCKETIZE(flipper_length_mm, 3) OVER() AS flipper_length_mm,\n",
    "                ML.IMPUTER(sex, 'most_frequent') OVER() AS sex,\n",
    "                ML.IMPUTER(island, 'most_frequent') OVER() AS island,\n",
    "                species\n",
    "            )\n",
    "            OPTIONS(\n",
    "                MODEL_TYPE = 'RANDOM_FOREST_CLASSIFIER',\n",
    "                INPUT_LABEL_COLS = ['species'],\n",
    "\n",
    "                # data specifics\n",
    "                DATA_SPLIT_METHOD = 'AUTO_SPLIT',\n",
    "\n",
    "                # model specifics\n",
    "                AUTO_CLASS_WEIGHTS = FALSE,\n",
    "                NUM_PARALLEL_TREE= 150,\n",
    "                TREE_METHOD = 'HIST',\n",
    "                SUBSAMPLE = 0.85,\n",
    "                COLSAMPLE_BYTREE = 0.9,\n",
    "                ENABLE_GLOBAL_EXPLAIN = TRUE,\n",
    "\n",
    "                # register model in Vertex AI For Online Serving\n",
    "                MODEL_REGISTRY = 'VERTEX_AI'\n",
    "            )\n",
    "        AS\n",
    "            SELECT species, island, culmen_length_mm, culmen_depth_mm, sex, flipper_length_mm, body_mass_g\n",
    "            FROM `statmike-mlops-349915.bqml_model_monitoring.training`\n",
    "            UNION ALL\n",
    "            SELECT species, island, culmen_length_mm, culmen_depth_mm, sex, flipper_length_mm, body_mass_g\n",
    "            FROM `statmike-mlops-349915.bqml_model_monitoring.serving`\n",
    "            WHERE DATE(instance_timestamp) = DATE_SUB(CURRENT_DATE(), INTERVAL 30 DAY)\n",
    "        ;\n",
    "\n",
    "        # get retrained models evaluation metrics: accuracy\n",
    "        SET retrain_accuracy = (\n",
    "            SELECT accuracy\n",
    "            FROM ML.EVALUATE (\n",
    "                MODEL `statmike-mlops-349915.bqml_model_monitoring.classify_species_rf`\n",
    "            )\n",
    "        );\n",
    "\n",
    "        SELECT ERROR(\n",
    "            CONCAT(\n",
    "                \"\\n\\nMonitoring Report:\",\n",
    "                drift,\n",
    "                skew,\n",
    "                \"\\n\\nThe Model was retrained:\",\n",
    "                \"\\n\\taccuracy of prior model: \", train_accuracy,\n",
    "                \"\\n\\trecent accuracy of prior model: \", recent_accuracy,\n",
    "                \"\\n\\taccuracy after retraining: \", retrain_accuracy,\n",
    "                \"\\n\\n\"\n",
    "            )\n",
    "        );\n",
    "    END;\n",
    "    ELSE\n",
    "        SELECT ERROR(\n",
    "            CONCAT(\n",
    "                \"\\n\\nMonitoring Report:\",\n",
    "                drift,\n",
    "                skew,\n",
    "                \"\\n\\n\"\n",
    "            )\n",
    "        );\n",
    "END IF;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From Job To Scheduled Query\n",
    "\n",
    "The model monitoring job created above can be modified and scheduled using [scheduled queries](https://cloud.google.com/bigquery/docs/scheduling-queries).  A key feature of the modification is making use of the parameter `@run_date` to parameterize the queries reference to dates (see [configuration options](https://cloud.google.com/bigquery/docs/scheduling-queries#configuration_options)).  This allows the query to run as though it is on different dates which will be helpful as we backfill the model monitoring runs after scheduling for today and forward.\n",
    "\n",
    "Note, the next cell is writing the content of the query to a file named `model_monitoring_job.sql`.\n",
    "Other modification to the job above:\n",
    "- Drift is set to compare the last weeks serving data to the prior week\n",
    "- Skew is set to compare the last weeks serving data to the baseline training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%writefile model_monitoring_job.sql\n",
    "DECLARE drift_anomalies ARRAY<STRUCT<input STRING, visualization_link STRING>>;\n",
    "DECLARE drift STRING;\n",
    "DECLARE skew_anomalies ARRAY<STRUCT<input STRING, visualization_link STRING>>;\n",
    "DECLARE skew STRING;\n",
    "\n",
    "# Monitor Drift:\n",
    "SET drift_anomalies = (\n",
    "    SELECT ARRAY_AGG(STRUCT(input, visualization_link))\n",
    "    FROM ML.VALIDATE_DATA_DRIFT(\n",
    "        (# base\n",
    "            SELECT * EXCEPT(instance_timestamp)\n",
    "            FROM `statmike-mlops-349915.bqml_model_monitoring.serving_all`\n",
    "            WHERE\n",
    "                DATE(instance_timestamp) >= DATE_SUB(@run_date, INTERVAL 2 WEEK)\n",
    "                AND\n",
    "                DATE(instance_timestamp) < DATE_SUB(@run_date, INTERVAL 1 WEEK)\n",
    "        ),\n",
    "        (# compare\n",
    "            SELECT * EXCEPT(instance_timestamp)\n",
    "            FROM `statmike-mlops-349915.bqml_model_monitoring.serving_all`\n",
    "            WHERE DATE(instance_timestamp) >= DATE_SUB(@run_date, INTERVAL 1 WEEK)\n",
    "        ),\n",
    "        STRUCT(\n",
    "            0.4 AS categorical_default_threshold,\n",
    "            0.4 AS numerical_default_threshold\n",
    "        )\n",
    "        , MODEL `statmike-mlops-349915.bqml_model_monitoring.classify_species_logistic`\n",
    "    )\n",
    "    WHERE is_anomaly = True\n",
    ");\n",
    "IF(ARRAY_LENGTH(drift_anomalies) > 0) THEN\n",
    "    SET drift = CONCAT(\n",
    "        \"\\n\\tDrift: detected in the following features\",\n",
    "        (\n",
    "            SELECT STRING_AGG(\n",
    "                CONCAT(\n",
    "                    '\\n\\t\\t',\n",
    "                    da.input,\n",
    "                    ': ',\n",
    "                    da.visualization_link\n",
    "                )\n",
    "            )\n",
    "            FROM UNNEST(drift_anomalies) as da\n",
    "        )\n",
    "    );\n",
    "    ELSE SET drift = '\\n\\tDrift: not detected.';\n",
    "END IF;\n",
    "\n",
    "# Monitor Skew\n",
    "SET skew_anomalies = (\n",
    "    SELECT ARRAY_AGG(STRUCT(input, visualization_link))\n",
    "    FROM ML.VALIDATE_DATA_SKEW(\n",
    "        # base\n",
    "        MODEL `statmike-mlops-349915.bqml_model_monitoring.classify_species_rf`,\n",
    "        (# compare\n",
    "            SELECT * EXCEPT(instance_timestamp)\n",
    "            FROM `statmike-mlops-349915.bqml_model_monitoring.serving_all`\n",
    "            WHERE DATE(instance_timestamp) >= DATE_SUB(@run_date, INTERVAL 1 WEEK)\n",
    "        )\n",
    "        ,STRUCT(TRUE AS enable_visualization_link)\n",
    "    )\n",
    "    WHERE is_anomaly = True\n",
    ");\n",
    "IF(ARRAY_LENGTH(skew_anomalies) > 0) THEN\n",
    "    SET skew = CONCAT(\n",
    "        \"\\n\\tSkew: detected in the following features\",\n",
    "        (\n",
    "            SELECT STRING_AGG(\n",
    "                CONCAT(\n",
    "                    '\\n\\t\\t',\n",
    "                    sa.input,\n",
    "                    ': ',\n",
    "                    sa.visualization_link\n",
    "                )\n",
    "            )\n",
    "            FROM UNNEST(skew_anomalies) as sa\n",
    "        )\n",
    "    );\n",
    "    ELSE SET skew = '\\n\\tSkew: not detected.';\n",
    "END IF;\n",
    "\n",
    "# Prepare Alert\n",
    "IF(ARRAY_LENGTH(drift_anomalies) > 0 OR ARRAY_LENGTH(skew_anomalies) > 0) THEN\n",
    "    BEGIN\n",
    "        DECLARE train_accuracy FLOAT64;\n",
    "        DECLARE recent_accuracy FLOAT64;\n",
    "        DECLARE retrain_accuracy FLOAT64;\n",
    "\n",
    "        # get current models evaluation metrics: accuracy\n",
    "        SET train_accuracy = (\n",
    "            SELECT accuracy\n",
    "            FROM ML.EVALUATE (\n",
    "                MODEL `statmike-mlops-349915.bqml_model_monitoring.classify_species_rf`\n",
    "            )\n",
    "        );\n",
    "\n",
    "        # get current models recent evaluation metrics: accuracy\n",
    "        SET recent_accuracy = (\n",
    "            SELECT accuracy\n",
    "            FROM ML.EVALUATE (\n",
    "                MODEL `statmike-mlops-349915.bqml_model_monitoring.classify_species_rf`,\n",
    "                (\n",
    "                    SELECT *\n",
    "                    FROM `statmike-mlops-349915.bqml_model_monitoring.serving`\n",
    "                    WHERE DATE(instance_timestamp) >= DATE_SUB(@run_date, INTERVAL 1 WEEK) \n",
    "                )\n",
    "            )\n",
    "        );\n",
    "\n",
    "        # retrain the model\n",
    "        CREATE OR REPLACE MODEL `statmike-mlops-349915.bqml_model_monitoring.classify_species_rf`\n",
    "            TRANSFORM(\n",
    "                ML.ROBUST_SCALER(body_mass_g) OVER() AS body_mass_g,\n",
    "                ML.STANDARD_SCALER(culmen_length_mm) OVER() AS culmen_length_mm,\n",
    "                ML.STANDARD_SCALER(culmen_depth_mm) OVER() AS culmen_depth_mm,\n",
    "                ML.QUANTILE_BUCKETIZE(flipper_length_mm, 3) OVER() AS flipper_length_mm,\n",
    "                ML.IMPUTER(sex, 'most_frequent') OVER() AS sex,\n",
    "                ML.IMPUTER(island, 'most_frequent') OVER() AS island,\n",
    "                species\n",
    "            )\n",
    "            OPTIONS(\n",
    "                MODEL_TYPE = 'RANDOM_FOREST_CLASSIFIER',\n",
    "                INPUT_LABEL_COLS = ['species'],\n",
    "\n",
    "                # data specifics\n",
    "                DATA_SPLIT_METHOD = 'AUTO_SPLIT',\n",
    "\n",
    "                # model specifics\n",
    "                AUTO_CLASS_WEIGHTS = FALSE,\n",
    "                NUM_PARALLEL_TREE= 150,\n",
    "                TREE_METHOD = 'HIST',\n",
    "                SUBSAMPLE = 0.85,\n",
    "                COLSAMPLE_BYTREE = 0.9,\n",
    "                ENABLE_GLOBAL_EXPLAIN = TRUE,\n",
    "\n",
    "                # register model in Vertex AI For Online Serving\n",
    "                MODEL_REGISTRY = 'VERTEX_AI',\n",
    "                VERTEX_AI_MODEL_ID = 'classify_species_rf'\n",
    "            )\n",
    "        AS\n",
    "            SELECT species, island, culmen_length_mm, culmen_depth_mm, sex, flipper_length_mm, body_mass_g\n",
    "            FROM `statmike-mlops-349915.bqml_model_monitoring.training_split`\n",
    "            WHERE splits = 'TRAIN'\n",
    "            UNION ALL\n",
    "            SELECT species, island, culmen_length_mm, culmen_depth_mm, sex, flipper_length_mm, body_mass_g\n",
    "            FROM `statmike-mlops-349915.bqml_model_monitoring.serving`\n",
    "            WHERE DATE(instance_timestamp) < @run_date\n",
    "        ;\n",
    "\n",
    "        # get retrained models evaluation metrics: accuracy\n",
    "        SET retrain_accuracy = (\n",
    "            SELECT accuracy\n",
    "            FROM ML.EVALUATE (\n",
    "                MODEL `statmike-mlops-349915.bqml_model_monitoring.classify_species_rf`\n",
    "            )\n",
    "        );\n",
    "\n",
    "        SELECT ERROR(\n",
    "            CONCAT(\n",
    "                \"\\n\\nMonitoring Report for \", @run_date, \":\",\n",
    "                \"\\n\\t\", drift,\n",
    "                \"\\n\\t\", skew,\n",
    "                \"\\n\\nThe Model was retrained:\",\n",
    "                \"\\n\\taccuracy of prior model: \", train_accuracy,\n",
    "                \"\\n\\trecent accuracy of prior model: \", recent_accuracy,\n",
    "                \"\\n\\taccuracy after retraining: \", retrain_accuracy,\n",
    "                \"\\n\\n\"\n",
    "            )\n",
    "        );\n",
    "    END;\n",
    "    # ELSE ... supressed alerts on runs without anomalies detected\n",
    "END IF;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Schedule The Query\n",
    "\n",
    "The query can be scheduled in [a number of ways](https://cloud.google.com/bigquery/docs/scheduling-queries#set_up_scheduled_queries) including the console, bq cli, and Python. Here, the Python client will be used.\n",
    "- **References**\n",
    "    - [Python Client For BigQuery Data Transfer](https://cloud.google.com/python/docs/reference/bigquerydatatransfer/latest)\n",
    "    - [Set up schedule queries with Python client](https://cloud.google.com/bigquery/docs/scheduling-queries#python)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from google.cloud import bigquery_datatransfer\n",
    "from datetime import datetime, timezone, timedelta\n",
    "import time\n",
    "transfer_client = bigquery_datatransfer.DataTransferServiceClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "start_time = datetime.now(timezone.utc) + timedelta(days=1) # start tomorrow\n",
    "start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('model_monitoring_job.sql', 'r') as file:\n",
    "    query = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "transfer_client.common_location_path('statmike-mlops-349915', 'us')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scheduled_query = transfer_client.create_transfer_config(\n",
    "    #parent = transfer_client.common_project_path('statmike-mlops-349915'),\n",
    "    parent = transfer_client.common_location_path('statmike-mlops-349915', 'us'),\n",
    "    transfer_config = bigquery_datatransfer.TransferConfig(\n",
    "        display_name = 'Continous Model Monitoring',\n",
    "        data_source_id = 'scheduled_query',\n",
    "        params = {'query': query},\n",
    "        schedule = 'every 24 hours',\n",
    "        schedule_options = bigquery_datatransfer.ScheduleOptions(\n",
    "            start_time=start_time.strftime(\"%Y-%m-%dT%H:%M:%SZ\")\n",
    "        ),\n",
    "        email_preferences = bigquery_datatransfer.EmailPreferences(\n",
    "            enable_failure_email = True\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scheduled_query.display_name, scheduled_query.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scheduled_query.next_run_time.strftime(\"%Y-%m-%d %H:%M:%S.%f\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a moment to see the query in the console:\n",
    "- Console > BigQuery > Scheduled Queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backfill History With Scheduled Query\n",
    "\n",
    "While the client can use a start and end time to run a range of backfill dates, it will runs these backwards from most recent to the earliest time.  Due to the nature of the model monitoring job it is more desirable to run these in the order from earliest to most recent.  This is accomplished by launching each days job separately in the desired order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# -30 days\n",
    "start_time = datetime.now(timezone.utc) + timedelta(days = -30)\n",
    "backfill_job = transfer_client.start_manual_transfer_runs(\n",
    "    request = bigquery_datatransfer.StartManualTransferRunsRequest(\n",
    "        parent = scheduled_query.name,\n",
    "        requested_run_time = start_time \n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "backfill_job.runs[0].name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "transfer_client.get_transfer_run(\n",
    "    name = backfill_job.runs[0].name\n",
    ").state.name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:** A State of 'FAILED' is actually the correct end state as the method of using SQL ERRORS to pass the results and trigger notification emails was used. A State of 'SUCCEEDED' will represent runs without an anomaly detected.  [Read more about TrasferState](https://cloud.google.com/python/docs/reference/bigquerydatatransfer/latest/google.cloud.bigquery_datatransfer_v1.types.TransferState)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "while True:\n",
    "    state = transfer_client.get_transfer_run(\n",
    "        name = backfill_job.runs[0].name\n",
    "    ).state.name\n",
    "    if state in ['FAILED', 'SUCCEEDED', 'CANCELLED']:\n",
    "        break\n",
    "    else:\n",
    "        time.sleep(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "backfill_jobs =[backfill_job]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Loop From -29 to -0 days\n",
    "for days in range(30)[::-1]:\n",
    "    start_time = datetime.now(timezone.utc) + timedelta(days = -1*days)\n",
    "    print(start_time)\n",
    "    # start job\n",
    "    backfill_jobs.append(\n",
    "        transfer_client.start_manual_transfer_runs(\n",
    "            request = bigquery_datatransfer.StartManualTransferRunsRequest(\n",
    "                parent = scheduled_query.name,\n",
    "                requested_run_time = start_time \n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    # monitor job before continuing:\n",
    "    while True:\n",
    "        state = transfer_client.get_transfer_run(\n",
    "            name = backfill_jobs[-1].runs[0].name\n",
    "        ).state.name\n",
    "        if state in ['FAILED', 'SUCCEEDED', 'CANCELLED']:\n",
    "            break\n",
    "        else:\n",
    "            time.sleep(10)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "backfill_results = [transfer_client.get_transfer_run(name = j.runs[0].name) for j in backfill_jobs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(\n",
    "    {\n",
    "        'Date':[r.run_time for r in backfill_results],\n",
    "        'Result':[r.error_status.message for r in backfill_results]\n",
    "    }\n",
    ").style.set_properties(**{'text-align': 'left', 'white-space': 'pre-wrap'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## More Resources\n",
    "\n",
    "Did you also check out the ['BigQuery ML (BQML) - Model Monitoring Introduction'](./bqml-model-monitoring-introduction.ipynb) for quick overview of model monitoring with BigQuery?  If not, try it out also. \n",
    "\n",
    "Read more about model monitoring in the documentation for the model monitoring functions:\n",
    "* [BigQuery ML Documentation](https://cloud.google.com/bigquery-ml/docs/)\n",
    "* [BigQuery ML Model Monitoring](https://cloud.google.com/bigquery/docs/model-monitoring-overview)\n",
    "    - [`ML.DESCRIBE_DATA`](https://cloud.google.com/bigquery/docs/reference/standard-sql/bigqueryml-syntax-describe-data)\n",
    "    - [`ML.VALIDATE_DATA_SKEW`](https://cloud.google.com/bigquery/docs/reference/standard-sql/bigqueryml-syntax-validate-data-skew)\n",
    "    - [`ML.VALIDATE_DATA_DRIFT`](https://cloud.google.com/bigquery/docs/reference/standard-sql/bigqueryml-syntax-validate-data-drift)\n",
    "    - [`ML.TFDV_DESCRIBE`](https://cloud.google.com/bigquery/docs/reference/standard-sql/bigqueryml-syntax-tfdv-describe)\n",
    "    - [`ML.TFDV_VALIDATE`](https://cloud.google.com/bigquery/docs/reference/standard-sql/bigqueryml-syntax-tfdv-validate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Remove Resources Created In This Notebook\n",
    "\n",
    "The content is contained within the BigQuery dataset named `bqml_model_monitoring` created above and Vertex AI (endpoint created above).\n",
    "\n",
    "The following will delete the Vertex AI and BigQuery resources created above and the BigQuery dataset if it is empty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# to remove resources change this flag to True:\n",
    "remove = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if remove:\n",
    "    # client for BigQuery\n",
    "    from google.cloud import bigquery\n",
    "    bq = bigquery.Client(project = 'statmike-mlops-349915')\n",
    "    \n",
    "    # delete BigQuery table(s) and model(s) created above\n",
    "    bq.delete_table('statmike-mlops-349915.bqml_model_monitoring.training_split')\n",
    "    bq.delete_table('statmike-mlops-349915.bqml_model_monitoring.serving')\n",
    "    bq.delete_table('statmike-mlops-349915.bqml_model_monitoring.serving_online')\n",
    "    bq.delete_table('statmike-mlops-349915.bqml_model_monitoring.serving_all')\n",
    "    bq.delete_model('statmike-mlops-349915.bqml_model_monitoring.classify_species_rf')\n",
    "    \n",
    "    # delete BigQuery dataset - fails if other content was in the dataset than what this notebook created\n",
    "    bq.delete_dataset('statmike-mlops-349915.bqml_model_monitoring', delete_contents = False)\n",
    "    \n",
    "    # delete the scheduled query\n",
    "    transfer_client.delete_transfer_config(\n",
    "        name = scheduled_query.name\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMy6GbowZC6hovxyAVQ0UWd",
   "provenance": []
  },
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m128",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m128"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "1109199e5b67477788dcf20b48558d41": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_93f32edfd72e4a29ac69d2e202d6e14c",
       "IPY_MODEL_3da40e23ffbd47db8d1a250292255c32",
       "IPY_MODEL_bbd5c7d0941a458dbaee866da7e5366f"
      ],
      "layout": "IPY_MODEL_e2e3c77141c04fa7885bf4b4c0e314f4"
     }
    },
    "16d1acd4a3e94cf9bc3d683ff7eb1125": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1b76a7321f1e482e92b6725f5d120700": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2d65e5a9073f4b65b95c2c629255cac1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "39a8f6a0c95342299729b62b7a818084": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3acd5dce7d1b4a84b1b5540ec8d37ed3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "3da40e23ffbd47db8d1a250292255c32": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1b76a7321f1e482e92b6725f5d120700",
      "max": 5,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_6827ef49075d48a1bb2582fb7fd52389",
      "value": 5
     }
    },
    "441b987af9044d1f9326f906d0f1d218": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "48543e1564664f73b553a0ae5bfb0843": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4e5a11ea456d49a8bd7563e9b2c35511": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "543a939bbf684e49ad83771418dfdd09": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "549c9135cfbe467ebc3a60d6ad5750e6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e0194e91019f4661a01322bbda67ac18",
      "placeholder": "​",
      "style": "IPY_MODEL_6b0ff87e15fd4ff684355a521e0f7a1f",
      "value": ""
     }
    },
    "5805c14443ec4d3ebf24ea8dda735a99": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6827ef49075d48a1bb2582fb7fd52389": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "6b0ff87e15fd4ff684355a521e0f7a1f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8930cc60223a4b56a70a17b1c5d03a93": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_48543e1564664f73b553a0ae5bfb0843",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_3acd5dce7d1b4a84b1b5540ec8d37ed3",
      "value": 1
     }
    },
    "93f32edfd72e4a29ac69d2e202d6e14c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_543a939bbf684e49ad83771418dfdd09",
      "placeholder": "​",
      "style": "IPY_MODEL_4e5a11ea456d49a8bd7563e9b2c35511",
      "value": "Downloading: 100%"
     }
    },
    "bbd5c7d0941a458dbaee866da7e5366f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5805c14443ec4d3ebf24ea8dda735a99",
      "placeholder": "​",
      "style": "IPY_MODEL_441b987af9044d1f9326f906d0f1d218",
      "value": ""
     }
    },
    "c656f444dbc4405a915eaecde42707d5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_16d1acd4a3e94cf9bc3d683ff7eb1125",
      "placeholder": "​",
      "style": "IPY_MODEL_2d65e5a9073f4b65b95c2c629255cac1",
      "value": "Job ID a2f9486b-cfda-4aad-959b-b5485f8f5dd8 successfully executed: 100%"
     }
    },
    "ddb7ba0f48b24355b23492fcb1db5939": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c656f444dbc4405a915eaecde42707d5",
       "IPY_MODEL_8930cc60223a4b56a70a17b1c5d03a93",
       "IPY_MODEL_549c9135cfbe467ebc3a60d6ad5750e6"
      ],
      "layout": "IPY_MODEL_39a8f6a0c95342299729b62b7a818084"
     }
    },
    "e0194e91019f4661a01322bbda67ac18": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e2e3c77141c04fa7885bf4b4c0e314f4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
