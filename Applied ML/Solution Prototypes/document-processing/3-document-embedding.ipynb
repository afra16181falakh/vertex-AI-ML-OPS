{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc7fd962",
   "metadata": {},
   "source": [
    "![tracker](https://us-central1-vertex-ai-mlops-369716.cloudfunctions.net/pixel-tracking?path=statmike%2Fvertex-ai-mlops%2FApplied+ML%2FSolution+Prototypes%2Fdocument-processing&file=3-document-embedding.ipynb)\n",
    "<!--- header table --->\n",
    "<table align=\"left\">\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://colab.research.google.com/github/statmike/vertex-ai-mlops/blob/main/Applied%20ML/Solution%20Prototypes/document-processing/3-document-embedding.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Google Colaboratory logo\">\n",
    "      <br>Run in<br>Colab\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/colab/import/https%3A%2F%2Fraw.githubusercontent.com%2Fstatmike%2Fvertex-ai-mlops%2Fmain%2FApplied%2520ML%2FSolution%2520Prototypes%2Fdocument-processing%2F3-document-embedding.ipynb\">\n",
    "      <img width=\"32px\" src=\"https://lh3.googleusercontent.com/JmcxdQi-qOpctIvWKgPtrzZdJJK-J3sWE1RsfjZNwshCFgE_9fULcNpuXYTilIR2hjwN\" alt=\"Google Cloud Colab Enterprise logo\">\n",
    "      <br>Run in<br>Colab Enterprise\n",
    "    </a>\n",
    "  </td>      \n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://github.com/statmike/vertex-ai-mlops/blob/main/Applied%20ML/Solution%20Prototypes/document-processing/3-document-embedding.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\">\n",
    "      <br>View on<br>GitHub\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/statmike/vertex-ai-mlops/main/Applied%20ML/Solution%20Prototypes/document-processing/3-document-embedding.ipynb\">\n",
    "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\">\n",
    "      <br>Open in<br>Vertex AI Workbench\n",
    "    </a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e8dd516",
   "metadata": {},
   "source": [
    "# Generate Embeddings For Documents\n",
    "\n",
    "> This workflow is part of a series of workflows for the solution prototype: [Document Processing With Generative AI: Parse, Extract, Validate Authenticity, and More](./readme.md)\n",
    "\n",
    "The earlier workflows in the series created a custom data extractor with Document AI and setup BigQuery object tables to help managed the processing of documents stored in GCS while providing a location to manage the extracted data as well.  Now that we have BigQuery tables linking to the documents and their extracted information, we can enhance our understanding of these documents.\n",
    "\n",
    "One effective way to represent information is by using an **embedding model**. These models are trained to create dense vector representations, known as embeddings. An embedding is essentially a vector of floating-point numbers, such as `[-0.06302902102470398, 0.00928034819662571, 0.014716853387653828, -0.028747491538524628, ...]`. These embeddings are incredibly useful for various tasks, including:\n",
    "-   **Similarity Search:** Finding and ranking similar content.\n",
    "-   **Classification:** Categorizing content based on similarity.\n",
    "-   **Clustering:** Grouping objects with similar attributes.\n",
    "-   **Anomaly Detection:** Identifying outliers or mismatched objects.\n",
    "-   **Contextual Sorting:** Ordering content based on its context.\n",
    "-   **And More:** Embeddings have a wide range of applications.\n",
    "\n",
    "Google Cloud's Vertex AI platform offers several embedding models as a service, ideal for both text and multimodal data (images, video, audio, and text). Vertex AI simplifies the use of these models through APIs and various client libraries, including Python.\n",
    "-   [Vertex AI Embeddings APIs Overview](https://cloud.google.com/vertex-ai/generative-ai/docs/embeddings)\n",
    "\n",
    "BigQuery also integrates these Vertex AI embedding models directly with the `ML.GENERATE_EMBEDDING` function. This allows us to enrich the data in BigQuery with embeddings of the source content stored in Google Cloud Storage, accessible through the object table we created.\n",
    "-   [BigQuery ML.GENERATE_EMBEDDING function](https://cloud.google.com/bigquery/docs/reference/standard-sql/bigqueryml-syntax-generate-embedding)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e90b741",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
